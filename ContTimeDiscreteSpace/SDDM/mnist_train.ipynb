{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lib.models.diffusion_model import CategoricalDiffusionModel\n",
    "from lib.config.config_mnist import get_config\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.optimizer.optimizer as optim\n",
    "import lib.networks.networks_utils as networks_utils\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "import lib.datasets.datasets_utils as datasets_utils\n",
    "from lib.datasets.datasets import get_dataloader\n",
    "import lib.utils.utils as utils\n",
    "import flax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_train = False\n",
    "config = get_config()\n",
    "\n",
    "# changed to see better what i need \n",
    "optimizer = optim.build_optimizer(config)\n",
    "fwd_model = model_utils.build_fwd_model(config)\n",
    "net = networks_utils.build_network(config)\n",
    "backwd_model = model_utils.build_backwd_model(config, fwd_model, net)\n",
    "\n",
    "model = CategoricalDiffusionModel(config, fwd_model, backwd_model, optimizer)\n",
    "\n",
    "global_key = jax.random.PRNGKey(42)\n",
    "global_key, model_key = jax.random.split(global_key, 2)\n",
    "\n",
    "# struct with step, params state, optimizer state, ema state\n",
    "state = model_utils.init_state(config, model, model_key)\n",
    "print(\"Number of parameters:\", sum(x.size for x in jax.tree_leaves(state.params)))\n",
    "\n",
    "\n",
    "if resume_train:\n",
    "    load_dir = ''\n",
    "\n",
    "init_step = state.step\n",
    "#state = flax.jax_utils.replicate(state)\n",
    "\n",
    "\n",
    "# replicate state over several devices: if one nothing happens\n",
    "# every device, process, got different rng key\n",
    "process_rng_key = jax.random.fold_in(global_key, jax.process_index())\n",
    "# functions over several devices\n",
    "#train_step_fn = jax.pmap(train_step_fn, axis_name=\"shard\")\n",
    "\n",
    "train_step_fn = model.training_step\n",
    "train_step_fn = jax.jit(train_step_fn)\n",
    "lr_schedule = optim.build_lr_schedule(config)\n",
    "\n",
    "num_samples = 16\n",
    "\n",
    "train_ds = datasets_utils.numpy_iter(get_dataloader(config, \"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for step in tqdm(range(init_step + 1, config.total_train_steps + 1)):\n",
    "    print(\"Iteration:\", step + 1)\n",
    "\n",
    "    #batch = fn_data_preprocess(next(train_ds))\n",
    "    batch = next(train_ds)\n",
    "    \n",
    "    process_rng_key = jax.random.fold_in(process_rng_key, step)\n",
    "    # for cpu: step_rng_keys = process_rng_key\n",
    "    step_rng_keys = utils.shard_prng_key(process_rng_key)\n",
    "    \n",
    "    state, aux = train_step_fn(state, step_rng_keys, batch)\n",
    "\n",
    "    #if step % config.log_every_steps == 0:\n",
    "    #    aux = jax.device_get(flax.jax_utils.unreplicate(aux))\n",
    "    #    aux[\"train/lr\"] = lr_schedule(step)\n",
    "\n",
    "    if step % config.sample_every_steps == 0:\n",
    "        x0 = model.sample_loop(state, process_rng_key, num_samples, conditioner=None)\n",
    "        #  x0 = utils.all_gather(x0)\n",
    "        \n",
    "    if step % config.save_every_steps == 0:\n",
    "        bookkeeping.save_model(state, step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
