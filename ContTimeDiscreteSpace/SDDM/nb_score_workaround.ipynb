{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from lib.models.forward_model import UniformForward\n",
    "from flax import linen as nn\n",
    "from lib.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.arange(10, dtype=jnp.int32)\n",
    "np.expand_dims(jnp.arange(10, dtype=jnp.int32), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_const = 1\n",
    "S = 4\n",
    "B = 2\n",
    "D = 4\n",
    "uni = UniformForward(S, rate_const)\n",
    "\n",
    "rng = jax.random.PRNGKey(1008)\n",
    "t_rng, sample_rng = jax.random.split(rng)\n",
    "t = jax.random.uniform(t_rng, (B,))\n",
    "print(t)\n",
    "xt = jax.random.randint(sample_rng, shape=(B, D), minval=0, maxval=S, dtype=jnp.int32)\n",
    "qt0 = uni.transition(t)\n",
    "qt0_y2x = jnp.transpose(qt0, (0, 2, 1))\n",
    "print(qt0, qt0.shape)\n",
    "print(qt0_y2x, qt0_y2x.shape)\n",
    "print(qt0 == qt0_y2x)\n",
    "\n",
    "b = jnp.expand_dims(jnp.arange(xt.shape[0]), tuple(range(1, xt.ndim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.27067754 0.2431075  0.2431075  0.2431075 ]\n",
      "  [0.2431075  0.2706775  0.2431075  0.2431075 ]\n",
      "  [0.2431075  0.2431075  0.27067754 0.2431075 ]\n",
      "  [0.2431075  0.2431075  0.2431075  0.2706775 ]]\n",
      "\n",
      " [[0.27584603 0.24138466 0.24138464 0.24138466]\n",
      "  [0.24138466 0.27584606 0.24138466 0.24138466]\n",
      "  [0.24138464 0.24138466 0.27584603 0.24138466]\n",
      "  [0.24138466 0.24138466 0.24138466 0.27584606]]] (2, 4, 4)\n",
      "[[[[0.27067754 0.2431075  0.2431075  0.2431075 ]\n",
      "   [0.2431075  0.2706775  0.2431075  0.2431075 ]\n",
      "   [0.2431075  0.2431075  0.27067754 0.2431075 ]\n",
      "   [0.2431075  0.2431075  0.2431075  0.2706775 ]]]\n",
      "\n",
      "\n",
      " [[[0.27584603 0.24138466 0.24138464 0.24138466]\n",
      "   [0.24138466 0.27584606 0.24138466 0.24138466]\n",
      "   [0.24138464 0.24138466 0.27584603 0.24138466]\n",
      "   [0.24138466 0.24138466 0.24138466 0.27584606]]]] (2, 1, 4, 4)\n",
      "[[[0.97059214 0.00980262 0.00980264 0.00980261]\n",
      "  [0.00980263 0.9705922  0.00980261 0.00980261]\n",
      "  [0.00980264 0.00980259 0.97059214 0.00980263]\n",
      "  [0.00980264 0.00980258 0.00980263 0.97059214]]\n",
      "\n",
      " [[0.97059214 0.00980262 0.00980264 0.00980261]\n",
      "  [0.00980263 0.9705922  0.00980261 0.00980261]\n",
      "  [0.00980264 0.00980259 0.97059214 0.00980262]\n",
      "  [0.00980264 0.00980258 0.00980262 0.97059214]]] (2, 4, 4)\n",
      "[[[0.97059214 0.00980263 0.00980264 0.00980264]\n",
      "  [0.00980262 0.9705922  0.00980259 0.00980258]\n",
      "  [0.00980264 0.00980261 0.97059214 0.00980263]\n",
      "  [0.00980261 0.00980261 0.00980263 0.97059214]]\n",
      "\n",
      " [[0.97059214 0.00980263 0.00980264 0.00980264]\n",
      "  [0.00980262 0.9705922  0.00980259 0.00980258]\n",
      "  [0.00980264 0.00980261 0.97059214 0.00980262]\n",
      "  [0.00980261 0.00980261 0.00980262 0.97059214]]] (2, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "t = jax.random.uniform(t_rng, (B,))\n",
    "xt = jax.random.randint(sample_rng, shape=(B, D), minval=0, maxval=S, dtype=jnp.int32)\n",
    "t_eps = t - 0.01\n",
    "q_teps_0 = uni.transition(t_eps)\n",
    "print(q_teps_0, q_teps_0.shape)\n",
    "q_teps_0 = jnp.expand_dims(q_teps_0, axis=list(range(1, xt.ndim)))\n",
    "print(q_teps_0, q_teps_0.shape)\n",
    "q_t_teps = uni.transit_between(t_eps, t)\n",
    "print(q_t_teps, q_t_teps.shape)\n",
    "q_t_teps = jnp.transpose(q_t_teps, (0, 2, 1))\n",
    "print(q_t_teps, q_t_teps.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]] (2, 1)\n",
      "[[[[0.97059214 0.00980263 0.00980264 0.00980264]]\n",
      "\n",
      "  [[0.00980264 0.00980261 0.97059214 0.00980263]]\n",
      "\n",
      "  [[0.00980262 0.9705922  0.00980259 0.00980258]]\n",
      "\n",
      "  [[0.97059214 0.00980263 0.00980264 0.00980264]]]\n",
      "\n",
      "\n",
      " [[[0.00980262 0.9705922  0.00980259 0.00980258]]\n",
      "\n",
      "  [[0.00980264 0.00980261 0.97059214 0.00980262]]\n",
      "\n",
      "  [[0.00980264 0.00980261 0.97059214 0.00980262]]\n",
      "\n",
      "  [[0.97059214 0.00980263 0.00980264 0.00980264]]]] (2, 4, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "b = jnp.expand_dims(jnp.arange(xt.shape[0]), tuple(range(1, xt.ndim)))\n",
    "print(b, b.shape)\n",
    "q_t_teps = jnp.expand_dims(q_t_teps[b, xt], axis=-2)\n",
    "print(q_t_teps, q_t_teps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = qt0_y2x\n",
    "log_p0t = nn.log_softmax(logits, axis=-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_qt0 = jnp.where(qt0 <= 1e-35, -1e9, jnp.log(qt0))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_qt0 = jnp.expand_dims(log_qt0, axis=list(range(1, xt.ndim)))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_p0t = jnp.expand_dims(log_p0t, axis=-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_prob = jax.nn.logsumexp(log_p0t + log_qt0, axis=-2)\n",
    "print(log_prob, log_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt0 = uni.transition(t)\n",
    "xt_onehot = jax.nn.one_hot(xt, S)\n",
    "print(xt_onehot.shape)\n",
    "p0t = jax.nn.softmax(logits, axis=-1)\n",
    "print(p0t, p0t.shape)\n",
    "qt0 = jnp.expand_dims(qt0, axis=list(range(1, xt.ndim - 1)))\n",
    "print(qt0, qt0.shape)\n",
    "prob_all = p0t @ qt0\n",
    "print(prob_all.shape)\n",
    "log_prob = jnp.log(prob_all + 1e-35)\n",
    "print(log_prob, log_prob.shape)\n",
    "log_xt = jnp.sum(log_prob * xt_onehot, axis=-1)\n",
    "print(log_xt, log_xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = uni.transition(t)\n",
    "b = jnp.expand_dims(jnp.arange(B), tuple(range(1, xt.ndim)))\n",
    "qt0 = qt[b, xt]\n",
    "print(qt0, qt0.shape)\n",
    "logits = jnp.where(qt0 <= 0.0, -1e9, jnp.log(qt0))\n",
    "print(logits, logits.shape)\n",
    "xt = jax.random.categorical(sample_rng, logits)\n",
    "print(xt, xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits# B, D, S\n",
    "loss = -(\n",
    "    (S - 1) * ll_xt\n",
    "    + jnp.sum(utils.log1mexp(ll_all), axis=-1)\n",
    "    - utils.log1mexp(ll_xt)\n",
    ")\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits\n",
    "xt_onehot = jax.nn.one_hot(xt, S)\n",
    "b = jnp.expand_dims(jnp.arange(xt.shape[0]), tuple(range(1, xt.ndim)))\n",
    "print(b, b.shape)\n",
    "qt0_x2y = uni.transition(t)\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = jnp.transpose(qt0_x2y, (0, 2, 1))\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = qt0_y2x[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "ll_xt = jnp.expand_dims(ll_xt, axis=-1)\n",
    "print(\"ll\", ll_xt, ll_xt.shape)\n",
    "backwd = jnp.exp(ll_all - ll_xt) * qt0_y2x\n",
    "print(backwd , backwd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_term = jnp.sum(backwd * (1 - xt_onehot), axis=-1)\n",
    "print(first_term , first_term.shape)\n",
    "qt0_x2y = qt0_x2y[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "fwd = (ll_xt - ll_all) * qt0_x2y\n",
    "print(fwd, fwd.shape)\n",
    "second_term = jnp.sum(fwd * (1 - xt_onehot), axis=-1)\n",
    "print(second_term, second_term.shape)\n",
    "loss = first_term - second_term\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = jnp.ones((B, ))\n",
    "weight = jnp.expand_dims(weight, axis=list(range(1, loss.ndim)))\n",
    "print(weight, weight.shape)\n",
    "loss = loss * weight\n",
    "print(loss, loss.shape)\n",
    "loss = jnp.sum(loss) / xt.shape[0]\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main bottleneck is the design of the conditional marginal parameterization, which requires non-trivial trade-offs between computational cost \n",
    "and flexibility of the architectures; score matching for general categorical discrete variables does not benefit from prior knowledge about ordinal \n",
    "discrete data; and finally unifying score matching between continu- ous and discrete spaces would be needed to handle data in mixed spaces\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
