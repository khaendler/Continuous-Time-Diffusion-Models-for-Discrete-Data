{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from lib.models.forward_model import UniformForward\n",
    "from flax import linen as nn\n",
    "from lib.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 10) [[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]]\n",
      "(1, 10, 21) [[[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n",
      "(1, 1, 10, 21) [[[[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "idx = jnp.arange(seq_len, dtype=jnp.int32)\n",
    "att_l2r_mask = nn.attention.make_attention_mask(idx, idx, jnp.greater_equal)\n",
    "print(att_l2r_mask.shape, att_l2r_mask)\n",
    "att_r2l_mask = nn.attention.make_attention_mask(idx, idx, jnp.less_equal)\n",
    "att_t = jnp.ones((1, seq_len, 1))\n",
    "joint_mask = jnp.concatenate([att_t, att_l2r_mask, att_r2l_mask], axis=-1)\n",
    "print(joint_mask.shape, joint_mask)\n",
    "joint_mask = jnp.expand_dims(joint_mask, axis=0)\n",
    "print(joint_mask.shape, joint_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.arange(10, dtype=jnp.int32)\n",
    "np.expand_dims(jnp.arange(10, dtype=jnp.int32), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16477692 0.6628156  0.5799111  0.91668844 0.38052666 0.22999239\n",
      " 0.744532   0.703349   0.68598914 0.95723104 0.7563106  0.33415103\n",
      " 0.9805318  0.9204687  0.7621286  0.70780146 0.7601353  0.11362052\n",
      " 0.18291497 0.4065224  0.6326307  0.30837262 0.38905704 0.8518803\n",
      " 0.8026649  0.47867346 0.66204286 0.3761475  0.3353703  0.63315034\n",
      " 0.64062595 0.5985664  0.2490884  0.22583091 0.13790691 0.7293955\n",
      " 0.68318963 0.00314939 0.35922694 0.4672613  0.5603125  0.37063622\n",
      " 0.79032135 0.26515067 0.0705471  0.37446618 0.96311915 0.22508585\n",
      " 0.1628896  0.4007709  0.5419551  0.24647427 0.28652573 0.38016844\n",
      " 0.00712883 0.27092147 0.1842525  0.12204552 0.67230463 0.6193998\n",
      " 0.09896588 0.66243434 0.68301713 0.4518553  0.55643034 0.5431613\n",
      " 0.95571244 0.949721   0.42050564 0.06308067 0.95509624 0.07910037\n",
      " 0.9015987  0.32073045 0.11115897 0.09862614 0.7475505  0.08981788\n",
      " 0.00303638 0.4186268  0.48477638 0.48392737 0.43903816 0.24950516\n",
      " 0.39431524 0.24700534 0.1004256  0.58200276 0.773296   0.66488135\n",
      " 0.7496245  0.4725108  0.69212055 0.04417372 0.5241575  0.23448932\n",
      " 0.9703195  0.5359105  0.02418947 0.61016893 0.7662786  0.8541434\n",
      " 0.36751544 0.02572012 0.38819838 0.5967225  0.84766173 0.7691425\n",
      " 0.97174287 0.16846716 0.85489166 0.8970492  0.65379345 0.8089092\n",
      " 0.20342588 0.78020966 0.35577178 0.40023398 0.04404318 0.6493324\n",
      " 0.61076164 0.2039609  0.8073919  0.33518565 0.02521944 0.05753839\n",
      " 0.6642972  0.5293137  0.2622925  0.22685313 0.25691795 0.24762428\n",
      " 0.24290323 0.36987567 0.50650334 0.15290761 0.97779787 0.92912614\n",
      " 0.5797802  0.47077668 0.41893435 0.85581625 0.36437428 0.8940841\n",
      " 0.2645042  0.00933886 0.85642827 0.21110189 0.27195477 0.42252076\n",
      " 0.88671064 0.4322828  0.2815597  0.21132445 0.8895935  0.1417154\n",
      " 0.6912241  0.9662998  0.69147575 0.10954952 0.32696354 0.13149917\n",
      " 0.27473438 0.28459156 0.21059799 0.87862885 0.99200857 0.49684262\n",
      " 0.91123426 0.49159348 0.7148863  0.06066489 0.11627173 0.76757646\n",
      " 0.09335542 0.04593349 0.9791006  0.9479536  0.43391633 0.7734612\n",
      " 0.7541183  0.13969648 0.32151163 0.5413526  0.9767345  0.02406526\n",
      " 0.9986347  0.1915034  0.39313328 0.59991264 0.83468485 0.21975338\n",
      " 0.6708189  0.29871786 0.50269365 0.84953177 0.24331164 0.64148986\n",
      " 0.7433616  0.9888458  0.24552691 0.34598565 0.48383534 0.30207884\n",
      " 0.6182364  0.7957506  0.15057099 0.08761573 0.6054456  0.09822702\n",
      " 0.6696304  0.9653199  0.44336736 0.8984455  0.2994609  0.7315655\n",
      " 0.4670589  0.9683825  0.6264409  0.51188505 0.8487297  0.15202355\n",
      " 0.06016719 0.26406503 0.21009994 0.23805523 0.4971757  0.3908404\n",
      " 0.3379203  0.868883   0.2955588  0.2767614  0.5679294  0.14867735\n",
      " 0.33237088 0.31541657 0.79958427 0.83183193 0.8710989  0.8568809\n",
      " 0.16225219 0.7242105  0.26263237 0.32567346 0.51358163 0.62634575\n",
      " 0.8829547  0.16122091 0.84633076 0.95056546 0.31633484 0.31481946\n",
      " 0.3817618  0.8822732  0.47631466 0.27445292]\n",
      "[[[0.6379845  0.12067182 0.12067182 0.12067182]\n",
      "  [0.12067182 0.6379845  0.12067182 0.12067184]\n",
      "  [0.12067184 0.12067181 0.6379845  0.12067182]\n",
      "  [0.12067182 0.12067184 0.12067181 0.6379845 ]]\n",
      "\n",
      " [[0.30292156 0.23235948 0.23235948 0.23235948]\n",
      "  [0.23235948 0.30292156 0.23235948 0.23235947]\n",
      "  [0.23235948 0.23235948 0.30292156 0.23235948]\n",
      "  [0.23235948 0.23235947 0.23235948 0.30292156]]\n",
      "\n",
      " [[0.32373142 0.22542287 0.22542287 0.22542286]\n",
      "  [0.22542287 0.32373142 0.22542286 0.22542289]\n",
      "  [0.22542287 0.22542286 0.32373142 0.22542286]\n",
      "  [0.22542286 0.22542287 0.22542286 0.3237314 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.27199864 0.24266712 0.24266711 0.24266712]\n",
      "  [0.24266714 0.27199867 0.24266712 0.24266712]\n",
      "  [0.24266712 0.24266712 0.27199864 0.24266712]\n",
      "  [0.24266712 0.24266712 0.24266712 0.27199867]]\n",
      "\n",
      " [[0.36158812 0.21280396 0.21280396 0.21280396]\n",
      "  [0.21280396 0.36158812 0.21280396 0.21280394]\n",
      "  [0.21280394 0.21280396 0.36158812 0.21280396]\n",
      "  [0.21280396 0.21280394 0.21280396 0.36158812]]\n",
      "\n",
      " [[0.5002002  0.16659993 0.16659993 0.16659993]\n",
      "  [0.16659993 0.5002002  0.16659993 0.16659993]\n",
      "  [0.16659993 0.16659993 0.5002003  0.1665999 ]\n",
      "  [0.16659993 0.16659993 0.16659991 0.5002002 ]]] (256, 4, 4)\n",
      "[[[0.6379845  0.12067182 0.12067184 0.12067182]\n",
      "  [0.12067182 0.6379845  0.12067181 0.12067184]\n",
      "  [0.12067182 0.12067182 0.6379845  0.12067181]\n",
      "  [0.12067182 0.12067184 0.12067182 0.6379845 ]]\n",
      "\n",
      " [[0.30292156 0.23235948 0.23235948 0.23235948]\n",
      "  [0.23235948 0.30292156 0.23235948 0.23235947]\n",
      "  [0.23235948 0.23235948 0.30292156 0.23235948]\n",
      "  [0.23235948 0.23235947 0.23235948 0.30292156]]\n",
      "\n",
      " [[0.32373142 0.22542287 0.22542287 0.22542286]\n",
      "  [0.22542287 0.32373142 0.22542286 0.22542287]\n",
      "  [0.22542287 0.22542286 0.32373142 0.22542286]\n",
      "  [0.22542286 0.22542289 0.22542286 0.3237314 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.27199864 0.24266714 0.24266712 0.24266712]\n",
      "  [0.24266712 0.27199867 0.24266712 0.24266712]\n",
      "  [0.24266711 0.24266712 0.27199864 0.24266712]\n",
      "  [0.24266712 0.24266712 0.24266712 0.27199867]]\n",
      "\n",
      " [[0.36158812 0.21280396 0.21280394 0.21280396]\n",
      "  [0.21280396 0.36158812 0.21280396 0.21280394]\n",
      "  [0.21280396 0.21280396 0.36158812 0.21280396]\n",
      "  [0.21280396 0.21280394 0.21280396 0.36158812]]\n",
      "\n",
      " [[0.5002002  0.16659993 0.16659993 0.16659993]\n",
      "  [0.16659993 0.5002002  0.16659993 0.16659993]\n",
      "  [0.16659993 0.16659993 0.5002003  0.16659991]\n",
      "  [0.16659993 0.16659993 0.1665999  0.5002002 ]]] (256, 4, 4)\n",
      "[[[ True False False  True]\n",
      "  [False  True False  True]\n",
      "  [False False  True False]\n",
      "  [ True  True False  True]]\n",
      "\n",
      " [[ True  True  True  True]\n",
      "  [ True  True  True  True]\n",
      "  [ True  True  True  True]\n",
      "  [ True  True  True  True]]\n",
      "\n",
      " [[ True  True  True  True]\n",
      "  [ True  True  True False]\n",
      "  [ True  True  True  True]\n",
      "  [ True False  True  True]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ True False False  True]\n",
      "  [False  True  True  True]\n",
      "  [False  True  True  True]\n",
      "  [ True  True  True  True]]\n",
      "\n",
      " [[ True  True False  True]\n",
      "  [ True  True  True  True]\n",
      "  [False  True  True  True]\n",
      "  [ True  True  True  True]]\n",
      "\n",
      " [[ True  True  True  True]\n",
      "  [ True  True  True  True]\n",
      "  [ True  True  True False]\n",
      "  [ True  True False  True]]]\n"
     ]
    }
   ],
   "source": [
    "rate_const = 1\n",
    "S = 4\n",
    "B = 256\n",
    "D = 4\n",
    "uni = UniformForward(S, rate_const)\n",
    "\n",
    "rng = jax.random.PRNGKey(1008)\n",
    "t_rng, sample_rng = jax.random.split(rng)\n",
    "t = jax.random.uniform(t_rng, (B,))\n",
    "print(t)\n",
    "xt = jax.random.randint(sample_rng, shape=(B, D), minval=0, maxval=S, dtype=jnp.int32)\n",
    "qt0 = uni.transition(t)\n",
    "qt0_y2x = jnp.transpose(qt0, (0, 2, 1))\n",
    "print(qt0, qt0.shape)\n",
    "print(qt0_y2x, qt0_y2x.shape)\n",
    "print(qt0 == qt0_y2x)\n",
    "\n",
    "b = jnp.expand_dims(jnp.arange(xt.shape[0]), tuple(range(1, xt.ndim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10)\n",
      "(256, 1, 10)\n",
      "(256, 1, 10)\n",
      "cond_dim 1\n",
      "conc dim 1024\n",
      "pos (1, 5)\n",
      "conditioner (256, 1, 10)\n",
      "x (256, 1024, 10)\n",
      "[[[[1. 0. 0. 0. 0.]\n",
      "   [1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 0. 0.]\n",
      "   [1. 1. 1. 1. 0.]\n",
      "   [1. 1. 1. 1. 1.]]]] (1, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "x = jax.random.randint(sample_rng, shape=(B, 1024, 10), minval=0, maxval=S, dtype=jnp.int32)\n",
    "temb = jax.random.uniform(t_rng, (B,10))\n",
    "print(temb.shape)\n",
    "temb = jnp.expand_dims(temb, axis=1)\n",
    "print(temb.shape)\n",
    "conditioner = temb\n",
    "concat_dim = 5\n",
    "# conditioner = jnp.concatenate([conditioner, temb], axis=1)\n",
    "print(conditioner.shape)\n",
    "cond_dim = conditioner.shape[1]\n",
    "print(\"cond_dim\", cond_dim)\n",
    "concat_dim = x.shape[1] + cond_dim - 1\n",
    "print(\"conc dim\", concat_dim)\n",
    "concat_dim = 5\n",
    "pos_idx = jnp.expand_dims(jnp.arange(concat_dim, dtype=jnp.int32), 0)\n",
    "print(\"pos\", pos_idx.shape)\n",
    "x = jnp.concatenate([conditioner, x[:, :-1]], axis=1)\n",
    "print(\"conditioner\", conditioner.shape)\n",
    "print(\"x\", x.shape)\n",
    "mask = nn.attention.make_attention_mask(pos_idx, pos_idx,\n",
    "                                        jnp.greater_equal)\n",
    "#print(\"mask1\", mask, mask.shape)\n",
    "mask = mask.at[:, :, :cond_dim, :cond_dim].set(1.0)\n",
    "print(mask, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]]]]\n"
     ]
    }
   ],
   "source": [
    "x = jnp.concatenate([x[:, 1:], conditioner], axis=1)\n",
    "mask = nn.attention.make_attention_mask(pos_idx, pos_idx,\n",
    "                                        jnp.less_equal)\n",
    "mask = mask.at[:, :, -cond_dim:, -cond_dim:].set(1.0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.27067754 0.2431075  0.2431075  0.2431075 ]\n",
      "  [0.2431075  0.2706775  0.2431075  0.2431075 ]\n",
      "  [0.2431075  0.2431075  0.27067754 0.2431075 ]\n",
      "  [0.2431075  0.2431075  0.2431075  0.2706775 ]]\n",
      "\n",
      " [[0.27584603 0.24138466 0.24138464 0.24138466]\n",
      "  [0.24138466 0.27584606 0.24138466 0.24138466]\n",
      "  [0.24138464 0.24138466 0.27584603 0.24138466]\n",
      "  [0.24138466 0.24138466 0.24138466 0.27584606]]] (2, 4, 4)\n",
      "[[[[0.27067754 0.2431075  0.2431075  0.2431075 ]\n",
      "   [0.2431075  0.2706775  0.2431075  0.2431075 ]\n",
      "   [0.2431075  0.2431075  0.27067754 0.2431075 ]\n",
      "   [0.2431075  0.2431075  0.2431075  0.2706775 ]]]\n",
      "\n",
      "\n",
      " [[[0.27584603 0.24138466 0.24138464 0.24138466]\n",
      "   [0.24138466 0.27584606 0.24138466 0.24138466]\n",
      "   [0.24138464 0.24138466 0.27584603 0.24138466]\n",
      "   [0.24138466 0.24138466 0.24138466 0.27584606]]]] (2, 1, 4, 4)\n",
      "[[[0.97059214 0.00980262 0.00980264 0.00980261]\n",
      "  [0.00980263 0.9705922  0.00980261 0.00980261]\n",
      "  [0.00980264 0.00980259 0.97059214 0.00980263]\n",
      "  [0.00980264 0.00980258 0.00980263 0.97059214]]\n",
      "\n",
      " [[0.97059214 0.00980262 0.00980264 0.00980261]\n",
      "  [0.00980263 0.9705922  0.00980261 0.00980261]\n",
      "  [0.00980264 0.00980259 0.97059214 0.00980262]\n",
      "  [0.00980264 0.00980258 0.00980262 0.97059214]]] (2, 4, 4)\n",
      "[[[0.97059214 0.00980263 0.00980264 0.00980264]\n",
      "  [0.00980262 0.9705922  0.00980259 0.00980258]\n",
      "  [0.00980264 0.00980261 0.97059214 0.00980263]\n",
      "  [0.00980261 0.00980261 0.00980263 0.97059214]]\n",
      "\n",
      " [[0.97059214 0.00980263 0.00980264 0.00980264]\n",
      "  [0.00980262 0.9705922  0.00980259 0.00980258]\n",
      "  [0.00980264 0.00980261 0.97059214 0.00980262]\n",
      "  [0.00980261 0.00980261 0.00980262 0.97059214]]] (2, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "t = jax.random.uniform(t_rng, (B,))\n",
    "xt = jax.random.randint(sample_rng, shape=(B, D), minval=0, maxval=S, dtype=jnp.int32)\n",
    "t_eps = t - 0.01\n",
    "q_teps_0 = uni.transition(t_eps)\n",
    "print(q_teps_0, q_teps_0.shape)\n",
    "q_teps_0 = jnp.expand_dims(q_teps_0, axis=list(range(1, xt.ndim)))\n",
    "print(q_teps_0, q_teps_0.shape)\n",
    "q_t_teps = uni.transit_between(t_eps, t)\n",
    "print(q_t_teps, q_t_teps.shape)\n",
    "q_t_teps = jnp.transpose(q_t_teps, (0, 2, 1))\n",
    "print(q_t_teps, q_t_teps.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]] (2, 1)\n",
      "[[[[0.97059214 0.00980263 0.00980264 0.00980264]]\n",
      "\n",
      "  [[0.00980264 0.00980261 0.97059214 0.00980263]]\n",
      "\n",
      "  [[0.00980262 0.9705922  0.00980259 0.00980258]]\n",
      "\n",
      "  [[0.97059214 0.00980263 0.00980264 0.00980264]]]\n",
      "\n",
      "\n",
      " [[[0.00980262 0.9705922  0.00980259 0.00980258]]\n",
      "\n",
      "  [[0.00980264 0.00980261 0.97059214 0.00980262]]\n",
      "\n",
      "  [[0.00980264 0.00980261 0.97059214 0.00980262]]\n",
      "\n",
      "  [[0.97059214 0.00980263 0.00980264 0.00980264]]]] (2, 4, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "b = jnp.expand_dims(jnp.arange(xt.shape[0]), tuple(range(1, xt.ndim)))\n",
    "print(b, b.shape)\n",
    "q_t_teps = jnp.expand_dims(q_t_teps[b, xt], axis=-2)\n",
    "print(q_t_teps, q_t_teps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = qt0_y2x\n",
    "log_p0t = nn.log_softmax(logits, axis=-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_qt0 = jnp.where(qt0 <= 1e-35, -1e9, jnp.log(qt0))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_qt0 = jnp.expand_dims(log_qt0, axis=list(range(1, xt.ndim)))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_p0t = jnp.expand_dims(log_p0t, axis=-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_prob = jax.nn.logsumexp(log_p0t + log_qt0, axis=-2)\n",
    "print(log_prob, log_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt0 = uni.transition(t)\n",
    "xt_onehot = jax.nn.one_hot(xt, S)\n",
    "print(xt_onehot.shape)\n",
    "p0t = jax.nn.softmax(logits, axis=-1)\n",
    "print(p0t, p0t.shape)\n",
    "qt0 = jnp.expand_dims(qt0, axis=list(range(1, xt.ndim - 1)))\n",
    "print(qt0, qt0.shape)\n",
    "prob_all = p0t @ qt0\n",
    "print(prob_all.shape)\n",
    "log_prob = jnp.log(prob_all + 1e-35)\n",
    "print(log_prob, log_prob.shape)\n",
    "log_xt = jnp.sum(log_prob * xt_onehot, axis=-1)\n",
    "print(log_xt, log_xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = uni.transition(t)\n",
    "b = jnp.expand_dims(jnp.arange(B), tuple(range(1, xt.ndim)))\n",
    "qt0 = qt[b, xt]\n",
    "print(qt0, qt0.shape)\n",
    "logits = jnp.where(qt0 <= 0.0, -1e9, jnp.log(qt0))\n",
    "print(logits, logits.shape)\n",
    "xt = jax.random.categorical(sample_rng, logits)\n",
    "print(xt, xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits# B, D, S\n",
    "loss = -(\n",
    "    (S - 1) * ll_xt\n",
    "    + jnp.sum(utils.log1mexp(ll_all), axis=-1)\n",
    "    - utils.log1mexp(ll_xt)\n",
    ")\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits\n",
    "xt_onehot = jax.nn.one_hot(xt, S)\n",
    "b = jnp.expand_dims(jnp.arange(xt.shape[0]), tuple(range(1, xt.ndim)))\n",
    "print(b, b.shape)\n",
    "qt0_x2y = uni.transition(t)\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = jnp.transpose(qt0_x2y, (0, 2, 1))\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = qt0_y2x[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "ll_xt = jnp.expand_dims(ll_xt, axis=-1)\n",
    "print(\"ll\", ll_xt, ll_xt.shape)\n",
    "backwd = jnp.exp(ll_all - ll_xt) * qt0_y2x\n",
    "print(backwd , backwd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_term = jnp.sum(backwd * (1 - xt_onehot), axis=-1)\n",
    "print(first_term , first_term.shape)\n",
    "qt0_x2y = qt0_x2y[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "fwd = (ll_xt - ll_all) * qt0_x2y\n",
    "print(fwd, fwd.shape)\n",
    "second_term = jnp.sum(fwd * (1 - xt_onehot), axis=-1)\n",
    "print(second_term, second_term.shape)\n",
    "loss = first_term - second_term\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = jnp.ones((B, ))\n",
    "weight = jnp.expand_dims(weight, axis=list(range(1, loss.ndim)))\n",
    "print(weight, weight.shape)\n",
    "loss = loss * weight\n",
    "print(loss, loss.shape)\n",
    "loss = jnp.sum(loss) / xt.shape[0]\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main bottleneck is the design of the conditional marginal parameterization, which requires non-trivial trade-offs between computational cost \n",
    "and flexibility of the architectures; score matching for general categorical discrete variables does not benefit from prior knowledge about ordinal \n",
    "discrete data; and finally unifying score matching between continu- ous and discrete spaces would be needed to handle data in mixed spaces\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
