{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/lib/datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=160'>161</a>\u001b[0m     plt\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m     main()\n",
      "\u001b[1;32m/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m training_step \u001b[39m=\u001b[39m training_utils\u001b[39m.\u001b[39mget_train_step(cfg)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m sampler \u001b[39m=\u001b[39m sampling_utils\u001b[39m.\u001b[39mget_sampler(cfg)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m dataset \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39;49mget_dataset(cfg, device, dataset_location)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m     shuffle\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshuffle)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/train_nb.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInfo:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/lib/datasets/dataset_utils.py:11\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(cfg, device, root)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataset\u001b[39m(cfg, device, root\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m _DATASETS[cfg\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mname](cfg, device, root)\n",
      "File \u001b[0;32m~/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/lib/datasets/mnist.py:62\u001b[0m, in \u001b[0;36mDiscreteMNIST.__init__\u001b[0;34m(self, cfg, device, root)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, cfg, device, root\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 62\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root\u001b[39m=\u001b[39;49mroot, train\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mtrain, download\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mdownload)\n\u001b[1;32m     63\u001b[0m     \u001b[39m#self.data = torch.from_numpy(self.data) # (N, H, W, C)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m)\n",
      "File \u001b[0;32m~/my_python_env/lib/python3.11/site-packages/torchvision/datasets/mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/my_python_env/lib/python3.11/site-packages/torchvision/datasets/mnist.py:179\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[1;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_folder, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    181\u001b[0m \u001b[39m# download files\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mfor\u001b[39;00m filename, md5 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresources:\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/lib/datasets'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ml_collections\n",
    "import yaml\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from tqdm import tqdm\n",
    "#from config.mnist_config.config_bert_mnist import get_config\n",
    "from config.mnist_config.config_tauUnet_mnist import get_config\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "import os\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.mnist as mnist\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "import lib.sampling.sampling as sampling\n",
    "import lib.sampling.sampling_utils as sampling_utils\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import lib.sampling.sampling_utils as sampling_utils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_resume = False\n",
    "    script_dir = '/'\n",
    "    save_location = os.path.join(script_dir, 'SavedModels/MNIST/')\n",
    "    save_location_png = os.path.join(save_location, 'PNGs/')\n",
    "    dataset_location = os.path.join(script_dir, 'lib/datasets')\n",
    "\n",
    "    if not train_resume:\n",
    "        cfg = get_config()\n",
    "        #bookkeeping.save_config(cfg, save_location)\n",
    "\n",
    "    else:\n",
    "        date = \"2023-11-17\"\n",
    "        config_name = \"config_001_bert.yaml\"\n",
    "        config_path = os.path.join(save_location, date, config_name)\n",
    "        cfg = bookkeeping.load_config(config_path)\n",
    "\n",
    "    device = torch.device(cfg.device)\n",
    "\n",
    "    model = model_utils.create_model(cfg, device)\n",
    "\n",
    "    optimizer = optimizers_utils.get_optimizer(model.parameters(), cfg)\n",
    "\n",
    "    state = {\"model\": model, \"optimizer\": optimizer, \"n_iter\": 0}\n",
    "\n",
    "    if train_resume:\n",
    "        model_name = \"model_17999_bert.pt\"\n",
    "        checkpoint_path = os.path.join(save_location, date, model_name)\n",
    "        state = bookkeeping.load_state(state, checkpoint_path)\n",
    "        cfg.training.n_iters = 30000 \n",
    "        cfg.sampler.sample_freq = 100000000\n",
    "        cfg.saving.checkpoint_freq = 2000\n",
    "        cfg.sampler.num_steps = 1000\n",
    "        bookkeeping.save_config(cfg, save_location)\n",
    "    \n",
    "    loss = losses_utils.get_loss(cfg)\n",
    "\n",
    "    training_step = training_utils.get_train_step(cfg)\n",
    "\n",
    "    sampler = sampling_utils.get_sampler(cfg)\n",
    "\n",
    "    dataset = dataset_utils.get_dataset(cfg, device, dataset_location)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,\n",
    "        batch_size=cfg.data.batch_size,\n",
    "        shuffle=cfg.data.shuffle)\n",
    "    \n",
    "    print(\"Info:\")\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"State Iter:\", state[\"n_iter\"])\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"Name Dataset:\", cfg.data.name)\n",
    "    print(\"Loss Name:\", cfg.loss.name)\n",
    "    #print(\"Loss Type: None\" if cfg.loss.name == \"GenericAux\" else f\"Loss Type: {cfg.loss.loss_type}\")\n",
    "    #print(\"Logit Type:\", cfg.loss.logit_type)\n",
    "    #print(\"Ce_coeff: None\" if cfg.loss.name == \"GenericAux\" else f\"Ce_Coeff: {cfg.loss.ce_coeff}\")\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"Model Name:\", cfg.model.name)\n",
    "    print(\"Number of Parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "    #print(\"Net Arch:\", cfg.model.net_arch)\n",
    "    #print(\"Bidir Readout:None\" if cfg.loss.name == \"GenericAux\" else f\"Loss Type: {cfg.model.bidir_readout}\")\n",
    "    print(\"Sampler:\", cfg.sampler.name)\n",
    "\n",
    "    n_samples = 16\n",
    "\n",
    "    print(\"cfg.saving.checkpoint_freq\", cfg.saving.checkpoint_freq)\n",
    "    training_loss = []\n",
    "    exit_flag = False\n",
    "    while True:\n",
    "        for minibatch in tqdm(dataloader):\n",
    "            minibatch = minibatch.to(device)\n",
    "            l = training_step.step(state, minibatch, loss)\n",
    "\n",
    "            training_loss.append(l.item())\n",
    "\n",
    "            if (state[\"n_iter\"] + 1) % cfg.saving.checkpoint_freq == 0 or state[\n",
    "                \"n_iter\"\n",
    "            ] == cfg.training.n_iters - 1:\n",
    "                bookkeeping.save_state(state, save_location)\n",
    "                saving_train_path = os.path.join(\n",
    "                    save_location_png, f\"loss_{cfg.loss.name}{state['n_iter']}.png\"\n",
    "                )\n",
    "                plt.plot(training_loss)\n",
    "                plt.xlabel('Iterations')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.title(\"Training loss\")\n",
    "                plt.savefig(saving_train_path)\n",
    "                plt.close()\n",
    "                print(\"Model saved in Iteration:\", state[\"n_iter\"] + 1)\n",
    "\n",
    "            if (state[\"n_iter\"] + 1) % cfg.sampler.sample_freq == 0 or state[\n",
    "                \"n_iter\"\n",
    "            ] == cfg.training.n_iters - 1:\n",
    "                state[\"model\"].eval()\n",
    "                samples = sampler.sample(state[\"model\"], n_samples, 10)\n",
    "                samples = samples.reshape(\n",
    "                    n_samples, 1, cfg.data.image_size, cfg.data.image_size\n",
    "                )\n",
    "\n",
    "                state[\"model\"].train()\n",
    "\n",
    "                fig = plt.figure(figsize=(9, 9))\n",
    "                for i in range(n_samples):\n",
    "                    plt.subplot(4, 4, 1 + i)\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.imshow(np.transpose(samples[i, ...], (1, 2, 0)), cmap=\"gray\")\n",
    "\n",
    "                saving_plot_path = os.path.join(\n",
    "                    save_location_png, f\"{cfg.loss.name}{state['n_iter']}_{cfg.sampler.name}{cfg.sampler.num_steps}.png\"\n",
    "                )\n",
    "                print(saving_plot_path)\n",
    "                plt.savefig(saving_plot_path)\n",
    "                plt.close()\n",
    "\n",
    "            state[\"n_iter\"] += 1\n",
    "            if state[\"n_iter\"] > cfg.training.n_iters - 1:\n",
    "                exit_flag = True\n",
    "                break\n",
    "\n",
    "        if exit_flag:\n",
    "            break\n",
    "\n",
    "    saving_train_path = os.path.join(\n",
    "        save_location_png, f\"loss_{cfg.loss.name}{state['n_iter']}.png\"\n",
    "    )\n",
    "    plt.plot(training_loss)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.savefig(saving_train_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
