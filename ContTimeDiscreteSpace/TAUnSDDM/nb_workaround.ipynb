{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNow, when we minimize LCT, we are sampling (x, x ̃) from the forward process and then maximizing the assigned model probability for \\n\\nthe pairing in the reverse direction, just as in LDT. The slight extra complexity comes from the fact we areconsidering the case \\n\\nwhen xk = xk+1 and the case when xk ̸= xk+1 separately. When xk = xk+1, this corresponds to the first term in LCT which we can see \\n\\nis minimizing the reverse rate out of x which is exactly maximizing the model probability for no transition to occur. When xk ̸= xk+1, \\n\\nthis corresponds to the second term in LCT, which is maximizing the reverse rate from x ̃ to x which in turn maximizes the model probability \\n\\nfor the x ̃ to x transition to occur.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from lib.models.models import UniformRate, UniformVariantRate\n",
    "import ml_collections\n",
    "from config.config_hollow import get_config\n",
    "from lib.utils import utils\n",
    "import torch.nn.functional as F\n",
    "from lib.networks.networks_paul import UNet\n",
    "from lib.networks.hollow_networks import BidirectionalTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "from lib.datasets.datasets import (\n",
    "    create_train_discrete_mnist_dataloader,\n",
    "    get_binmnist_datasets,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "Now, when we minimize LCT, we are sampling (x, x ̃) from the forward process and then maximizing the assigned model probability for \n",
    "\n",
    "the pairing in the reverse direction, just as in LDT. The slight extra complexity comes from the fact we areconsidering the case \n",
    "\n",
    "when xk = xk+1 and the case when xk ̸= xk+1 separately. When xk = xk+1, this corresponds to the first term in LCT which we can see \n",
    "\n",
    "is minimizing the reverse rate out of x which is exactly maximizing the model probability for no transition to occur. When xk ̸= xk+1, \n",
    "\n",
    "this corresponds to the second term in LCT, which is maximizing the reverse rate from x ̃ to x which in turn maximizes the model probability \n",
    "\n",
    "for the x ̃ to x transition to occur.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2947, 0.2942, 0.3251])\n"
     ]
    }
   ],
   "source": [
    "ts = torch.rand((3,), device='cpu') * (1.0 - 0.01) + 0.01\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1 * torch.ones((4, ))\n",
    "cosi = -torch.sqrt(torch.cos(torch.pi / 2 * t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg =  get_config()\n",
    "cfg.model.t_func = \"log_sqr\"\n",
    "cfg.model.rate_const = 0.01\n",
    "dataloader = create_train_discrete_mnist_dataloader(\n",
    "        batch_size=cfg.data.batch_size, image_size=cfg.data.image_size, use_augmentation=cfg.data.use_augm\n",
    "    )\n",
    "#train_set, _, _ = get_binmnist_datasets('/Users/paulheller/PythonRepositories/Master-Thesis/ContTimeDiscreteSpace/TAUnSDDM/lib/datasets/', device=\"cpu\")\n",
    "#dataloader = DataLoader(train_set, batch_size=cfg.data.batch_size, shuffle=True, num_workers=4)\n",
    "model = UniformRate(cfg, 'cpu')\n",
    "#model = UniformVariantRate(cfg, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_batch(batch, save_path=None):\n",
    "    \"\"\"Plottet ein Batch von MNIST-Bildern.\"\"\"\n",
    "    num_images = batch.shape[0]\n",
    "    sqrt_num_images = int(np.sqrt(num_images))\n",
    "\n",
    "    fig, axes = plt.subplots(sqrt_num_images, sqrt_num_images, figsize=(8, 8))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = batch[i].squeeze()\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.axis(\"off\") \n",
    "\n",
    "    plt.tight_layout() \n",
    "    #plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(124.2143)\n",
      "Mean: tensor(124.2143)\n",
      "Std: tensor(79.6786)\n",
      "tensor(122.0179)\n",
      "Mean: tensor(123.1161)\n",
      "Std: tensor(79.3374)\n",
      "tensor(117.2806)\n",
      "Mean: tensor(121.1709)\n",
      "Std: tensor(79.3426)\n",
      "tensor(122.1977)\n",
      "Mean: tensor(121.4276)\n",
      "Std: tensor(78.3450)\n",
      "tensor(117.2347)\n",
      "Mean: tensor(120.5890)\n",
      "Std: tensor(78.3847)\n",
      "tensor(121.1531)\n",
      "Mean: tensor(120.6830)\n",
      "Std: tensor(78.6649)\n",
      "tensor(124.5855)\n",
      "Mean: tensor(121.2405)\n",
      "Std: tensor(78.6513)\n",
      "tensor(124.6709)\n",
      "Mean: tensor(121.6693)\n",
      "Std: tensor(78.8410)\n",
      "tensor(118.4286)\n",
      "Mean: tensor(121.3092)\n",
      "Std: tensor(78.7591)\n",
      "tensor(122.2959)\n",
      "Mean: tensor(121.4079)\n",
      "Std: tensor(78.7721)\n",
      "tensor(121.0829)\n",
      "Mean: tensor(121.3783)\n",
      "Std: tensor(78.6564)\n",
      "tensor(119.1658)\n",
      "Mean: tensor(121.1940)\n",
      "Std: tensor(78.5637)\n",
      "tensor(125.3597)\n",
      "Mean: tensor(121.5144)\n",
      "Std: tensor(78.6816)\n",
      "tensor(113.4018)\n",
      "Mean: tensor(120.9349)\n",
      "Std: tensor(78.6371)\n",
      "tensor(123.9069)\n",
      "Mean: tensor(121.1331)\n",
      "Std: tensor(78.6616)\n",
      "tensor(118.9936)\n",
      "Mean: tensor(120.9994)\n",
      "Std: tensor(78.6999)\n",
      "tensor(119.9400)\n",
      "Mean: tensor(120.9370)\n",
      "Std: tensor(78.5603)\n",
      "tensor(121.4617)\n",
      "Mean: tensor(120.9662)\n",
      "Std: tensor(78.5619)\n",
      "tensor(120.3469)\n",
      "Mean: tensor(120.9336)\n",
      "Std: tensor(78.5661)\n",
      "tensor(124.0268)\n",
      "Mean: tensor(121.0883)\n",
      "Std: tensor(78.5053)\n",
      "tensor(119.7513)\n",
      "Mean: tensor(121.0246)\n",
      "Std: tensor(78.4342)\n",
      "tensor(120.1365)\n",
      "Mean: tensor(120.9842)\n",
      "Std: tensor(78.4084)\n",
      "tensor(121.6173)\n",
      "Mean: tensor(121.0117)\n",
      "Std: tensor(78.3991)\n",
      "tensor(117.2832)\n",
      "Mean: tensor(120.8564)\n",
      "Std: tensor(78.2786)\n",
      "tensor(122.1327)\n",
      "Mean: tensor(120.9074)\n",
      "Std: tensor(78.1995)\n",
      "tensor(122.7372)\n",
      "Mean: tensor(120.9778)\n",
      "Std: tensor(78.2073)\n",
      "tensor(123.3278)\n",
      "Mean: tensor(121.0649)\n",
      "Std: tensor(78.2255)\n",
      "tensor(119.9936)\n",
      "Mean: tensor(121.0266)\n",
      "Std: tensor(78.2537)\n",
      "tensor(116.8967)\n",
      "Mean: tensor(120.8842)\n",
      "Std: tensor(78.2823)\n",
      "tensor(117.6556)\n",
      "Mean: tensor(120.7766)\n",
      "Std: tensor(78.3020)\n",
      "tensor(120.5395)\n",
      "Mean: tensor(120.7689)\n",
      "Std: tensor(78.3229)\n",
      "tensor(116.4273)\n",
      "Mean: tensor(120.6332)\n",
      "Std: tensor(78.3228)\n",
      "tensor(125.1633)\n",
      "Mean: tensor(120.7705)\n",
      "Std: tensor(78.3459)\n",
      "tensor(121.1429)\n",
      "Mean: tensor(120.7815)\n",
      "Std: tensor(78.3025)\n",
      "tensor(121.6059)\n",
      "Mean: tensor(120.8050)\n",
      "Std: tensor(78.2359)\n",
      "tensor(118.9796)\n",
      "Mean: tensor(120.7543)\n",
      "Std: tensor(78.3016)\n",
      "tensor(126.5510)\n",
      "Mean: tensor(120.9110)\n",
      "Std: tensor(78.3169)\n",
      "tensor(121.2296)\n",
      "Mean: tensor(120.9194)\n",
      "Std: tensor(78.3070)\n",
      "tensor(121.8023)\n",
      "Mean: tensor(120.9420)\n",
      "Std: tensor(78.3032)\n",
      "tensor(117.8635)\n",
      "Mean: tensor(120.8650)\n",
      "Std: tensor(78.3025)\n",
      "tensor(116.2436)\n",
      "Mean: tensor(120.7523)\n",
      "Std: tensor(78.3192)\n",
      "tensor(119.0727)\n",
      "Mean: tensor(120.7123)\n",
      "Std: tensor(78.3336)\n",
      "tensor(124.8571)\n",
      "Mean: tensor(120.8087)\n",
      "Std: tensor(78.3262)\n",
      "tensor(122.4668)\n",
      "Mean: tensor(120.8464)\n",
      "Std: tensor(78.3069)\n",
      "tensor(117.2730)\n",
      "Mean: tensor(120.7670)\n",
      "Std: tensor(78.2857)\n",
      "tensor(125.9796)\n",
      "Mean: tensor(120.8803)\n",
      "Std: tensor(78.3218)\n",
      "tensor(122.6275)\n",
      "Mean: tensor(120.9175)\n",
      "Std: tensor(78.3587)\n",
      "tensor(119.9043)\n",
      "Mean: tensor(120.8964)\n",
      "Std: tensor(78.3148)\n",
      "tensor(118.5395)\n",
      "Mean: tensor(120.8483)\n",
      "Std: tensor(78.3241)\n",
      "tensor(121.1301)\n",
      "Mean: tensor(120.8539)\n",
      "Std: tensor(78.3179)\n",
      "tensor(120.3533)\n",
      "Mean: tensor(120.8441)\n",
      "Std: tensor(78.3175)\n",
      "tensor(123.5025)\n",
      "Mean: tensor(120.8952)\n",
      "Std: tensor(78.2953)\n",
      "tensor(120.9158)\n",
      "Mean: tensor(120.8956)\n",
      "Std: tensor(78.3061)\n",
      "tensor(116.5179)\n",
      "Mean: tensor(120.8145)\n",
      "Std: tensor(78.3302)\n",
      "tensor(121.3393)\n",
      "Mean: tensor(120.8241)\n",
      "Std: tensor(78.3451)\n",
      "tensor(118.8610)\n",
      "Mean: tensor(120.7890)\n",
      "Std: tensor(78.3442)\n",
      "tensor(117.1952)\n",
      "Mean: tensor(120.7260)\n",
      "Std: tensor(78.3458)\n",
      "tensor(121.2309)\n",
      "Mean: tensor(120.7347)\n",
      "Std: tensor(78.3649)\n",
      "tensor(119.0906)\n",
      "Mean: tensor(120.7068)\n",
      "Std: tensor(78.3503)\n",
      "tensor(123.6952)\n",
      "Mean: tensor(120.7566)\n",
      "Std: tensor(78.3707)\n",
      "tensor(121.9490)\n",
      "Mean: tensor(120.7762)\n",
      "Std: tensor(78.4024)\n",
      "tensor(122.9962)\n",
      "Mean: tensor(120.8120)\n",
      "Std: tensor(78.4037)\n",
      "tensor(122.5204)\n",
      "Mean: tensor(120.8391)\n",
      "Std: tensor(78.4323)\n",
      "tensor(122.5548)\n",
      "Mean: tensor(120.8659)\n",
      "Std: tensor(78.4436)\n",
      "tensor(120.1454)\n",
      "Mean: tensor(120.8548)\n",
      "Std: tensor(78.4467)\n",
      "tensor(118.8546)\n",
      "Mean: tensor(120.8245)\n",
      "Std: tensor(78.4181)\n",
      "tensor(120.5025)\n",
      "Mean: tensor(120.8197)\n",
      "Std: tensor(78.4087)\n",
      "tensor(115.7194)\n",
      "Mean: tensor(120.7447)\n",
      "Std: tensor(78.4090)\n",
      "tensor(116.0077)\n",
      "Mean: tensor(120.6760)\n",
      "Std: tensor(78.4054)\n",
      "tensor(121.4362)\n",
      "Mean: tensor(120.6869)\n",
      "Std: tensor(78.3768)\n",
      "tensor(121.7895)\n",
      "Mean: tensor(120.7024)\n",
      "Std: tensor(78.3710)\n",
      "tensor(119.8814)\n",
      "Mean: tensor(120.6910)\n",
      "Std: tensor(78.3784)\n",
      "tensor(120.7309)\n",
      "Mean: tensor(120.6916)\n",
      "Std: tensor(78.3999)\n",
      "tensor(123.2462)\n",
      "Mean: tensor(120.7261)\n",
      "Std: tensor(78.3967)\n",
      "tensor(123.6084)\n",
      "Mean: tensor(120.7645)\n",
      "Std: tensor(78.3868)\n",
      "tensor(125.3036)\n",
      "Mean: tensor(120.8243)\n",
      "Std: tensor(78.3850)\n",
      "tensor(120.8265)\n",
      "Mean: tensor(120.8243)\n",
      "Std: tensor(78.3795)\n",
      "tensor(117.3380)\n",
      "Mean: tensor(120.7796)\n",
      "Std: tensor(78.3848)\n",
      "tensor(124.2436)\n",
      "Mean: tensor(120.8234)\n",
      "Std: tensor(78.3979)\n",
      "tensor(123.9158)\n",
      "Mean: tensor(120.8621)\n",
      "Std: tensor(78.3789)\n",
      "tensor(115.3954)\n",
      "Mean: tensor(120.7946)\n",
      "Std: tensor(78.3976)\n",
      "tensor(124.3304)\n",
      "Mean: tensor(120.8377)\n",
      "Std: tensor(78.3953)\n",
      "tensor(119.1684)\n",
      "Mean: tensor(120.8176)\n",
      "Std: tensor(78.4013)\n",
      "tensor(120.7423)\n",
      "Mean: tensor(120.8167)\n",
      "Std: tensor(78.4197)\n",
      "tensor(116.7181)\n",
      "Mean: tensor(120.7685)\n",
      "Std: tensor(78.4226)\n",
      "tensor(121.7334)\n",
      "Mean: tensor(120.7797)\n",
      "Std: tensor(78.4100)\n",
      "tensor(120.6531)\n",
      "Mean: tensor(120.7782)\n",
      "Std: tensor(78.3857)\n",
      "tensor(123.6467)\n",
      "Mean: tensor(120.8108)\n",
      "Std: tensor(78.4069)\n",
      "tensor(117.4171)\n",
      "Mean: tensor(120.7727)\n",
      "Std: tensor(78.3677)\n",
      "tensor(119.4490)\n",
      "Mean: tensor(120.7580)\n",
      "Std: tensor(78.3936)\n",
      "tensor(125.9375)\n",
      "Mean: tensor(120.8149)\n",
      "Std: tensor(78.3989)\n",
      "tensor(121.8699)\n",
      "Mean: tensor(120.8264)\n",
      "Std: tensor(78.4158)\n",
      "tensor(125.5383)\n",
      "Mean: tensor(120.8770)\n",
      "Std: tensor(78.4171)\n",
      "tensor(123.6696)\n",
      "Mean: tensor(120.9068)\n",
      "Std: tensor(78.4219)\n",
      "tensor(120.2513)\n",
      "Mean: tensor(120.8999)\n",
      "Std: tensor(78.4350)\n",
      "tensor(119.2870)\n",
      "Mean: tensor(120.8831)\n",
      "Std: tensor(78.4217)\n",
      "tensor(120.9770)\n",
      "Mean: tensor(120.8840)\n",
      "Std: tensor(78.4218)\n",
      "tensor(121.6020)\n",
      "Mean: tensor(120.8913)\n",
      "Std: tensor(78.4028)\n",
      "tensor(121.8482)\n",
      "Mean: tensor(120.9010)\n",
      "Std: tensor(78.3989)\n",
      "tensor(121.7156)\n",
      "Mean: tensor(120.9092)\n",
      "Std: tensor(78.4178)\n",
      "tensor(117.8316)\n",
      "Mean: tensor(120.8787)\n",
      "Std: tensor(78.4324)\n",
      "tensor(118.4311)\n",
      "Mean: tensor(120.8547)\n",
      "Std: tensor(78.4350)\n",
      "tensor(120.0038)\n",
      "Mean: tensor(120.8464)\n",
      "Std: tensor(78.4299)\n",
      "tensor(127.4286)\n",
      "Mean: tensor(120.9097)\n",
      "Std: tensor(78.4420)\n",
      "tensor(111.6645)\n",
      "Mean: tensor(120.8217)\n",
      "Std: tensor(78.4381)\n",
      "tensor(118.4222)\n",
      "Mean: tensor(120.7990)\n",
      "Std: tensor(78.4405)\n",
      "tensor(123.8342)\n",
      "Mean: tensor(120.8274)\n",
      "Std: tensor(78.4456)\n",
      "tensor(120.9260)\n",
      "Mean: tensor(120.8283)\n",
      "Std: tensor(78.4364)\n",
      "tensor(116.8610)\n",
      "Mean: tensor(120.7919)\n",
      "Std: tensor(78.4164)\n",
      "tensor(116.9515)\n",
      "Mean: tensor(120.7570)\n",
      "Std: tensor(78.4275)\n",
      "tensor(121.7283)\n",
      "Mean: tensor(120.7657)\n",
      "Std: tensor(78.4229)\n",
      "tensor(117.0383)\n",
      "Mean: tensor(120.7325)\n",
      "Std: tensor(78.4276)\n",
      "tensor(119.0753)\n",
      "Mean: tensor(120.7178)\n",
      "Std: tensor(78.4275)\n",
      "tensor(119.3380)\n",
      "Mean: tensor(120.7057)\n",
      "Std: tensor(78.4201)\n",
      "tensor(118.2819)\n",
      "Mean: tensor(120.6846)\n",
      "Std: tensor(78.4277)\n",
      "tensor(120.6990)\n",
      "Mean: tensor(120.6847)\n",
      "Std: tensor(78.4197)\n",
      "tensor(119.3622)\n",
      "Mean: tensor(120.6734)\n",
      "Std: tensor(78.4263)\n",
      "tensor(122.4133)\n",
      "Mean: tensor(120.6882)\n",
      "Std: tensor(78.4415)\n",
      "tensor(118.3622)\n",
      "Mean: tensor(120.6686)\n",
      "Std: tensor(78.4329)\n",
      "tensor(120.7232)\n",
      "Mean: tensor(120.6691)\n",
      "Std: tensor(78.4433)\n",
      "tensor(123.9043)\n",
      "Mean: tensor(120.6958)\n",
      "Std: tensor(78.4436)\n",
      "tensor(117.2806)\n",
      "Mean: tensor(120.6678)\n",
      "Std: tensor(78.4329)\n",
      "tensor(117.4745)\n",
      "Mean: tensor(120.6419)\n",
      "Std: tensor(78.4483)\n",
      "tensor(120.1811)\n",
      "Mean: tensor(120.6382)\n",
      "Std: tensor(78.4576)\n",
      "tensor(124.8967)\n",
      "Mean: tensor(120.6722)\n",
      "Std: tensor(78.4723)\n",
      "tensor(121.9668)\n",
      "Mean: tensor(120.6825)\n",
      "Std: tensor(78.4561)\n",
      "tensor(124.4847)\n",
      "Mean: tensor(120.7124)\n",
      "Std: tensor(78.4668)\n",
      "tensor(116.3240)\n",
      "Mean: tensor(120.6782)\n",
      "Std: tensor(78.4583)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# log loss\u001b[39;00m\n\u001b[1;32m     21\u001b[0m log_qt0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(qt0 \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1e9\u001b[39m, torch\u001b[39m.\u001b[39mlog(qt0))\n\u001b[0;32m---> 22\u001b[0m xt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mdistributions\u001b[39m.\u001b[39;49mcategorical\u001b[39m.\u001b[39;49mCategorical(logits\u001b[39m=\u001b[39;49mlog_qt0)\u001b[39m.\u001b[39msample()\n\u001b[1;32m     23\u001b[0m \u001b[39m#print(type(xt))\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mmean(xt[\u001b[39m0\u001b[39m,:]\u001b[39m.\u001b[39mfloat()))\n",
      "File \u001b[0;32m~/PythonRepositories/Master-Thesis/diffvenv/lib/python3.10/site-packages/torch/distributions/categorical.py:62\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`logits` parameter must be at least one-dimensional.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Normalize\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits \u001b[39m=\u001b[39m logits \u001b[39m-\u001b[39m logits\u001b[39m.\u001b[39;49mlogsumexp(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdim\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobs \u001b[39mif\u001b[39;00m probs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits\n\u001b[1;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_events \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "x_mean = 0 # 127.5\n",
    "x_std = 0 # 73.7\n",
    "\n",
    "for minibatch, _ in dataloader:\n",
    "    \n",
    "    B, C, H, W = minibatch.shape\n",
    "    minibatch = minibatch.view(B, C * H * W) \n",
    "    # hollow xt, t, l_all, l_xt geht rein\n",
    "    device = cfg.device\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.0\n",
    "    ts = torch.ones((B, )) \n",
    "    qt0 = model.transition(ts)  # (B, S, S)\n",
    "\n",
    "    # rate = model.rate(ts)  # (B, S, S)\n",
    "\n",
    "    b = utils.expand_dims(torch.arange(B), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "\n",
    "    # log loss\n",
    "    log_qt0 = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0))\n",
    "    xt = torch.distributions.categorical.Categorical(logits=log_qt0).sample()\n",
    "    #print(type(xt))\n",
    "\n",
    "    print(torch.mean(xt[0,:].float()))\n",
    "    x_mean +=torch.mean(xt[0,:].float())\n",
    "    x_std += torch.std(xt[0,:].float())\n",
    "    i = i+1\n",
    "    print(\"Mean:\", x_mean / i)\n",
    "    print(\"Std:\", x_std / i)\n",
    "    if i == 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall tensor(129.9031)\n",
      "overall tensor(129.8731)\n",
      "overall tensor(129.4154)\n",
      "overall tensor(127.7149)\n",
      "overall tensor(127.5316)\n",
      "overall tensor(127.7532)\n",
      "overall tensor(127.4016)\n",
      "overall tensor(127.5756)\n",
      "overall tensor(128.0835)\n",
      "overall tensor(128.1330)\n",
      "overall tensor(127.8340)\n",
      "overall tensor(127.8485)\n",
      "overall tensor(127.5180)\n",
      "overall tensor(127.5259)\n",
      "overall tensor(127.7029)\n",
      "overall tensor(127.6688)\n",
      "overall tensor(127.5735)\n",
      "overall tensor(127.5109)\n",
      "overall tensor(127.5726)\n",
      "overall tensor(127.6734)\n",
      "overall tensor(127.7119)\n",
      "overall tensor(127.7330)\n",
      "overall tensor(127.8131)\n",
      "overall tensor(127.9375)\n",
      "overall tensor(127.6839)\n",
      "overall tensor(127.6849)\n",
      "overall tensor(127.8428)\n",
      "overall tensor(127.6692)\n",
      "overall tensor(127.8840)\n",
      "overall tensor(127.9300)\n",
      "overall tensor(127.8764)\n",
      "overall tensor(127.9904)\n",
      "overall tensor(128.0751)\n",
      "overall tensor(128.0299)\n",
      "overall tensor(128.0891)\n",
      "overall tensor(128.1724)\n",
      "overall tensor(128.0675)\n",
      "overall tensor(128.0328)\n",
      "overall tensor(128.0071)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39m# get random timestep between 1.0 and self.min_time\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     ts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((B,), device\u001b[39m=\u001b[39mdevice) \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.01\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[0;32m---> 14\u001b[0m     qt0 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtransition(\n\u001b[1;32m     15\u001b[0m ts\n\u001b[1;32m     16\u001b[0m     )  \u001b[39m# (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m# R_t = beta_t * R_b\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     rate \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mrate(\n\u001b[1;32m     20\u001b[0m ts\n\u001b[1;32m     21\u001b[0m     )  \u001b[39m# (B, S, S) # no proability in here (diagonal = - sum of rows)\u001b[39;00m\n",
      "File \u001b[0;32m~/PythonRepositories/Master-Thesis/ContTimeDiscreteSpace/TAUnSDDM/lib/models/models.py:325\u001b[0m, in \u001b[0;36mUniformRate.transition\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    316\u001b[0m S \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mS\n\u001b[1;32m    317\u001b[0m transitions \u001b[39m=\u001b[39m (\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meigvecs\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, S, S)  \u001b[39m# Q\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39m@\u001b[39m torch\u001b[39m.\u001b[39mdiag_embed(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meigvecs\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, S, S)  \u001b[39m# Q^-1\u001b[39;00m\n\u001b[1;32m    323\u001b[0m )\n\u001b[0;32m--> 325\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49mmin(transitions) \u001b[39m<\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1e-6\u001b[39m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    327\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Warning] UniformRate, large negative transition values \u001b[39m\u001b[39m{\u001b[39;00mtorch\u001b[39m.\u001b[39mmin(transitions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m transitions[transitions \u001b[39m<\u001b[39m \u001b[39m1e-8\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "        # if 4 Dim => like images: True\n",
    "i = 0\n",
    "x_mean_t = 0\n",
    "for minibatch, _ in dataloader:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    minibatch = minibatch.view(B, C * H * W)\n",
    "\n",
    "    B, D = minibatch.shape\n",
    "    device = model.device\n",
    "\n",
    "    # get random timestep between 1.0 and self.min_time\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "    # --------------- Sampling x_t, x_tilde --------------------\n",
    "    # qt0_rows_reg = (B * D, S) probability distribution\n",
    "    # diagonal elements of qt0 (higher probability) will be put at column of value of x_t\n",
    "    # we do this because then we sample from qt0_rows_reg and then it is most likely more similar to x0=batch\n",
    "    # example: q_t0 =   [0.4079, 0.2961, 0.2961],\n",
    "    #                   [0.2961, 0.4079, 0.2961],\n",
    "    #                   [0.2961, 0.2961, 0.4079]],\n",
    "    # batch = (2, 0, 1)\n",
    "    # qt0_rows_reg = [0.2961, 0.2961, 0.4079],\n",
    "    #                [0.4079, 0.2961, 0.4079],\n",
    "    #                [0.2961, 0.4079, 0.2961]\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "    #print(torch.mean(x_t[0, :].float()))\n",
    "    x_mean_t +=torch.mean(x_t[0,:].float())\n",
    "    i = i+1\n",
    "    print(\"overall\", x_mean_t / i)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "B = 2\n",
    "D = 4\n",
    "S = 3\n",
    "log_prob = torch.rand((B,D, S))\n",
    "print(log_prob)\n",
    "x = torch.randint(low=0, high=3, size=(B, 1), device='cpu')\n",
    "one_hot = F.one_hot(x)\n",
    "print(one_hot,one_hot.shape)\n",
    "mult = log_prob * one_hot\n",
    "print(mult, mult.shape)\n",
    "sum_mult = torch.sum(mult, dim=-1)\n",
    "print(sum_mult, sum_mult.shape)\n",
    "\n",
    "print(torch.sum(sum_mult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config =  get_config()\n",
    "bdt = BidirectionalTransformer(config)\n",
    "print(\"number of parameters: \", sum([p.numel() for p in bdt.parameters()]))\n",
    "B = config.data.batch_size\n",
    "D = config.concat_dim\n",
    "S = config.data.S\n",
    "xt= torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "t = 1 * torch.ones((B, ))\n",
    "print(len(t.shape))\n",
    "# x_pred = bdt(xt, t)\n",
    "#print(x_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config =  get_config()\n",
    "model = UniformRate(config, 'cpu')\n",
    "S = 256\n",
    "B = 32\n",
    "D = 1024\n",
    "y = torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "t = 1 * torch.ones((B, ))\n",
    "rate = model.rate_mat(y, t)\n",
    "print(rate.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "S=256\n",
    "rate_const = 1\n",
    "\n",
    "\n",
    "cfg.data.S = S\n",
    "device = 'cpu'\n",
    "cfg.model.rate_const = rate_const\n",
    "\n",
    "S = 256\n",
    "B = 64\n",
    "D = 1024\n",
    "model = UniformRate(cfg, 'cpu')\n",
    "unet = UNet(\n",
    "                in_channel=1,\n",
    "                out_channel=1,\n",
    "                channel=32,\n",
    "                channel_multiplier=cfg.model.ch_mult,\n",
    "                n_res_blocks=cfg.model.num_res_blocks,\n",
    "                attn_resolutions=[16],\n",
    "                num_heads=1,\n",
    "                dropout=cfg.model.dropout,\n",
    "                model_output = 'logits',  # 'logits' or 'logistic_pars'\n",
    "                num_classes=S,\n",
    "                x_min_max=(0, 255),\n",
    "                img_size=32,\n",
    "        )\n",
    "t = 1\n",
    "xt= torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "B, D = xt.shape\n",
    "C, H, W = (1, 32, 32)\n",
    "S = 256\n",
    "x = xt.view(B, C, H, W)\n",
    "x_pred = unet(x, t * torch.ones((B,), device=device))\n",
    "x_pred = x_pred.view(B, D, S)\n",
    "print(\"PRED\",x_pred, x_pred.shape)\n",
    "log_p0t = F.log_softmax(x_pred, dim=2)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def transformer_timestep_embedding(timesteps, embedding_dim, max_positions=10000):\n",
    "    assert embedding_dim % 2 == 0\n",
    "    assert len(timesteps.shape) == 1\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(max_positions) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = timesteps[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "x = torch.randint(0, S, (B, D))  # Zufällige Integer zwischen 0 und vocab_size - 1\n",
    "\n",
    "# Embedding-Layer\n",
    "embedding = nn.Embedding(S, 10)\n",
    "x = embedding(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "x = torch.randint(0, S, (B, D))  # Zufällige Integer zwischen 0 und vocab_size - 1\n",
    "\n",
    "# Embedding-Layer\n",
    "embedding = nn.Embedding(S, 10)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "\n",
    "t =1 * torch.ones((B,))\n",
    "temb = transformer_timestep_embedding(t, 10, max_positions=10000)\n",
    "\n",
    "assert x.ndim == 3 and temb.ndim == 2 # B, D, E and B, E\n",
    "print(temb.shape)\n",
    "temb = temb.unsqueeze(1)\n",
    "print(temb.shape)\n",
    "conditioner = temb\n",
    "\n",
    "#conditioner = torch.cat([conditioner, temb], dim=1) # B, 2D, E\n",
    "print(conditioner.shape)\n",
    "cond_dim = conditioner.size(1) # 2D\n",
    "print(\"cond_dim\", cond_dim)\n",
    "concat_dim = x.size(1) + cond_dim - 1 # 3D -1\n",
    "print(\"conc dim\", concat_dim)\n",
    "pos_idx = torch.arange(concat_dim, dtype=torch.int32).unsqueeze(0)\n",
    "print(\"pos\", pos_idx.shape)\n",
    "print(\"x[:, :-1]\", x[:, :-1].shape)\n",
    "x = torch.cat([conditioner, x[:, :-1]], dim=1)\n",
    "print(\"conditioner\", conditioner.shape)\n",
    "print(\"x\", x.shape)\n",
    "mask = pos_idx.unsqueeze(-1) <= pos_idx.unsqueeze(-2)\n",
    "mask = mask.unsqueeze(-3) \n",
    "print(\"mask\", mask, mask.shape)\n",
    "mask = mask[:, :, -cond_dim:, -cond_dim:] = 1.0\n",
    "print(\"mask\", mask, mask.shape)\n",
    "#attn_mask = torch.triu(torch.ones((concat_dim, concat_dim)), diagonal=1).bool()\n",
    "attn_mask = torch.tril(torch.ones(concat_dim, concat_dim), diagonal=1).bool()\n",
    "print(\"mask\", mask, mask.shape)\n",
    "print(mask.squeeze(0).squeeze(0) == ~attn_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = torch.triu(torch.ones((5, 5)), diagonal=1).bool()\n",
    "print(attn_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = torch.tril(torch.ones(5, 5), diagonal=-1).bool()\n",
    "print(attn_mask)\n",
    "#print(attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_test = model.transition\n",
    "print(qt_test.shape)\n",
    "qt_test = utils.expand_dims(qt_test, axis=list(range(1, xt.dim() - 1)))\n",
    "print(qt_test.shape)\n",
    "torch.where(qt_test <= 1e-35, -1e9, torch.log(qt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "start_opt = time.time()\n",
    "t_eps = t - h #tau\n",
    "q_teps_0 = model.transition(t_eps * torch.ones((B,), device=device)) # (N, S, S)\n",
    "print(q_teps_0)\n",
    "q_teps_0 = utils.expand_dims(q_teps_0, axis=list(range(1, xt.ndim)))\n",
    "\n",
    "\n",
    "q_t_teps = model.transit_between(t_eps * torch.ones((B,), device=device), t * torch.ones((B,), device=device))  # (N, S, S\n",
    "print(q_t_teps)\n",
    "q_t_teps = q_t_teps.permute(0, 2, 1)\n",
    "b = utils.expand_dims(torch.arange(xt.shape[0]), axis=list(range(1, xt.ndim)))\n",
    "q_t_teps = q_t_teps[b, xt.long()].unsqueeze(-2)\n",
    "print(\"q_teps_0\", q_teps_0, q_teps_0.shape)\n",
    "print(\"q_t_teps\", q_t_teps, q_t_teps.shape)\n",
    "start_opt = time.time()\n",
    "qt0 = q_teps_0 * q_t_teps \n",
    "print(\"qt0\", qt0, qt0.shape)\n",
    "\n",
    "end_opt = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((qt0 >= 0).all())\n",
    "print(torch.log(qt0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.where(q_teps_0 <= 0.0, -1e9, torch.log(q_teps_0))\n",
    "b = torch.where(q_t_teps <= 0.0, -1e9, torch.log(q_t_teps))\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = utils.expand_dims(torch.arange(xt.shape[0]), axis=list(range(1, xt.ndim)))\n",
    "q_t_teps = q_t_teps[b, xt.long()].unsqueeze(-2)\n",
    "qt0 = q_teps_0 * q_t_teps # 30-60sekunden\n",
    "\n",
    "log_qt0 = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0)) # 7min\n",
    "start_opt = time.time()\n",
    "log_p0t = log_p0t.unsqueeze(-1)\n",
    "log_prob = torch.logsumexp(log_p0t + log_qt0, dim=-2)\n",
    "end_opt = time.time()\n",
    "print(end_opt - start_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_qt0, log_qt0.shape)\n",
    "print(c, c.shape)\n",
    "print(c == log_qt0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_p0t = log_p0t.unsqueeze(-1)\n",
    "log_prob = torch.logsumexp(log_p0t + log_qt0, dim=-2)\n",
    "# axis kein parameter? fehler hier\n",
    "end_opt = time.time()\n",
    "print(\"sampling operations time\", end_opt - start_opt)\n",
    "q_teps_0 = model.transition(t_eps * torch.ones((B,), device=device)) # (N, S, S)\n",
    "print(q_teps_0, q_teps_0.shape)\n",
    "q_teps_0 = utils.expand_dims(q_teps_0, axis=list(range(1, xt.ndim)))\n",
    "print(q_teps_0, q_teps_0.shape)\n",
    "q_t_teps = model.transit_between(t_eps * torch.ones((B,), device=device), t * torch.ones((B,), device=device))  # (N, S, S\n",
    "print(q_t_teps, q_t_teps.shape)\n",
    "q_t_teps = q_t_teps.permute(0, 2, 1)\n",
    "print(q_t_teps, q_t_teps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = utils.expand_dims(torch.arange(xt.shape[0]), axis=list(range(1, xt.ndim)))\n",
    "print(b, b.shape)\n",
    "q_t_teps = q_t_teps[b, xt].unsqueeze(-2)\n",
    "print(q_t_teps, q_t_teps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Transition matrix q_t|0: x0 -> xt ---------------------\n",
    "cfg = get_config()\n",
    "cfg.data.S = S\n",
    "cfg.model.rate_const = rate_const\n",
    "uni = UniformRate(cfg, 'cpu')\n",
    "ts = torch.rand((B,))\n",
    "qt0 = uni.transition(ts)\n",
    "x0= torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "#print(x0)\n",
    "#print(qt0, qt0.shape)\n",
    "qt0_rows_reg = qt0[\n",
    "    torch.arange(B, device=device).repeat_interleave(\n",
    "        D\n",
    "    ),  # repeats every element 0 to B-1 D-times\n",
    "    x0.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "    :,\n",
    "]\n",
    "print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "b = utils.expand_dims(torch.arange(B), (tuple(range(1, x0.dim()))))\n",
    "qt0_rows_reg2 = qt0[b, x0] #.view(-1, S)\n",
    "\n",
    "logits = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0_rows_reg2))\n",
    "\n",
    "\n",
    "x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "x_t = x_t_cat.sample().view(B, D)\n",
    "print(x_t, x_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- Transition rate: x_t -> x_tilde ------------------\n",
    "rate = uni.rate(ts)\n",
    "#print(rate, rate.shape) # B, S, S\n",
    "rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]\n",
    "#print(rate_vals_square, rate_vals_square.shape)\n",
    "rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0 \n",
    "print(rate_vals_square, rate_vals_square.shape)\n",
    "\n",
    "rate_vals_square = rate_vals_square.view(B, D, S)\n",
    "print(rate_vals_square, rate_vals_square.shape)\n",
    "\n",
    "rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(B, D)\n",
    "print(rate_vals_square_dimsum, rate_vals_square_dimsum.shape)\n",
    "\n",
    "square_dimcat = torch.distributions.categorical.Categorical(rate_vals_square_dimsum)\n",
    "\n",
    "square_dims = square_dimcat.sample() # sampled where transition takes places in every row of B\n",
    "print(\"Where transition\", square_dims, square_dims.shape)\n",
    "\n",
    "rate_new_val_probs = rate_vals_square[\n",
    "    torch.arange(B, device=device), square_dims, :\n",
    "]  # (B, S)\n",
    "print(rate_new_val_probs, rate_new_val_probs.shape)\n",
    "\n",
    "square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "    rate_new_val_probs\n",
    ")\n",
    "\n",
    "# Shape: (B,) mit Werten im Bereich [0, S)\n",
    "square_newval_samples = (\n",
    "    square_newvalcat.sample()\n",
    ")\n",
    "print(\"Transition value\", square_newval_samples, square_newval_samples.shape)\n",
    "\n",
    "x_tilde = x_t.clone()\n",
    "        # noisy image \n",
    "x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "print(x_t)\n",
    "print(x_tilde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------ELBO-------------------\n",
    "mask_reg = torch.ones((B, D, S), device=device)\n",
    "\n",
    "mask_reg[\n",
    "    torch.arange(B, device=device).repeat_interleave(D),\n",
    "    torch.arange(D, device=device).repeat(B),\n",
    "    x_tilde.long().flatten(),\n",
    "] = 0.0\n",
    "print(x_tilde)\n",
    "print(mask_reg, mask_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt0_numer_reg = qt0.view(B, S, S)\n",
    "print(qt0_numer_reg , qt0_numer_reg.shape)\n",
    "# q_{t|0} (x|x_0)\n",
    "qt0_denom_reg = (\n",
    "    qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(D),\n",
    "        :,\n",
    "        x_tilde.long().flatten(),\n",
    "    ].view(B, D, S)\n",
    "    + 1e-6\n",
    ")\n",
    "#print(qt0_denom_reg, qt0_denom_reg.shape)\n",
    "\n",
    "#print(rate, rate.shape)\n",
    "rate_vals_reg = rate[\n",
    "    torch.arange(B, device=device).repeat_interleave(D),\n",
    "    :,\n",
    "    x_tilde.long().flatten(),\n",
    "].view(B, D, S)\n",
    "print(rate_vals_reg, rate_vals_reg.shape)\n",
    "print((mask_reg * rate_vals_reg))\n",
    "reg_tmp = (mask_reg * rate_vals_reg) @ qt0_numer_reg.transpose(1, 2)\n",
    "print(reg_tmp, reg_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_const = 1\n",
    "S = 3\n",
    "B = 2\n",
    "D = 4\n",
    "cfg = get_config()\n",
    "cfg.data.S = S\n",
    "cfg.model.rate_const = rate_const\n",
    "uni = UniformRate(cfg, 'cpu')\n",
    "ts = torch.rand((B,))\n",
    "xt= torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "print(xt)\n",
    "\n",
    "qt0 = uni.transition(ts)\n",
    "\n",
    "qt0_y2x = qt0.permute(0, 2, 1)\n",
    "print(qt0, qt0.shape)\n",
    "print(qt0_y2x, qt0_y2x.shape)\n",
    "print(qt0 == qt0_y2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = utils.expand_dims(\n",
    "    torch.arange(xt.shape[0]), tuple(range(1, xt.dim()))\n",
    ")\n",
    "print(b, b.shape)\n",
    "qt0_y2x = qt0_y2x[b, xt]\n",
    "print(qt0_y2x, qt0_y2x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = qt0_y2x\n",
    "log_p0t = F.log_softmax(logits, dim=-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_qt0 = torch.where(qt0 <= 1e-35, -1e9, torch.log(qt0))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_qt0 = utils.expand_dims(log_qt0, axis=list(range(1, xt.dim())))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_p0t = log_p0t.unsqueeze(-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_prob = torch.logsumexp(log_p0t + log_qt0, dim=-2)\n",
    "print(log_prob, log_prob.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_onehot = F.one_hot(xt.long(), S)\n",
    "qt0 = uni.transition(ts)\n",
    "p0t = F.softmax(logits, dim=-1)\n",
    "print(p0t, p0t.shape)\n",
    "qt0 = utils.expand_dims(qt0, axis=list(range(1, xt.dim() - 1)))\n",
    "print(qt0, qt0.shape)\n",
    "prob_all = p0t @ qt0\n",
    "print(prob_all.shape)\n",
    "log_prob = torch.log(prob_all + 1e-35)\n",
    "print(log_prob, log_prob.shape)\n",
    "log_xt = torch.sum(log_prob * xt_onehot, axis=-1)\n",
    "print(log_xt, log_xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt0 = uni.transition(ts)\n",
    "t_eps = ts - 0.1\n",
    "q_t_teps = uni.transit_between(t_eps * torch.ones((B,), device=device), ts * torch.ones((B,), device=device))\n",
    "print(q_t_teps, q_t_teps.shape, qt0.shape)\n",
    "b = utils.expand_dims(torch.arange(B), (tuple(range(1, x0.dim()))))\n",
    "qt0_rows_reg2 = qt0[b, x0]\n",
    "print(qt0_rows_reg2, qt0_rows_reg2.shape)\n",
    "logits = torch.where(qt0_rows_reg2  <= 0.0, -1e9, torch.log(qt0_rows_reg2))\n",
    "print(logits, logits.shape)\n",
    "\n",
    "x_t_cat = torch.distributions.categorical.Categorical(logits).sample()\n",
    "print(x_t_cat,x_t_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits# B, D, S\n",
    "loss = -(\n",
    "    (S - 1) * ll_xt\n",
    "    + torch.sum(utils.log1mexp(ll_all), dim=-1)\n",
    "    - utils.log1mexp(ll_xt)\n",
    ")\n",
    "print(loss, loss.shape)\n",
    "weight = torch.ones((B,), dtype=torch.float32)\n",
    "weight = utils.expand_dims(weight, axis=list(range(1, loss.dim())))\n",
    "print(weight, weight.shape)\n",
    "loss = loss * weight\n",
    "print(loss, loss.shape)\n",
    "loss = torch.sum(loss) / xt.shape[0]\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits\n",
    "xt_onehot = F.one_hot(xt.long(), num_classes=S)\n",
    "b = utils.expand_dims(torch.arange(xt.shape[0]), tuple(range(1, xt.dim())))\n",
    "print(b, b.shape)\n",
    "qt0_x2y = uni.transition(ts)\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = qt0_x2y.permute(0, 2, 1)\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = qt0_y2x[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "ll_xt = ll_xt.unsqueeze(-1)\n",
    "print(\"ll\", ll_xt, ll_xt.shape)\n",
    "backwd = torch.exp(ll_all - ll_xt) * qt0_y2x\n",
    "print(backwd , backwd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_term = torch.sum(backwd * (1 - xt_onehot), dim=-1)\n",
    "print(first_term , first_term.shape)\n",
    "qt0_x2y = qt0_x2y[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "fwd = (ll_xt - ll_all) * qt0_x2y\n",
    "print(fwd, fwd.shape)\n",
    "second_term = torch.sum(fwd * (1 - xt_onehot), dim=-1)\n",
    "print(second_term, second_term.shape)\n",
    "loss = first_term - second_term\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones((B,), dtype=torch.float32)\n",
    "weight = utils.expand_dims(weight, axis=list(range(1, loss.dim())))\n",
    "print(weight, weight.shape)\n",
    "loss = loss * weight\n",
    "print(loss, loss.shape)\n",
    "loss = torch.sum(loss) / xt.shape[0]\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.concatenate((np.linspace(1.0, 1e-3, 1000), np.array([0])))\n",
    "#save_ts = ts[np.linspace(0, len(ts)-2, num_intermediates, dtype=int)]\n",
    "\n",
    "for idx, t in (enumerate(ts[0:-1])):\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
