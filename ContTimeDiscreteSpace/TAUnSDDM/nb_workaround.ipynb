{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from lib.models.models import UniformRate, UniformVariantRate\n",
    "\n",
    "from lib.utils import utils\n",
    "import torch.nn.functional as F\n",
    "from lib.networks.unet import UNet\n",
    "from lib.networks.hollow_networks import BidirectionalTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "import lib.sampling.sampling as sampling\n",
    "import lib.sampling.sampling_utils as sampling_utils\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import lib.sampling.sampling_utils as sampling_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 1]], device='cuda:0', dtype=torch.int32) torch.Size([8192, 32])\n",
      "mask torch.Size([4096, 32])\n",
      "xrep torch.Size([4096, 32])\n",
      "xneg torch.Size([4096, 32])\n",
      "t torch.Size([4096])\n",
      "qxt torch.Size([4096, 1])\n",
      "qxt torch.Size([128, 32])\n",
      "qxt torch.Size([128, 32, 1])\n",
      "torch.Size([128, 32, 2])\n"
     ]
    }
   ],
   "source": [
    "D = 32\n",
    "ddim = D\n",
    "B = 128\n",
    "bsize = B\n",
    "S = 2\n",
    "device = 'cuda'\n",
    "vocab_size = S\n",
    "#mask = jnp.eye(ddim, dtype=jnp.int32).repeat(bsize * vocab_size, axis=0)\n",
    "#print(mask, mask.shape)\n",
    "mask = torch.eye(D, device=device, dtype=torch.int32).repeat_interleave(B * S, 0)\n",
    "print(\"mask\", mask, mask.shape)\n",
    "min_time = 0.01\n",
    "ts = torch.rand((B,), device=device) * (1.0 - min_time) + min_time\n",
    "xt = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "\n",
    "mask = torch.eye(D, device=xt.device).repeat_interleave(B, 0)\n",
    "print(\"mask\", mask.shape)\n",
    "xrep = torch.tile(xt, (D, 1))\n",
    "print(\"xrep\", xrep.shape)\n",
    "xneg = (mask - xrep) * mask + (1 - mask) * xrep\n",
    "print(\"xneg\", xneg.shape)\n",
    "ts = torch.tile(ts, (D,))\n",
    "print(\"t\", ts.shape)\n",
    "qxt = torch.tile(torch.randint(low=0, high=S, size=(B, 1), device=device), (D, 1))\n",
    "print(\"qxt\", qxt.shape)\n",
    "qxt = qxt.view(-1, B).t()\n",
    "print(\"qxt\", qxt.shape)\n",
    "qxt = qxt.unsqueeze(-1)\n",
    "print(\"qxt\", qxt.shape)\n",
    "xt_onehot = F.one_hot(xt, num_classes=2).to(qxt.dtype)\n",
    "print((xt_onehot * qxt).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask (4096, 32)\n",
      "xrep (4096, 32)\n",
      "xneg (4096, 32)\n",
      "t (4096,)\n",
      "qxt (4096, 1)\n",
      "qxt (128, 32)\n"
     ]
    }
   ],
   "source": [
    "D = 32\n",
    "ddim = D\n",
    "B = 128\n",
    "bsize = B\n",
    "S = 2\n",
    "device = 'cuda'\n",
    "vocab_size = S\n",
    "rng = jax.random.PRNGKey(0)\n",
    "t = jax.random.uniform(rng, (bsize,))\n",
    "xt = jax.random.randint(rng, (B, D), minval=0,\n",
    "                        maxval=S, dtype=jnp.int32)\n",
    "mask = jnp.eye(ddim).repeat(bsize, axis=0)\n",
    "print(\"mask\", mask.shape)\n",
    "xrep = jnp.tile(xt, (ddim, 1))\n",
    "print(\"xrep\", xrep.shape)\n",
    "xneg = (mask - xrep) * mask + (1 - mask) * xrep\n",
    "print(\"xneg\", xneg.shape)\n",
    "t = jnp.tile(t, (ddim,))\n",
    "print(\"t\", t.shape)\n",
    "qxt = jnp.tile(jax.random.randint(rng, (B, 1), minval=0, maxval=S, dtype=jnp.int32), (ddim, 1))\n",
    "print(\"qxt\", qxt.shape)\n",
    "qxt = jnp.reshape(qxt, (-1, bsize)).T\n",
    "print(\"qxt\", qxt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import utils\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "S = 2\n",
    "N = 5\n",
    "D = 32\n",
    "device = 'cpu'\n",
    "xt = torch.randint(low=0, high=S, size=(N, D), device=device)\n",
    "choices = jnp.expand_dims(jnp.arange(S, dtype=jnp.int32),\n",
    "                            axis=list(range(xt.ndim)))\n",
    "print(choices, choices.shape)\n",
    "choices = utils.expand_dims(\n",
    "    torch.arange(S, dtype=torch.int32), axis=list(range(xt.ndim))\n",
    ")\n",
    "print(choices, choices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = '/Users/paulheller/PythonRepositories/Master-Thesis/ContTimeDiscreteSpace/TAUnSDDM/'\n",
    "save_location = os.path.join(script_dir, 'SavedModels/Synthetic/')\n",
    "save_location_png = os.path.join(save_location, 'PNGs/')\n",
    "dataset_location = os.path.join(script_dir, 'lib/datasets/Synthetic/data_2spirals.npy')\n",
    "\n",
    "\n",
    "cfg = get_config()\n",
    "\n",
    "device = cfg.device\n",
    "dataset = dataset_utils.get_dataset(cfg, device, dataset_location)\n",
    "dataloader = DataLoader(dataset,\n",
    "    batch_size=1000,\n",
    "    shuffle=cfg.data.shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm, inv_bm = dataset_utils.get_binmap(cfg.concat_dim, cfg.data.binmode)\n",
    "for samples in dataloader:\n",
    "    samples = samples.numpy()\n",
    "    samples = dataset_utils.bin2float(\n",
    "        samples.astype(np.int32), inv_bm, cfg.concat_dim, cfg.data.int_scale\n",
    "    )\n",
    "\n",
    "    saving_plot_path = os.path.join(\n",
    "        save_location_png,\n",
    "        f\"{cfg.loss.name}test_{cfg.sampler.name}{cfg.sampler.num_steps}.pdf\",\n",
    "    )\n",
    "    dataset_utils.plot_samples(\n",
    "        samples, saving_plot_path, im_size=4.1, im_fmt=\"pdf\"\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "x_mean = 0 # 127.5\n",
    "x_std = 0 # 73.7\n",
    "\n",
    "for minibatch in dataloader:\n",
    "    \n",
    "    B = minibatch.shape[0]\n",
    "    # hollow xt, t, l_all, l_xt geht rein\n",
    "    device = cfg.device\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.0\n",
    "    ts = torch.ones((B, ), device=device) * 0\n",
    "    #print(ts)\n",
    "    #ts = torch.ones((B, )) \n",
    "    qt0 = model.transition(ts)  # (B, S, S)\n",
    "\n",
    "    # rate = model.rate(ts)  # (B, S, S)\n",
    "\n",
    "    b = utils.expand_dims(torch.arange(B), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "\n",
    "    # log loss\n",
    "    log_qt0 = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0))\n",
    "    xt = torch.distributions.categorical.Categorical(logits=log_qt0).sample()\n",
    "    xt = xt.numpy()\n",
    "    #print(type(xt))\n",
    "    samples = dataset_utils.bin2float(\n",
    "        xt.astype(np.int32), inv_bm, cfg.concat_dim, cfg.data.int_scale\n",
    "    )\n",
    "\n",
    "    saving_plot_path = os.path.join(\n",
    "        save_location_png,\n",
    "        f\"{cfg.loss.name}noisy_{cfg.sampler.name}{cfg.sampler.num_steps}.png\",\n",
    "    )\n",
    "    dataset_utils.plot_samples(\n",
    "        samples, saving_plot_path, im_size=cfg.data.plot_size, im_fmt=\"png\"\n",
    "    )\n",
    "\n",
    "    break\n",
    "xt = torch.randint(low=0, high=2, size=(1000, 32), device=device)\n",
    "xt = xt.numpy()\n",
    "    #print(type(xt))\n",
    "samples = dataset_utils.bin2float(\n",
    "    xt.astype(np.int32), inv_bm, cfg.concat_dim, cfg.data.int_scale\n",
    ")\n",
    "\n",
    "saving_plot_path = os.path.join(\n",
    "    save_location_png,\n",
    "    f\"{cfg.loss.name}realnoisy_{cfg.sampler.name}{cfg.sampler.num_steps}.png\",\n",
    ")\n",
    "dataset_utils.plot_samples(\n",
    "    samples, saving_plot_path, im_size=cfg.data.plot_size, im_fmt=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cpu'  # BeispielgerÃ¤t\n",
    "num_steps = 100\n",
    "max_time = 1\n",
    "min_time = 0.01\n",
    "time_dilation = 2\n",
    "\n",
    "# Szenario 1: time_dilation_start_time ist None\n",
    "time_steps = torch.linspace(\n",
    "    max_time, min_time, num_steps * time_dilation + 1, device=device\n",
    ")\n",
    "step_sizes = time_steps[:-1] - time_steps[1:]\n",
    "time_steps = time_steps[:-1]\n",
    "\n",
    "print(\"Szenario 1 - Time Steps:\", time_steps, time_steps.shape)\n",
    "print(\"Szenario 1 - Step Sizes:\", step_sizes, step_sizes.shape)\n",
    "\n",
    "# Szenario 2: time_dilation_start_time ist 0.1\n",
    "time_dilation_start_time = 0.1\n",
    "num_steps_first = round(100 * (max_time - time_dilation_start_time) / max_time) + 1\n",
    "num_steps_second = round(100 * (time_dilation_start_time - min_time) / max_time) * time_dilation + 1\n",
    "\n",
    "time_steps_first = torch.linspace(max_time, time_dilation_start_time, num_steps_first, device=device)[:-1]\n",
    "time_steps_second = torch.linspace(time_dilation_start_time, min_time, num_steps_second, device=device)\n",
    "time_steps = torch.cat([time_steps_first, time_steps_second])\n",
    "\n",
    "step_sizes = time_steps[:-1] - time_steps[1:]\n",
    "time_steps = time_steps[:-1]\n",
    "\n",
    "print(\"Szenario 2 - Time Steps:\", time_steps, time_steps.shape)\n",
    "print(\"Szenario 2 - Step Sizes:\", step_sizes, step_sizes.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
