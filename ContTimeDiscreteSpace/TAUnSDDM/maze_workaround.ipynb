{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code by David Roberts https://www.kaggle.com/code/davidbroberts/tensorflow-transfer-learning/notebook\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Set the log level to keep the warnings down\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from config.config_hollow_maze import get_config\n",
    "import lib.datasets.maze as maze \n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "from lib.models.models import UniformRate, UniformVariantRate\n",
    "import lib.utils.utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lib.datasets import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "cfg = get_config()\n",
    "device = cfg.device \n",
    "print(\"1\", device)\n",
    "dataset = dataset_utils.get_dataset(cfg, device)\n",
    "cfg.data.batch_size = 10\n",
    "train_dataloader = DataLoader(dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=4)\n",
    "                                #worker_init_fn=worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out torch.Size([10, 1, 15, 15]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "def show_images(images, n=8):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0).numpy().astype(\"uint8\"), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "for i in train_dataloader:\n",
    "    print(\"out\", i.shape, type(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([10, 1, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in train_dataloader:\n",
    "    show_images(i * 127.5, n=8)\n",
    "    print(type(i), i.shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time points tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[0.3374, 0.3313, 0.3313],\n",
      "        [0.3313, 0.3374, 0.3313],\n",
      "        [0.3374, 0.3313, 0.3313],\n",
      "        ...,\n",
      "        [0.3374, 0.3313, 0.3313],\n",
      "        [0.3313, 0.3374, 0.3313],\n",
      "        [0.3374, 0.3313, 0.3313]]) torch.Size([2250, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 225, 255]' is invalid for input of size 6750",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m rate_vals_square \u001b[39m=\u001b[39m rate[\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     torch\u001b[39m.\u001b[39marange(B, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mrepeat_interleave(D), x_t\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mflatten(), :\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m ]  \u001b[39m# (B*D, S)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m rate_vals_square[\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     torch\u001b[39m.\u001b[39marange(B \u001b[39m*\u001b[39m D, device\u001b[39m=\u001b[39mdevice), x_t\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m ] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m  \u001b[39m# - values = 0 => in rate_vals_square[0, 1] = 0\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m rate_vals_square \u001b[39m=\u001b[39m rate_vals_square\u001b[39m.\u001b[39;49mview(B, D, S)  \u001b[39m# (B*D, S) => (B, D, S)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m#  Summe der Werte entlang der Dimension S\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m rate_vals_square_dimsum \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(rate_vals_square, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mview(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     B, D\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m )  \u001b[39m# B, D with every entry = S-1? => for entries of x_t same prob to transition?\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10, 225, 255]' is invalid for input of size 6750"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg.model.rate_const = 1.7\n",
    "cfg.model.t_func = \"sqrt_cos\"\n",
    "model = UniformRate(cfg, 'cpu')\n",
    "#model = UniformVariantRate(cfg, 'cpu')\n",
    "device = 'cpu'\n",
    "S = 255\n",
    "\n",
    "\n",
    "for minibatch in train_dataloader:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    D = C*H*W\n",
    "    minibatch = minibatch.view(B, D)\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,)) * 1\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "    print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "    print(torch.mean(x_tilde[1,:, :, :].float()))\n",
    "    #print(x_tilde[0,0, :, :].std())\n",
    "    show_images(minibatch.view(B, C, H, W) * 127.5, n=9)\n",
    "    show_images(x_tilde * 127.5, n=9)\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W) * 127.5, n=9)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.utils.utils as utils\n",
    "cfg.model.rate_const = 0.5\n",
    "cfg.model.t_func = \"sqrt_cos\"\n",
    "model = UniformRate(cfg, 'cpu')\n",
    "model = UniformVariantRate(cfg, 'cpu')\n",
    "device = 'cpu'\n",
    "S = 255\n",
    "min_time = 0.01\n",
    "\n",
    "\n",
    "for minibatch in train_dataloader:\n",
    "    \n",
    "\n",
    "    if len(minibatch.shape) == 4:\n",
    "        B, C, H, W = minibatch.shape\n",
    "        minibatch = minibatch.view(B, C * H * W)\n",
    "    # hollow xt, t, l_all, l_xt geht rein\n",
    "    B = minibatch.shape[0]\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - min_time) + min_time\n",
    "    ts = torch.ones((B,)) * 1\n",
    "    print(ts[:9])\n",
    "    #\n",
    "\n",
    "    qt0 = model.transition(ts)  # (B, S, S)\n",
    "\n",
    "    # rate = model.rate(ts)  # (B, S, S)\n",
    "\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "\n",
    "    # log loss\n",
    "    log_qt0 = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0))\n",
    "    x_tilde = torch.distributions.categorical.Categorical(\n",
    "        logits=log_qt0\n",
    "    ).sample()  # bis hierhin <1 sek\n",
    "\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "    print(torch.mean(x_tilde[1,:, :, :].float()))\n",
    "    #print(x_tilde[0,0, :, :].std())\n",
    "    show_images(minibatch.view(B, C, H, W) * 127.5, n=9)\n",
    "    show_images(x_tilde * 127.5, n=9)\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W) * 127.5, n=9)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
