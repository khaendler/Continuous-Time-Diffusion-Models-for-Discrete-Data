{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lib.datasets.synthetic as synthetic\n",
    "import torchvision\n",
    "import lib.datasets.maze as maze \n",
    "import lib.datasets.mnist as mnist\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "from lib.models.models import UniformRate, UniformVariantRate, GaussianTargetRate\n",
    "import lib.utils.utils as utils\n",
    "import numpy as np\n",
    "from lib.datasets import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "def show_images(images, n=8):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0).numpy().astype(\"uint8\"), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig('Mazes2.png')\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "\n",
    "def plot_samples(samples, im_size=0, axis=False, im_fmt=None):\n",
    "    \"\"\"Plot samples.\"\"\"\n",
    "    plt.scatter(samples[:, 0], samples[:, 1], marker=\".\")\n",
    "    plt.axis(\"equal\")\n",
    "    if im_size > 0:\n",
    "        plt.xlim(-im_size, im_size)\n",
    "        plt.ylim(-im_size, im_size)\n",
    "    if not axis:\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "#loss_res = np.load('loss_CatRM104999_hollow10MRRes.npy')\n",
    "def apply_ema(signal, alpha):\n",
    "    \"\"\"\n",
    "    Anwendung des Exponential Moving Average auf ein Signal.\n",
    "\n",
    "    :param signal: Das Eingangssignal (Liste oder NumPy-Array).\n",
    "    :param alpha: Der Gl채ttungsfaktor. Niedrigere Werte gl채tten mehr, typisch zwischen 0 und 1.\n",
    "    :return: Das gegl채ttete Signal.\n",
    "    \"\"\"\n",
    "    ema = [signal[0]]  # Startwert f체r EMA\n",
    "    for i in range(1, len(signal)):\n",
    "        ema.append(alpha * signal[i] + (1 - alpha) * ema[i-1])\n",
    "    return np.array(ema)\n",
    "\"\"\"\n",
    "res = loss_res[1000:105000]\n",
    "sm = apply_ema(res, 0.0001)\n",
    "plt.plot(sm)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "def plot_squared(n_samples, samples, save_location_png):\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(int(np.sqrt(n_samples)), int(np.sqrt(n_samples)), 1 + i)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.transpose(samples[i, ...], (1, 2, 0)), cmap=\"gray\")\n",
    "\n",
    "    saving_plot_path = os.path.join(\n",
    "        save_location_png,\"mazes.png\",\n",
    "    )\n",
    "    #plt.suptitle('Mazes', fontsize=16)\n",
    "    #plt.subplots_adjust(top=0.85)\n",
    "    #plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(saving_plot_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters:  11358466\n"
     ]
    }
   ],
   "source": [
    "from config.maze_config.config_tauUnet_maze import get_config\n",
    "cfg = get_config()\n",
    "model = model_utils.create_model(cfg, cfg.device)\n",
    "print(\"Number of Parameters: \", sum([p.numel() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.9900, 0.9800, 0.9700, 0.9600, 0.9500, 0.9400, 0.9300, 0.9200,\n",
      "        0.9100, 0.9000, 0.8900, 0.8800, 0.8700, 0.8600, 0.8500, 0.8400, 0.8300,\n",
      "        0.8200, 0.8100, 0.8000, 0.7900, 0.7800, 0.7700, 0.7600, 0.7500, 0.7400,\n",
      "        0.7300, 0.7200, 0.7100, 0.7000, 0.6900, 0.6800, 0.6700, 0.6600, 0.6500,\n",
      "        0.6400, 0.6300, 0.6200, 0.6100, 0.6000, 0.5900, 0.5800, 0.5700, 0.5600,\n",
      "        0.5500, 0.5400, 0.5300, 0.5200, 0.5100, 0.5000, 0.4900, 0.4800, 0.4700,\n",
      "        0.4600, 0.4500, 0.4400, 0.4300, 0.4200, 0.4100, 0.4000, 0.3900, 0.3800,\n",
      "        0.3700, 0.3600, 0.3500, 0.3400, 0.3300, 0.3200, 0.3100, 0.3000, 0.2900,\n",
      "        0.2800, 0.2700, 0.2600, 0.2500, 0.2400, 0.2300, 0.2200, 0.2100, 0.2000,\n",
      "        0.1900, 0.1800, 0.1700, 0.1600, 0.1500, 0.1400, 0.1300, 0.1200, 0.1100,\n",
      "        0.1000, 0.0900, 0.0800, 0.0700, 0.0600, 0.0500, 0.0400, 0.0300, 0.0200,\n",
      "        0.0100, 0.0000], device='cuda:0')\n",
      "(tensor([1.0000, 0.9900], device='cuda:0'), tensor([0.9900, 0.9800], device='cuda:0'), tensor([0.9800, 0.9700], device='cuda:0'), tensor([0.9700, 0.9600], device='cuda:0'), tensor([0.9600, 0.9500], device='cuda:0'), tensor([0.9500, 0.9400], device='cuda:0'), tensor([0.9400, 0.9300], device='cuda:0'), tensor([0.9300, 0.9200], device='cuda:0'), tensor([0.9200, 0.9100], device='cuda:0'), tensor([0.9100, 0.9000], device='cuda:0'), tensor([0.9000, 0.8900], device='cuda:0'), tensor([0.8900, 0.8800], device='cuda:0'), tensor([0.8800, 0.8700], device='cuda:0'), tensor([0.8700, 0.8600], device='cuda:0'), tensor([0.8600, 0.8500], device='cuda:0'), tensor([0.8500, 0.8400], device='cuda:0'), tensor([0.8400, 0.8300], device='cuda:0'), tensor([0.8300, 0.8200], device='cuda:0'), tensor([0.8200, 0.8100], device='cuda:0'), tensor([0.8100, 0.8000], device='cuda:0'), tensor([0.8000, 0.7900], device='cuda:0'), tensor([0.7900, 0.7800], device='cuda:0'), tensor([0.7800, 0.7700], device='cuda:0'), tensor([0.7700, 0.7600], device='cuda:0'), tensor([0.7600, 0.7500], device='cuda:0'), tensor([0.7500, 0.7400], device='cuda:0'), tensor([0.7400, 0.7300], device='cuda:0'), tensor([0.7300, 0.7200], device='cuda:0'), tensor([0.7200, 0.7100], device='cuda:0'), tensor([0.7100, 0.7000], device='cuda:0'), tensor([0.7000, 0.6900], device='cuda:0'), tensor([0.6900, 0.6800], device='cuda:0'), tensor([0.6800, 0.6700], device='cuda:0'), tensor([0.6700, 0.6600], device='cuda:0'), tensor([0.6600, 0.6500], device='cuda:0'), tensor([0.6500, 0.6400], device='cuda:0'), tensor([0.6400, 0.6300], device='cuda:0'), tensor([0.6300, 0.6200], device='cuda:0'), tensor([0.6200, 0.6100], device='cuda:0'), tensor([0.6100, 0.6000], device='cuda:0'), tensor([0.6000, 0.5900], device='cuda:0'), tensor([0.5900, 0.5800], device='cuda:0'), tensor([0.5800, 0.5700], device='cuda:0'), tensor([0.5700, 0.5600], device='cuda:0'), tensor([0.5600, 0.5500], device='cuda:0'), tensor([0.5500, 0.5400], device='cuda:0'), tensor([0.5400, 0.5300], device='cuda:0'), tensor([0.5300, 0.5200], device='cuda:0'), tensor([0.5200, 0.5100], device='cuda:0'), tensor([0.5100, 0.5000], device='cuda:0'), tensor([0.5000, 0.4900], device='cuda:0'), tensor([0.4900, 0.4800], device='cuda:0'), tensor([0.4800, 0.4700], device='cuda:0'), tensor([0.4700, 0.4600], device='cuda:0'), tensor([0.4600, 0.4500], device='cuda:0'), tensor([0.4500, 0.4400], device='cuda:0'), tensor([0.4400, 0.4300], device='cuda:0'), tensor([0.4300, 0.4200], device='cuda:0'), tensor([0.4200, 0.4100], device='cuda:0'), tensor([0.4100, 0.4000], device='cuda:0'), tensor([0.4000, 0.3900], device='cuda:0'), tensor([0.3900, 0.3800], device='cuda:0'), tensor([0.3800, 0.3700], device='cuda:0'), tensor([0.3700, 0.3600], device='cuda:0'), tensor([0.3600, 0.3500], device='cuda:0'), tensor([0.3500, 0.3400], device='cuda:0'), tensor([0.3400, 0.3300], device='cuda:0'), tensor([0.3300, 0.3200], device='cuda:0'), tensor([0.3200, 0.3100], device='cuda:0'), tensor([0.3100, 0.3000], device='cuda:0'), tensor([0.3000, 0.2900], device='cuda:0'), tensor([0.2900, 0.2800], device='cuda:0'), tensor([0.2800, 0.2700], device='cuda:0'), tensor([0.2700, 0.2600], device='cuda:0'), tensor([0.2600, 0.2500], device='cuda:0'), tensor([0.2500, 0.2400], device='cuda:0'), tensor([0.2400, 0.2300], device='cuda:0'), tensor([0.2300, 0.2200], device='cuda:0'), tensor([0.2200, 0.2100], device='cuda:0'), tensor([0.2100, 0.2000], device='cuda:0'), tensor([0.2000, 0.1900], device='cuda:0'), tensor([0.1900, 0.1800], device='cuda:0'), tensor([0.1800, 0.1700], device='cuda:0'), tensor([0.1700, 0.1600], device='cuda:0'), tensor([0.1600, 0.1500], device='cuda:0'), tensor([0.1500, 0.1400], device='cuda:0'), tensor([0.1400, 0.1300], device='cuda:0'), tensor([0.1300, 0.1200], device='cuda:0'), tensor([0.1200, 0.1100], device='cuda:0'), tensor([0.1100, 0.1000], device='cuda:0'), tensor([0.1000, 0.0900], device='cuda:0'), tensor([0.0900, 0.0800], device='cuda:0'), tensor([0.0800, 0.0700], device='cuda:0'), tensor([0.0700, 0.0600], device='cuda:0'), tensor([0.0600, 0.0500], device='cuda:0'), tensor([0.0500, 0.0400], device='cuda:0'), tensor([0.0400, 0.0300], device='cuda:0'), tensor([0.0300, 0.0200], device='cuda:0'), tensor([0.0200, 0.0100], device='cuda:0'), tensor([0.0100, 0.0000], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "times = torch.linspace(1.0, 0.0, 100 + 1, device='cuda')\n",
    "print(times)\n",
    "#times = times * torch.ones((5, ), device='cuda')\n",
    "times = torch.stack((times[:-1], times[ 1:]), dim=0)\n",
    "times = times.unbind(dim=-1)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0') tensor(0.9900, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, j in times:\n",
    "    print(i, j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_res = np.load('loss_CatRM104999_hollow10MRRes.npy')\n",
    "def apply_ema(signal, alpha):\n",
    "    \"\"\"\n",
    "    Anwendung des Exponential Moving Average auf ein Signal.\n",
    "\n",
    "    :param signal: Das Eingangssignal (Liste oder NumPy-Array).\n",
    "    :param alpha: Der Gl채ttungsfaktor. Niedrigere Werte gl채tten mehr, typisch zwischen 0 und 1.\n",
    "    :return: Das gegl채ttete Signal.\n",
    "    \"\"\"\n",
    "    ema = [signal[0]]  # Startwert f체r EMA\n",
    "    for i in range(1, len(signal)):\n",
    "        ema.append(alpha * signal[i] + (1 - alpha) * ema[i-1])\n",
    "    return np.array(ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets.maze import maze_gen\n",
    "from config.maze_config.config_hollow_maze import get_config\n",
    "cfg = get_config()\n",
    "mazes =maze_gen(\n",
    "            limit=50,\n",
    "            device='cuda',\n",
    "            crop=False,\n",
    "            random_transform=cfg.data.random_transform,\n",
    "            dim_x=7,\n",
    "            dim_y=7,\n",
    "            pixelSizeOfTile=1,\n",
    "            weightHigh=99,\n",
    "            weightLow=97,\n",
    "        )\n",
    "show_images(mazes.detach().cpu(), n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters:  10538715\n"
     ]
    }
   ],
   "source": [
    "from config.maze_config.config_bert_maze import get_config\n",
    "cfg = get_config()\n",
    "model = model_utils.create_model(cfg, cfg.device)\n",
    "print(\"Number of Parameters: \", sum([p.numel() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m S \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mS \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m B \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m net \u001b[39m=\u001b[39m ProteinScoreNet(cfg)\u001b[39m.\u001b[39;49mto(cfg\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m ts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((B,), device\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mdevice) \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m \u001b[39m0.01\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blise/home/pheller/Remote-Thesis/ContTimeDiscreteSpace/TAUnSDDM/maze_workaround.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(low\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, high\u001b[39m=\u001b[39mS, size\u001b[39m=\u001b[39m(B, D), device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/my_python_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/my_python_env/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/my_python_env/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/my_python_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lib.networks.ddsm_networks import ProteinScoreNet\n",
    "from config.maze_config.config_hollow_maze import get_config\n",
    "cfg = get_config()\n",
    "cfg.device = 'cuda'\n",
    "\n",
    "\n",
    "\n",
    "D = cfg.model.concat_dim = 1024\n",
    "S = cfg.data.S = 5\n",
    "B = cfg.data.batch_size\n",
    "net = ProteinScoreNet(cfg).to(cfg.device)\n",
    "ts = torch.rand((B,), device=cfg.device) * (1.0 - 0.01) + 0.01\n",
    "x = torch.randint(low=0, high=S, size=(B, D), device='cuda')\n",
    "x_out = net(x, ts)\n",
    "print(x_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.mnist_config.config_bert_mnist import get_config\n",
    "cfg = get_config()\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "mnist_dataset = dataset_utils.get_dataset(cfg, device, cfg.data.location)\n",
    "cfg.data.batch_size = 10\n",
    "mnist_dl = DataLoader(mnist_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.synthetic_config.config_ebm_synthetic import get_config\n",
    "cfg = get_config()\n",
    "location = \"lib/datasets/Synthetic/data_2spirals.npy\"\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "mnist_dataset = dataset_utils.get_dataset(cfg, device, location)\n",
    "cfg.data.batch_size = 1000\n",
    "mnist_dl = DataLoader(mnist_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.rate_const = 2.5 #0.00009\n",
    "cfg.model.t_func = \"log_sqr\"\n",
    "#model = UniformRate(cfg, device)\n",
    "model = UniformVariantRate(cfg, device)\n",
    "# model = GaussianTargetRate(cfg, device)\n",
    "S = 2\n",
    "bm, inv_bm = synthetic.get_binmap(cfg.model.concat_dim, cfg.data.binmode)\n",
    "\n",
    "for minibatch in mnist_dl:\n",
    "    print(minibatch.device)\n",
    "    B, D = minibatch.shape\n",
    "    minibatch = minibatch.view(B, D).to('cpu')\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) * 1\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "    print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = synthetic.bin2float(x_tilde.detach().cpu().numpy().astype(np.int32), inv_bm, cfg.model.concat_dim, cfg.data.int_scale)\n",
    "    minibatch = synthetic.bin2float(minibatch.detach().cpu().numpy().astype(np.int32), inv_bm, cfg.model.concat_dim, cfg.data.int_scale)\n",
    "    plot_samples(minibatch) # * 127.5\n",
    "    plot_samples(x_tilde) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    #noise_x = synthetic.bin2float(noise_x.detach().cpu().numpy().astype(np.int32), inv_bm, cfg.model.concat_dim, cfg.data.int_scale)\n",
    "    #plot_samples(noise_x) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.rate_const = 0.1 #0.00009\n",
    "cfg.model.t_func = \"log\"\n",
    "\n",
    "cfg.model.time_base = 3\n",
    "cfg.model.time_exp = 100\n",
    "cfg.model.rate_sigma = 6.0\n",
    "cfg.model.Q_sigma = 512.0\n",
    "#model = UniformRate(cfg, device)\n",
    "model = UniformVariantRate(cfg, device)\n",
    "# model = GaussianTargetRate(cfg, device)\n",
    "S = 256\n",
    "\n",
    "\n",
    "for minibatch in mnist_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    print(minibatch.device)\n",
    "    D = C*H*W\n",
    "    minibatch = minibatch.view(B, D).to('cpu')\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) *1\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "    print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu(), n=9) # * 127.5\n",
    "    show_images(x_tilde.detach().cpu(), n=9) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W).detach().cpu(), n=9) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.maze_config.config_hollow_maze import get_config\n",
    "cfg = get_config()\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "maze_dataset = dataset_utils.get_dataset(cfg, device)\n",
    "cfg.data.batch_size = 25\n",
    "maze_dl = DataLoader(maze_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in maze_dl:\n",
    "    print(type(i))\n",
    "    show_images(i.detach().cpu() * 127.5, n=10)\n",
    "    plot_squared(25, i.detach().cpu().numpy(), \"\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.rate_const = 2.3 # 2.3 log_sqr t=0.5T 0.4763, 0.2619, 0.2619\n",
    "cfg.model.t_func = \"log_sqr\"\n",
    "cfg.model.time_base = 1\n",
    "cfg.model.time_exp = 250\n",
    "#model = UniformRate(cfg, 'cuda')\n",
    "model = UniformVariantRate(cfg, 'cuda')\n",
    "S = 3\n",
    "# 0.25 [0.7867, 0.1116, 0.1116]\n",
    "# 0.5 [0.4763, 0.2619, 0.2619\n",
    "# 1 [0.3389, 0.3305, 0.3305],\n",
    "for minibatch in maze_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    print(minibatch.device)\n",
    "    D = C*H*W\n",
    "    minibatch = minibatch.view(B, D)\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) * 0.25\n",
    "    #ts = torch.linspace(0.01, 1, B, device=device)\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()].view(-1, S)\n",
    "    print(qt0_rows_reg)# , qt0)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu()* 127.5, n=B) # * 127.5\n",
    "    show_images(x_tilde.detach().cpu() * 127.5, n=B) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W).detach().cpu() * 127.5, n=B) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for minibatch in maze_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu()* 127.5, n=8) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "D= 1\n",
    "S = 256\n",
    "x = torch.randint(low=0, high=S, size=(B, D))\n",
    "print(x.shape)\n",
    "x = F.one_hot(x.long(), S)\n",
    "out = x.permute(0, 2, 1).float()\n",
    "print(out.shape, type(out))\n",
    "#out = x\n",
    "lin = nn.Conv1d(S, 256*2, kernel_size=9, padding=4)\n",
    "print(lin(out).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.utils.utils as utils\n",
    "cfg.model.rate_const = 0.5\n",
    "cfg.model.t_func = \"log\"\n",
    "cfg.model.time_base = 5\n",
    "cfg.model.time_exp = 5\n",
    "model = UniformRate(cfg, 'cuda')\n",
    "model = UniformVariantRate(cfg, 'cuda')\n",
    "device = 'cpu'\n",
    "S = 3\n",
    "min_time = 0.01\n",
    "\n",
    "\n",
    "for minibatch in mnist_dataset:\n",
    "    \n",
    "\n",
    "    if len(minibatch.shape) == 4:\n",
    "        B, C, H, W = minibatch.shape\n",
    "        minibatch = minibatch.view(B, C * H * W)\n",
    "    # hollow xt, t, l_all, l_xt geht rein\n",
    "    B = minibatch.shape[0]\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - min_time) + min_time\n",
    "    ts = torch.ones((B,)) * 1\n",
    "    print(ts[:9])\n",
    "    #\n",
    "\n",
    "    qt0 = model.transition(ts)  # (B, S, S)\n",
    "\n",
    "    # rate = model.rate(ts)  # (B, S, S)\n",
    "\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "\n",
    "    # log loss\n",
    "    log_qt0 = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0))\n",
    "    x_tilde = torch.distributions.categorical.Categorical(\n",
    "        logits=log_qt0\n",
    "    ).sample()  # bis hierhin <1 sek\n",
    "\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "    print(torch.mean(x_tilde[1,:, :, :].float()))\n",
    "    #print(x_tilde[0,0, :, :].std())\n",
    "    show_images(minibatch.view(B, C, H, W) * 127.5, n=9)\n",
    "    show_images(x_tilde * 127.5, n=9)\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W) * 127.5, n=9)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int log(t**2 + 1)\n",
    "t = np.linspace(0.01, 1, 1000)\n",
    "f = 2 * t / (t**2 + 1)\n",
    "f_int = np.log(t**2 + 1)\n",
    "f_cos = np.sin(t) / np.sqrt(np.cos(t))\n",
    "a = 5\n",
    "b = 5\n",
    "f_log = a * np.log(b) * b**t\n",
    "plt.plot(f, label='log sqr')\n",
    "plt.plot(f_int, label='int log sqr')\n",
    "plt.plot(f_cos, label='cos')\n",
    "plt.plot(f_log, label='log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
