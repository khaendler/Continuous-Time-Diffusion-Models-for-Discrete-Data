{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code by David Roberts https://www.kaggle.com/code/davidbroberts/tensorflow-transfer-learning/notebook\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Set the log level to keep the warnings down\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import lib.datasets.maze as maze \n",
    "import lib.datasets.mnist as mnist\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "from lib.models.models import UniformRate, UniformVariantRate, GaussianTargetRate\n",
    "import lib.utils.utils as utils\n",
    "import numpy as np\n",
    "from lib.datasets import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "def show_images(images, n=8):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0).numpy().astype(\"uint8\"), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.mnist_config.config_bert_mnist import get_config\n",
    "cfg = get_config()\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "mnist_dataset = dataset_utils.get_dataset(cfg, device, cfg.data.location)\n",
    "cfg.data.batch_size = 10\n",
    "mnist_dl = DataLoader(mnist_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.rate_const = 0.1 #0.00009\n",
    "cfg.model.t_func = \"log\"\n",
    "\n",
    "cfg.model.time_base = 3\n",
    "cfg.model.time_exp = 100\n",
    "cfg.model.rate_sigma = 6.0\n",
    "cfg.model.Q_sigma = 512.0\n",
    "#model = UniformRate(cfg, device)\n",
    "model = UniformVariantRate(cfg, device)\n",
    "# model = GaussianTargetRate(cfg, device)\n",
    "S = 256\n",
    "\n",
    "\n",
    "for minibatch in mnist_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    print(minibatch.device)\n",
    "    D = C*H*W\n",
    "    minibatch = minibatch.view(B, D).to('cpu')\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) *1\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "    print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu(), n=9) # * 127.5\n",
    "    show_images(x_tilde.detach().cpu(), n=9) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W).detach().cpu(), n=9) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.maze_config.config_hollow_maze import get_config\n",
    "cfg = get_config()\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "maze_dataset = dataset_utils.get_dataset(cfg, device)\n",
    "cfg.data.batch_size = 6\n",
    "maze_dl = DataLoader(maze_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Time points tensor([1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([[0.3389, 0.3305, 0.3305],\n",
      "        [0.3305, 0.3389, 0.3305],\n",
      "        [0.3389, 0.3305, 0.3305],\n",
      "        ...,\n",
      "        [0.3389, 0.3305, 0.3305],\n",
      "        [0.3305, 0.3389, 0.3305],\n",
      "        [0.3389, 0.3305, 0.3305]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg.model.rate_const = 2.3 # 2.3 log_sqr t=0.5T 0.4763, 0.2619, 0.2619\n",
    "cfg.model.t_func = \"log_sqr\"\n",
    "cfg.model.time_base = 1\n",
    "cfg.model.time_exp = 250\n",
    "#model = UniformRate(cfg, 'cuda')\n",
    "model = UniformVariantRate(cfg, 'cuda')\n",
    "S = 3\n",
    "\n",
    "\n",
    "for minibatch in maze_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    print(minibatch.device)\n",
    "    D = C*H*W\n",
    "    minibatch = minibatch.view(B, D)\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) * 1\n",
    "    #ts = torch.linspace(0.01, 1, B, device=device)\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()].view(-1, S)\n",
    "    print(qt0_rows_reg)# , qt0)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu()* 127.5, n=B) # * 127.5\n",
    "    show_images(x_tilde.detach().cpu() * 127.5, n=B) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W).detach().cpu() * 127.5, n=B) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3**0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.utils.utils as utils\n",
    "cfg.model.rate_const = 0.5\n",
    "cfg.model.t_func = \"log\"\n",
    "cfg.model.time_base = 5\n",
    "cfg.model.time_exp = 5\n",
    "model = UniformRate(cfg, 'cuda')\n",
    "model = UniformVariantRate(cfg, 'cuda')\n",
    "device = 'cpu'\n",
    "S = 3\n",
    "min_time = 0.01\n",
    "\n",
    "\n",
    "for minibatch in mnist_dataset:\n",
    "    \n",
    "\n",
    "    if len(minibatch.shape) == 4:\n",
    "        B, C, H, W = minibatch.shape\n",
    "        minibatch = minibatch.view(B, C * H * W)\n",
    "    # hollow xt, t, l_all, l_xt geht rein\n",
    "    B = minibatch.shape[0]\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - min_time) + min_time\n",
    "    ts = torch.ones((B,)) * 1\n",
    "    print(ts[:9])\n",
    "    #\n",
    "\n",
    "    qt0 = model.transition(ts)  # (B, S, S)\n",
    "\n",
    "    # rate = model.rate(ts)  # (B, S, S)\n",
    "\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "\n",
    "    # log loss\n",
    "    log_qt0 = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0))\n",
    "    x_tilde = torch.distributions.categorical.Categorical(\n",
    "        logits=log_qt0\n",
    "    ).sample()  # bis hierhin <1 sek\n",
    "\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "    print(torch.mean(x_tilde[1,:, :, :].float()))\n",
    "    #print(x_tilde[0,0, :, :].std())\n",
    "    show_images(minibatch.view(B, C, H, W) * 127.5, n=9)\n",
    "    show_images(x_tilde * 127.5, n=9)\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W) * 127.5, n=9)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
