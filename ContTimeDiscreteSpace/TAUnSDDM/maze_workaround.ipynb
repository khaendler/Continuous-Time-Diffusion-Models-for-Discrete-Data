{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lib.datasets.synthetic as synthetic\n",
    "import torchvision\n",
    "import lib.datasets.maze as maze \n",
    "import lib.datasets.mnist as mnist\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "from lib.models.models import UniformRate, UniformVariantRate, GaussianTargetRate\n",
    "import lib.utils.utils as utils\n",
    "import numpy as np\n",
    "from lib.datasets import dataset_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "def show_images(images, n=8):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0).numpy().astype(\"uint8\"), cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_samples(samples, im_size=0, axis=False, im_fmt=None):\n",
    "    \"\"\"Plot samples.\"\"\"\n",
    "    plt.scatter(samples[:, 0], samples[:, 1], marker=\".\")\n",
    "    plt.axis(\"equal\")\n",
    "    if im_size > 0:\n",
    "        plt.xlim(-im_size, im_size)\n",
    "        plt.ylim(-im_size, im_size)\n",
    "    if not axis:\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.eye(10)\n",
    "a[2, 2] = 0\n",
    "a[-1, 1] = 2\n",
    "print(a)\n",
    "arr = np.rot90(a)\n",
    "print(arr)\n",
    "c = np.flip(a, axis=1)\n",
    "b = np.transpose(a)\n",
    "c = np.flip(a.T, axis=0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets.maze import maze_gen\n",
    "from config.maze_config.config_hollow_maze import get_config\n",
    "cfg = get_config()\n",
    "mazes =maze_gen(\n",
    "            limit=50,\n",
    "            device='cuda',\n",
    "            crop=False,\n",
    "            random_transform=cfg.data.random_transform,\n",
    "            dim_x=7,\n",
    "            dim_y=7,\n",
    "            pixelSizeOfTile=1,\n",
    "            weightHigh=99,\n",
    "            weightLow=97,\n",
    "        )\n",
    "show_images(mazes.detach().cpu(), n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.maze_config.config_bert_maze import get_config\n",
    "cfg = get_config()\n",
    "model = model_utils.create_model(cfg, cfg.device)\n",
    "print(\"Number of Parameters: \", sum([p.numel() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.networks.ddsm_networks import ProteinScoreNet\n",
    "from config.maze_config.config_hollow_maze import get_config\n",
    "cfg = get_config()\n",
    "cfg.device = 'cuda'\n",
    "\n",
    "\n",
    "\n",
    "D = cfg.model.concat_dim = 1024\n",
    "S = cfg.data.S = 5\n",
    "B = cfg.data.batch_size\n",
    "net = ProteinScoreNet(cfg).to(cfg.device)\n",
    "ts = torch.rand((B,), device=cfg.device) * (1.0 - 0.01) + 0.01\n",
    "x = torch.randint(low=0, high=S, size=(B, D), device='cuda')\n",
    "x_out = net(x, ts)\n",
    "print(x_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.mnist_config.config_bert_mnist import get_config\n",
    "cfg = get_config()\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "mnist_dataset = dataset_utils.get_dataset(cfg, device, cfg.data.location)\n",
    "cfg.data.batch_size = 10\n",
    "mnist_dl = DataLoader(mnist_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.synthetic_config.config_ebm_synthetic import get_config\n",
    "cfg = get_config()\n",
    "location = \"lib/datasets/Synthetic/data_2spirals.npy\"\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "mnist_dataset = dataset_utils.get_dataset(cfg, device, location)\n",
    "cfg.data.batch_size = 1000\n",
    "mnist_dl = DataLoader(mnist_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.rate_const = 2.5 #0.00009\n",
    "cfg.model.t_func = \"log_sqr\"\n",
    "#model = UniformRate(cfg, device)\n",
    "model = UniformVariantRate(cfg, device)\n",
    "# model = GaussianTargetRate(cfg, device)\n",
    "S = 2\n",
    "bm, inv_bm = synthetic.get_binmap(cfg.model.concat_dim, cfg.data.binmode)\n",
    "\n",
    "for minibatch in mnist_dl:\n",
    "    print(minibatch.device)\n",
    "    B, D = minibatch.shape\n",
    "    minibatch = minibatch.view(B, D).to('cpu')\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) * 1\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "    print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = synthetic.bin2float(x_tilde.detach().cpu().numpy().astype(np.int32), inv_bm, cfg.model.concat_dim, cfg.data.int_scale)\n",
    "    minibatch = synthetic.bin2float(minibatch.detach().cpu().numpy().astype(np.int32), inv_bm, cfg.model.concat_dim, cfg.data.int_scale)\n",
    "    plot_samples(minibatch) # * 127.5\n",
    "    plot_samples(x_tilde) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    #noise_x = synthetic.bin2float(noise_x.detach().cpu().numpy().astype(np.int32), inv_bm, cfg.model.concat_dim, cfg.data.int_scale)\n",
    "    #plot_samples(noise_x) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.rate_const = 0.1 #0.00009\n",
    "cfg.model.t_func = \"log\"\n",
    "\n",
    "cfg.model.time_base = 3\n",
    "cfg.model.time_exp = 100\n",
    "cfg.model.rate_sigma = 6.0\n",
    "cfg.model.Q_sigma = 512.0\n",
    "#model = UniformRate(cfg, device)\n",
    "model = UniformVariantRate(cfg, device)\n",
    "# model = GaussianTargetRate(cfg, device)\n",
    "S = 256\n",
    "\n",
    "\n",
    "for minibatch in mnist_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    print(minibatch.device)\n",
    "    D = C*H*W\n",
    "    minibatch = minibatch.view(B, D).to('cpu')\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) *1\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "    print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu(), n=9) # * 127.5\n",
    "    show_images(x_tilde.detach().cpu(), n=9) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W).detach().cpu(), n=9) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.maze_config.config_hollow_maze import get_config\n",
    "cfg = get_config()\n",
    "device = cfg.device \n",
    "device = 'cuda'\n",
    "maze_dataset = dataset_utils.get_dataset(cfg, device)\n",
    "cfg.data.batch_size = 10\n",
    "maze_dl = DataLoader(maze_dataset,\n",
    "                                cfg.data.batch_size, shuffle=cfg.data.shuffle,\n",
    "                                num_workers=0)\n",
    "                                #worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Time points tensor([0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500],\n",
      "       device='cuda:0')\n",
      "tensor([[0.7721, 0.1139, 0.1139],\n",
      "        [0.1139, 0.7721, 0.1139],\n",
      "        [0.7721, 0.1139, 0.1139],\n",
      "        ...,\n",
      "        [0.7721, 0.1139, 0.1139],\n",
      "        [0.7721, 0.1139, 0.1139],\n",
      "        [0.7721, 0.1139, 0.1139]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg.model.rate_const = 2.3 # 2.3 log_sqr t=0.5T 0.4763, 0.2619, 0.2619\n",
    "cfg.model.t_func = \"log_sqr\"\n",
    "cfg.model.time_base = 1\n",
    "cfg.model.time_exp = 250\n",
    "#model = UniformRate(cfg, 'cuda')\n",
    "model = UniformVariantRate(cfg, 'cuda')\n",
    "S = 3\n",
    "# 0.25 [0.7867, 0.1116, 0.1116]\n",
    "# 0.5 [0.4763, 0.2619, 0.2619\n",
    "# 1 [0.3389, 0.3305, 0.3305],\n",
    "for minibatch in maze_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    print(minibatch.device)\n",
    "    D = C*H*W\n",
    "    minibatch = minibatch.view(B, D)\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - 0.01) + 0.01\n",
    "    ts = torch.ones((B,), device=device) * 0.25\n",
    "    #ts = torch.linspace(0.01, 1, B, device=device)\n",
    "    print(\"Time points\", ts[:9])\n",
    "\n",
    "    qt0 = model.transition(\n",
    "        ts\n",
    "    )  # (B, S, S) # transition q_{t | s=0} eq.15 => here randomness because of ts => for every ts another q_{t|0}\n",
    "\n",
    "    # R_t = beta_t * R_b\n",
    "    rate = model.rate(\n",
    "        ts\n",
    "    )  # (B, S, S) # no proability in here (diagonal = - sum of rows)\n",
    "\n",
    "\n",
    "    qt0_rows_reg = qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(\n",
    "            D\n",
    "        ),  # repeats every element 0 to B-1 D-times\n",
    "        minibatch.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "        :,\n",
    "    ]  # (B*D, S)\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()].view(-1, S)\n",
    "    print(qt0_rows_reg)# , qt0)\n",
    "    # set of (B*D) categorical distributions with probabilities from qt0_rows_reg\n",
    "    x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "    x_t = x_t_cat.sample().view(  # sampling B * D times => from every row of qt0_rows_reg once => then transform it to shape B, D\n",
    "        B, D\n",
    "    )  # (B*D,) mit view => (B, D) Bsp: x_t = (0, 1, 2, 4, 3) (for B =1 )\n",
    "\n",
    "    rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]  # (B*D, S)\n",
    "\n",
    "    rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0  # - values = 0 => in rate_vals_square[0, 1] = 0\n",
    "\n",
    "    rate_vals_square = rate_vals_square.view(B, D, S)  # (B*D, S) => (B, D, S)\n",
    "\n",
    "        #  Summe der Werte entlang der Dimension S\n",
    "    rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(\n",
    "        B, D\n",
    "    )  # B, D with every entry = S-1? => for entries of x_t same prob to transition?\n",
    "    square_dimcat = torch.distributions.categorical.Categorical(\n",
    "        rate_vals_square_dimsum\n",
    "    )\n",
    "\n",
    "\n",
    "    square_dims = square_dimcat.sample()  # (B,) taking values in [0, D)\n",
    "\n",
    "    rate_new_val_probs = rate_vals_square[\n",
    "        torch.arange(B, device=device), square_dims, :\n",
    "    ]  # (B, S) => every row has only one entry = 0, everywhere else 1; chooses the row square_dim of rate_vals_square\n",
    "    # => now rate_new_val_probs: (B, S) with every row (1, 1, 0)\n",
    "\n",
    "    # samples from rate_new_val_probs and chooses state to transition to => more likely where entry is 1 instead of 0?\n",
    "    square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "        rate_new_val_probs\n",
    "    )\n",
    "\n",
    "    square_newval_samples = (\n",
    "        square_newvalcat.sample()\n",
    "    )  # (B, ) taking values in [0, S)\n",
    "\n",
    "\n",
    "    x_tilde = x_t.clone()\n",
    "    x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu()* 127.5, n=B) # * 127.5\n",
    "    show_images(x_tilde.detach().cpu() * 127.5, n=B) # * 127.5\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W).detach().cpu() * 127.5, n=B) # * 127.5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for minibatch in maze_dl:\n",
    "    B, C, H, W = minibatch.shape\n",
    "    show_images(minibatch.view(B, C, H, W).detach().cpu()* 127.5, n=8) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "D= 1\n",
    "S = 256\n",
    "x = torch.randint(low=0, high=S, size=(B, D))\n",
    "print(x.shape)\n",
    "x = F.one_hot(x.long(), S)\n",
    "out = x.permute(0, 2, 1).float()\n",
    "print(out.shape, type(out))\n",
    "#out = x\n",
    "lin = nn.Conv1d(S, 256*2, kernel_size=9, padding=4)\n",
    "print(lin(out).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.utils.utils as utils\n",
    "cfg.model.rate_const = 0.5\n",
    "cfg.model.t_func = \"log\"\n",
    "cfg.model.time_base = 5\n",
    "cfg.model.time_exp = 5\n",
    "model = UniformRate(cfg, 'cuda')\n",
    "model = UniformVariantRate(cfg, 'cuda')\n",
    "device = 'cpu'\n",
    "S = 3\n",
    "min_time = 0.01\n",
    "\n",
    "\n",
    "for minibatch in mnist_dataset:\n",
    "    \n",
    "\n",
    "    if len(minibatch.shape) == 4:\n",
    "        B, C, H, W = minibatch.shape\n",
    "        minibatch = minibatch.view(B, C * H * W)\n",
    "    # hollow xt, t, l_all, l_xt geht rein\n",
    "    B = minibatch.shape[0]\n",
    "    ts = torch.rand((B,), device=device) * (1.0 - min_time) + min_time\n",
    "    ts = torch.ones((B,)) * 1\n",
    "    print(ts[:9])\n",
    "    #\n",
    "\n",
    "    qt0 = model.transition(ts)  # (B, S, S)\n",
    "\n",
    "    # rate = model.rate(ts)  # (B, S, S)\n",
    "\n",
    "    b = utils.expand_dims(torch.arange(B, device=device), (tuple(range(1, minibatch.dim()))))\n",
    "    qt0 = qt0[b, minibatch.long()]\n",
    "\n",
    "    # log loss\n",
    "    log_qt0 = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0))\n",
    "    x_tilde = torch.distributions.categorical.Categorical(\n",
    "        logits=log_qt0\n",
    "    ).sample()  # bis hierhin <1 sek\n",
    "\n",
    "    x_tilde = x_tilde.view(B, C, H, W)\n",
    "    print(torch.mean(x_tilde[1,:, :, :].float()))\n",
    "    #print(x_tilde[0,0, :, :].std())\n",
    "    show_images(minibatch.view(B, C, H, W) * 127.5, n=9)\n",
    "    show_images(x_tilde * 127.5, n=9)\n",
    "    noise_x = torch.randint(low=0, high=S, size=(B, D), device=device)\n",
    "    show_images(noise_x.view(B, C, H, W) * 127.5, n=9)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int log(t**2 + 1)\n",
    "t = np.linspace(0.01, 1, 1000)\n",
    "f = 2 * t / (t**2 + 1)\n",
    "f_int = np.log(t**2 + 1)\n",
    "f_cos = np.sin(t) / np.sqrt(np.cos(t))\n",
    "a = 5\n",
    "b = 5\n",
    "f_log = a * np.log(b) * b**t\n",
    "plt.plot(f, label='log sqr')\n",
    "plt.plot(f_int, label='int log sqr')\n",
    "plt.plot(f_cos, label='cos')\n",
    "plt.plot(f_log, label='log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
