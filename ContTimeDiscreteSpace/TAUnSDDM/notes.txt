Rechnerisch Rate: 1.54 nach Sebastian
Minimizing L_CT loss => wird nicht 0, da abhängig von Rate
Je kleiner die Rate desto kleiner der loss => heißt nicht dass besser lernt
=> R=0.001 schlechter nach 3000 iter als R=0.7

bei CatRM:
Loss bei geringerer Rate auch geringer bei Maze: 0.001, 0.1, 1.5 
Plots bei 0.001 am schlechtesten bzw. R=1.54
=> reicht nicht Endverteilung anzusehen; vll am Ende bei t=T nahe zu Uniform Rate. aber bei t=0.5*T auch
Loss aber nicht abhängig von Rate?

MAZE: Je nach Performance: log_sqr mit Rate=2.3
MNIST Images: GaussianRate sigma_0 = 512, sigma_r = 6, beta(t) = 3*100^t log(100)

Tau schlechter als LBJF?

Maze: 
Hollow ab 200999 => mazes from 97, 97 to 99, 98
Problem Evaluierung:
Nur ein Solution Path
Solution Path gefunden und nur diesen Markiert

Problem Modell Architekturen:
Hollow muss immer Transformer-artig sein wegen Masking
Masked: MLP, Transformer, ResNet
CT-ELBO: Alles

Trade-Off: Flexibility und Speed:
Ursprüngliche Idee:
Masked Models und ELBO gleiches Modell und Hollow=Hollow
Maze => Unet gut:
Masked Modell kein Unet möglich?=> Nehme 12-layer Bert 
=> Schlechter als Hollow: Vll ist Architektur aber einfach nur schlechter und ich 
könnte ja auch ein BiDir nehmen?

=> Wenn ich aber bei allen gleiche Modell nehme, 
ja auch irgendwie doof => will ja flexibility nutzen

MNIST: 
CT-ELBO: Unet
Masked Model: 12-layer Bert?
Hollow: Hollow


Archi Fragen:
Kann ich Unet für Masked Models?
Kann ich BiDir für Masked Models? => theoretisch ja bringt 
aber nicht wirklich Mehrwert: Mache ja 2 Richtungen nur wegen Masking 

Bert nochmal mit tiefere Hidden Dim und weniger ResBlock layers? => heute nacht


Synthetic:
EBM: Stärke bei schwierigen Daten durch Flexibilität, 
aber genau da auch  Nachteil, da meist schwierige Datem hohe D und C und EBM O(DxC)


Auswertung:
Ziel: 
Mit den 2 Continuous Time Diffusion Model Framework diskrete Daten erzeugen 
und dabei herausfinden, welches Framework wann besser ist und wo es Verbesserungsansätze gibt (diese eventuell umsetzen)

Fragestellung:
Wie kann ich wissenschaftlich konsistent vergleichen?

Vergleichsebenen:
Framework an sich: CT-ELBO <=> CRM 
Architektur: Beliebig <=> CRM hat Architektur constraints und damit verschiedenen Parametrisierungsmöglichkeiten:
                        Tradeoff zwischen Speed und Flexibilität:
                        => EBM: arbiträr NN, aber O(DxC) Feedforward Evaluations
                        => Masked Model: Masking begrenzt NN (immer noch sehr flexibel), aber O(D)
                        => HollowTransformer: Nur BiDirectional Transformer mit masked Jacobi Matrix, aber nur O(1)
Sampling: Euler, Tau Leaping <=> CRM hat durch constraints auch neue Sampling Methode


Fragestellung:
Wie wähle ich nun Modellarchitekturen und nutze dabei die Vorteile(Flexibilität) der Parametrisierungen aus, um konsistent über verschiedene Datensätze vergleiche zu können?
(Vergleich anhand verschiedener Datensätze, da möglich, dass ein Framework bei geringerer Datendimension oder Anzahl der State Spaces besser ist)

Überlegungen:
Vorwissen einbringen: Unet am besten für MNIST, eventuell für Maze auch
CT-ELBO: Ich sollte best mögliches Modell nehmen, was es gibt für diese Task, da ich die Möglichkeit habe, diese Flexibilität zu nutzen => MNIST: MAZE
CRM: Masked Model: best mögliches Modell nehmen 

=> Gut, wenn best mögliche Modell für Masked Model und ELBO bei einem Datensatz gleich ist.
=> Problem bei MNIST? ELBO kann Unet nutzen,  


Datensatz Synthetic: D=32, S=2
Einfaches Datenset: Ansätze verifyen? Verargumentieren, dass es bessere Tradeoffs als EBM
CRM Paper: Nimmt für alle Modelle einen 3 Layer Transformer => schneiden ähnlich ab => Masked Models + HollowTransformer eher nutzen, da geringere FFEvaluations

Datensatz Maze: D=225, S=3
ELBO: Unet, 12-layer Bert + ResNet <=>  Masked Model erlaubt kein Standard Unet, 12-layer Bert + ResNet, HollowTransformer

Datensatz MNIST: D=28*28, S=256
Unet <=> Masked Model erlaubt kein Standard Unet, HollowTransformer

Datensatz ProteinSequenzen: D=48, S=21
Unet Style Architecture <=> Unet Style Architecture, HollowTransformer
(anderes Paper hat für DNA Sequenzen so eine Unet Style Architecture)


=> Wenn ich jedes Mal für Masked Model und ELBO anderes Model nehme, dann habe ich die Flexibilität dieser Parametrisierungen drin  
(Nach dem Motto, wenn es ein besseres Modell gibt, nehme ich das)

Sollte ich immer für ELBO und Masked Model die gleichen Modelle nehmen oder sollte ich ausnutzen, dass dieses Framework noch freiere Modelle erlauben? 
Wie vergleiche ich dann?

ToDo:
Testweise Bilder einfügen
Bert, Hollow Transformer beschreiben