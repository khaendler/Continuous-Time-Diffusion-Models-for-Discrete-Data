{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulheller/PythonRepositories/Master-Thesis/diffvenv/lib/python3.10/site-packages/cooltools/lib/numutils.py:652: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def iterative_correction_symmetric(\n",
      "/Users/paulheller/PythonRepositories/Master-Thesis/diffvenv/lib/python3.10/site-packages/cooltools/lib/numutils.py:727: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def iterative_correction_asymmetric(x, max_iter=1000, tol=1e-5, verbose=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples 10000 256\n",
      "started first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 13/400 [13:43<6:48:35, 63.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m beta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(config\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnum_cat \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mn_samples\u001b[39m\u001b[39m\"\u001b[39m, config\u001b[39m.\u001b[39mnoise_sample\u001b[39m.\u001b[39mn_samples, config\u001b[39m.\u001b[39mnoise_sample\u001b[39m.\u001b[39mnum_cat)\n\u001b[0;32m---> 40\u001b[0m v_one, v_zero, v_one_loggrad, v_zero_loggrad, timepoints \u001b[39m=\u001b[39m noise_factory(\n\u001b[1;32m     41\u001b[0m     config\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49mn_samples,\n\u001b[1;32m     42\u001b[0m     config\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49mn_time_steps,\n\u001b[1;32m     43\u001b[0m     alpha,\n\u001b[1;32m     44\u001b[0m     beta,\n\u001b[1;32m     45\u001b[0m     total_time\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49mmax_time,\n\u001b[1;32m     46\u001b[0m     order\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49morder,\n\u001b[1;32m     47\u001b[0m     time_steps\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49msteps_per_tick,\n\u001b[1;32m     48\u001b[0m     logspace\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49mlogspace,\n\u001b[1;32m     49\u001b[0m     speed_balanced\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49mspeed_balance,\n\u001b[1;32m     50\u001b[0m     mode\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnoise_sample\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m v_one \u001b[39m=\u001b[39m v_one\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     54\u001b[0m v_zero \u001b[39m=\u001b[39m v_zero\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/PythonRepositories/Master-Thesis/ContTimeDiscreteSpace/DDSM/lib/models/ddsm.py:194\u001b[0m, in \u001b[0;36mnoise_factory\u001b[0;34m(N, n_time_steps, a, b, total_time, order, time_steps, speed_balanced, logspace, mode, device)\u001b[0m\n\u001b[1;32m    184\u001b[0m             noise_factory_zero[:, i, :] \u001b[39m=\u001b[39m Jacobi_Euler_Maruyama_sampler(\n\u001b[1;32m    185\u001b[0m                 noise_factory_zero[:, i, :],\n\u001b[1;32m    186\u001b[0m                 a,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m    192\u001b[0m             )\n\u001b[1;32m    193\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m             noise_factory_one[:, i, :] \u001b[39m=\u001b[39m Jacobi_Euler_Maruyama_sampler(\n\u001b[1;32m    195\u001b[0m                 noise_factory_one[:, i \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, :],\n\u001b[1;32m    196\u001b[0m                 a,\n\u001b[1;32m    197\u001b[0m                 b,\n\u001b[1;32m    198\u001b[0m                 timepoints[i] \u001b[39m-\u001b[39;49m timepoints[i \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m],\n\u001b[1;32m    199\u001b[0m                 time_steps,\n\u001b[1;32m    200\u001b[0m                 speed_balanced\u001b[39m=\u001b[39;49mspeed_balanced,\n\u001b[1;32m    201\u001b[0m                 device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    202\u001b[0m             )\n\u001b[1;32m    203\u001b[0m             noise_factory_zero[:, i, :] \u001b[39m=\u001b[39m Jacobi_Euler_Maruyama_sampler(\n\u001b[1;32m    204\u001b[0m                 noise_factory_zero[:, i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, :],\n\u001b[1;32m    205\u001b[0m                 a,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m    211\u001b[0m             )\n\u001b[1;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonRepositories/Master-Thesis/ContTimeDiscreteSpace/DDSM/lib/models/ddsm.py:121\u001b[0m, in \u001b[0;36mJacobi_Euler_Maruyama_sampler\u001b[0;34m(x0, a, b, t, num_steps, speed_balanced, device, eps)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    120\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m time_steps:\n\u001b[0;32m--> 121\u001b[0m         x_next \u001b[39m=\u001b[39m step(x, step_size)\n\u001b[1;32m    122\u001b[0m         x_next \u001b[39m=\u001b[39m x_next\u001b[39m.\u001b[39mclip(eps, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m eps)\n\u001b[1;32m    123\u001b[0m         x \u001b[39m=\u001b[39m x_next\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os.path\n",
    "import torch\n",
    "from lib.models.ddsm import noise_factory\n",
    "from lib.config.config_mnist import get_config\n",
    "from lib.sampling.sampling_utils import importance_sampling\n",
    "import torch\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import os\n",
    "from lib.datasets.datasets import get_mnist_dataset\n",
    "from lib.sampling.sampling_utils import importance_sampling\n",
    "# Main file which contrains all DDSM logic\n",
    "from lib.models.ddsm import *\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "if not os.path.exists(config.noise_sample.out_path):\n",
    "    os.makedirs(config.noise_sample.out_path)\n",
    "elif not os.path.isdir(config.noise_sample.out_path):\n",
    "    print(f\"{config.out_path} is already exists and it is not a directory\")\n",
    "    exit(1)\n",
    "\n",
    "str_speed = \".speed_balance\" if config.noise_sample.speed_balance  else \"\"\n",
    "filename = (\n",
    "    f\"mnist_steps{config.noise_sample.n_time_steps}.cat{config.noise_sample.num_cat}{str_speed}.time{config.noise_sample.max_time}.\"\n",
    "    f\"samples{config.noise_sample.n_samples}\"\n",
    ")\n",
    "filepath = os.path.join(config.noise_sample.out_path, filename + \".pth\")\n",
    "\n",
    "if os.path.exists(filepath):\n",
    "    print(\"File is already exists.\")\n",
    "    exit(1)\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "alpha = torch.ones(config.data.num_cat - 1)\n",
    "beta = torch.arange(config.data.num_cat - 1, 0, -1)\n",
    "print(\"n_samples\", config.noise_sample.n_samples, config.noise_sample.num_cat)\n",
    "v_one, v_zero, v_one_loggrad, v_zero_loggrad, timepoints = noise_factory(\n",
    "    config.noise_sample.n_samples,\n",
    "    config.noise_sample.n_time_steps,\n",
    "    alpha,\n",
    "    beta,\n",
    "    total_time=config.noise_sample.max_time,\n",
    "    order=config.noise_sample.order,\n",
    "    time_steps=config.noise_sample.steps_per_tick,\n",
    "    logspace=config.noise_sample.logspace,\n",
    "    speed_balanced=config.noise_sample.speed_balance,\n",
    "    mode=config.noise_sample.mode,\n",
    ")\n",
    "\n",
    "v_one = v_one.cpu()\n",
    "v_zero = v_zero.cpu()\n",
    "v_one_loggrad = v_one_loggrad.cpu()\n",
    "v_zero_loggrad = v_zero_loggrad.cpu()\n",
    "timepoints = torch.FloatTensor(timepoints)\n",
    "\n",
    "torch.save((v_one, v_zero, v_one_loggrad, v_zero_loggrad, timepoints), filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = UnitStickBreakingTransform()\n",
    "if config.use_fast_diff:\n",
    "    diffuser_func = partial(\n",
    "        diffusion_fast_flatdirichlet,\n",
    "        noise_factory_one=v_one,\n",
    "        v_one_loggrad=v_one_loggrad,\n",
    "    )\n",
    "else:\n",
    "    diffuser_func = partial(\n",
    "        diffusion_factory,\n",
    "        noise_factory_one=v_one,\n",
    "        noise_factory_zero=v_zero,\n",
    "        noise_factory_one_loggrad=v_one_loggrad,\n",
    "        noise_factory_zero_loggrad=v_zero_loggrad,\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        device=config.device,\n",
    "    )\n",
    "\n",
    "\n",
    "if config.speed_balanced:\n",
    "    s = 2 / (\n",
    "        torch.ones(config.data.num_cat - 1, device=config.device)\n",
    "        + torch.arange(config.data.num_cat - 1, 0, -1, device=config.device).float()\n",
    "    )\n",
    "else:\n",
    "    s = torch.ones(config.data.num_cat - 1, device=config.device)\n",
    "\n",
    "if not os.path.exists(config.saving.time_dep_weights_path):\n",
    "    os.makedirs(config.saving.time_dep_weights_path)\n",
    "str_speed = \".speed_balance\" if config.speed_balanced  else \"\"\n",
    "str_random_order = \".random_order\" if config.random_order else \"\"\n",
    "filename = (f\"time_depend_weights_steps{config.n_time_steps}.cat{config.data.num_cat}{str_speed}{str_random_order}\")\n",
    "filepath = os.path.join(config.saving.time_dep_weights_path, filename + \".pth\")\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = get_mnist_dataset(config)\n",
    "time_dependent_weights = importance_sampling(config, train_dataloader,  diffuser_func, sb, s)\n",
    "torch.save(time_dependent_weights, filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
