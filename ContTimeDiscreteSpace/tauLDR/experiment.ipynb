{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ml_collections\n",
    "import yaml\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import signal\n",
    "import argparse\n",
    "from config.config_train_sample import get_config\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.datasets as datasets\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "from lib.datasets.datasets import (\n",
    "    create_train_discrete_mnist_dataloader,\n",
    "    create_train_discrete_cifar10_dataloader,\n",
    ")\n",
    "\n",
    "import lib.sampling.sampling as sampling\n",
    "import lib.sampling.sampling_utils as sampling_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_config()\n",
    "custom_name = None\n",
    "\n",
    "device = torch.device(cfg.device)\n",
    "save_dir, checkpoint_dir, config_dir = bookkeeping.create_experiment_folder(\n",
    "    cfg.save_location,\n",
    "    cfg.experiment_name if custom_name is None else custom_name,\n",
    "    custom_name is None,\n",
    ")\n",
    "bookkeeping.save_config_as_yaml(cfg, config_dir)\n",
    "\n",
    "model = model_utils.create_model(cfg, device)\n",
    "print(\"number of parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "# dataset = dataset_utils.get_dataset(cfg, device)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.data.batch_size, shuffle=cfg.data.shuffle)\n",
    "dataloader = create_train_discrete_mnist_dataloader(batch_size=32)\n",
    "# dataloader = create_train_discrete_cifar10_dataloader(batch_size=32)\n",
    "loss = losses_utils.get_loss(cfg)\n",
    "\n",
    "training_step = training_utils.get_train_step(cfg)\n",
    "\n",
    "optimizer = optimizers_utils.get_optimizer(model.parameters(), cfg)\n",
    "\n",
    "state = {\"model\": model, \"optimizer\": optimizer, \"n_iter\": 0}\n",
    "\n",
    "n_samples = 9\n",
    "\n",
    "sampler = sampling_utils.get_sampler(cfg)\n",
    "\n",
    "training_loss = []\n",
    "exit_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # for minibatch, _ in tqdm(dataloader):\n",
    "    for minibatch, _ in tqdm(dataloader):\n",
    "        # print(\"minibatch\", minibatch, minibatch.shape)\n",
    "        l = training_step.step(state, minibatch, loss)\n",
    "        print(\"l\", l.item())\n",
    "        training_loss.append(l.item())\n",
    "\n",
    "        # just to save model\n",
    "        if (\n",
    "            state[\"n_iter\"] + 1 % cfg.saving.checkpoint_freq == 0\n",
    "            or state[\"n_iter\"] == cfg.training.n_iters - 1\n",
    "        ):\n",
    "            bookkeeping.save_checkpoint(\n",
    "                checkpoint_dir, state, cfg.saving.num_checkpoints_to_keep\n",
    "            )\n",
    "\n",
    "        if (\n",
    "            state[\"n_iter\"] + 1 % cfg.sampler.sample_freq == 0\n",
    "            or state[\"n_iter\"] == cfg.training.n_iters - 1\n",
    "        ):\n",
    "            state[\"model\"].eval()\n",
    "            samples, x_hist, x0_hist = sampler.sample(state[\"model\"], n_samples, 10)\n",
    "            samples = samples.reshape(n_samples, 1, 32, 32)\n",
    "            #x_hist = x_hist.reshape(10, n_samples, 1, 32, 32)\n",
    "            #x0_hist = x0_hist.reshape(10, n_samples, 1, 32, 32)\n",
    "            state[\"model\"].train()\n",
    "\n",
    "            fig = plt.figure(figsize=(9, 9))  \n",
    "            for i in range(n_samples):\n",
    "                plt.subplot(3, 3, 1 + i)\n",
    "                plt.axis(\"off\")\n",
    "                plt.imshow(np.transpose(samples[i, ...], (1,2,0)), cmap=\"gray\")\n",
    "            \n",
    "\n",
    "            plt.savefig(f\"/Users/paulheller/PythonRepositories/Master-Thesis/ContTimeDiscreteSpace/SavedModels/MNIST/PNGs/samples_epoch_.png\")\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        state[\"n_iter\"] += 1\n",
    "        if state[\"n_iter\"] > cfg.training.n_iters - 1:\n",
    "            exit_flag = True\n",
    "            break\n",
    "\n",
    "    if exit_flag:\n",
    "        break\n",
    "\n",
    "plt.plot(training_loss)\n",
    "plt.title(\"Training loss\")\n",
    "plt.savefig(\n",
    "    \"/Users/paulheller/PythonRepositories/Master-Thesis/ContTimeDiscreteSpace/SavedModels/MNIST/PNGs/training_loss.png\"\n",
    ")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
