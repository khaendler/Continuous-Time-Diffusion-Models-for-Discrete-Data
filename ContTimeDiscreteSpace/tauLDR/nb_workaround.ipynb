{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from lib.models.models import UniformRate\n",
    "import ml_collections\n",
    "from config.config_train_sample import get_config\n",
    "from lib.utils import utils\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now, when we minimize LCT, we are sampling (x, x ̃) from the forward process and then maximizing the assigned model probability for \n",
    "\n",
    "the pairing in the reverse direction, just as in LDT. The slight extra complexity comes from the fact we areconsidering the case \n",
    "\n",
    "when xk = xk+1 and the case when xk ̸= xk+1 separately. When xk = xk+1, this corresponds to the first term in LCT which we can see \n",
    "\n",
    "is minimizing the reverse rate out of x which is exactly maximizing the model probability for no transition to occur. When xk ̸= xk+1, \n",
    "\n",
    "this corresponds to the second term in LCT, which is maximizing the reverse rate from x ̃ to x which in turn maximizes the model probability \n",
    "\n",
    "for the x ̃ to x transition to occur.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fragen Yannick:\n",
    "# Wieso xt samplen from q_t|0 and then one transition to x_tilde => and then logits = net(x_tile, t)\n",
    "#    # q_{t|0} (x ̃|x_0) =>  qt0_numer_reg = qt0.view(B, S, S)\n",
    "\n",
    "# 2 forward passed: p^{θ}_{0|t}(x0|x) to calculate Rˆ{θ}_t(x, x′) and p^{θ}_{0|t}(x0|x ̃) to calculate Rˆ{θ}_t(x ̃, x). This is wasteful\n",
    "rate_const = 1\n",
    "S = 3\n",
    "B = 2\n",
    "D = 4\n",
    "device = 'cpu'\n",
    "rate = rate_const * np.ones((S, S))\n",
    "rate = rate - np.diag(np.diag(rate))\n",
    "#print(rate)\n",
    "rate = rate - np.diag(np.sum(rate, axis=1))\n",
    "\n",
    "#print(rate)\n",
    "rate_matrix = torch.from_numpy(rate).float()\n",
    "\n",
    "rate_matrix = torch.tile(rate_matrix.view(1, S, S), (B, 1, 1))\n",
    "#print(rate_matrix.shape)\n",
    "v = torch.tensor([1, 2, 3])\n",
    "matrix = torch.diag_embed(v)\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Transition matrix q_t|0: x0 -> xt ---------------------\n",
    "cfg = get_config()\n",
    "cfg.data.S = S\n",
    "cfg.model.rate_const = rate_const\n",
    "uni = UniformRate(cfg, 'cpu')\n",
    "ts = torch.rand((B,))\n",
    "qt0 = uni.transition(ts)\n",
    "x0= torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "#print(x0)\n",
    "#print(qt0, qt0.shape)\n",
    "qt0_rows_reg = qt0[\n",
    "    torch.arange(B, device=device).repeat_interleave(\n",
    "        D\n",
    "    ),  # repeats every element 0 to B-1 D-times\n",
    "    x0.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "    :,\n",
    "]\n",
    "print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "b = utils.expand_dims(torch.arange(B), (tuple(range(1, x0.dim()))))\n",
    "qt0_rows_reg2 = qt0[b, x0] #.view(-1, S)\n",
    "\n",
    "logits = torch.where(qt0 <= 0.0, -1e9, torch.log(qt0_rows_reg2))\n",
    "\n",
    "\n",
    "x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "x_t = x_t_cat.sample().view(B, D)\n",
    "print(x_t, x_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- Transition rate: x_t -> x_tilde ------------------\n",
    "rate = uni.rate(ts)\n",
    "#print(rate, rate.shape) # B, S, S\n",
    "rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]\n",
    "#print(rate_vals_square, rate_vals_square.shape)\n",
    "rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0 \n",
    "print(rate_vals_square, rate_vals_square.shape)\n",
    "\n",
    "rate_vals_square = rate_vals_square.view(B, D, S)\n",
    "print(rate_vals_square, rate_vals_square.shape)\n",
    "\n",
    "rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(B, D)\n",
    "print(rate_vals_square_dimsum, rate_vals_square_dimsum.shape)\n",
    "\n",
    "square_dimcat = torch.distributions.categorical.Categorical(rate_vals_square_dimsum)\n",
    "\n",
    "square_dims = square_dimcat.sample() # sampled where transition takes places in every row of B\n",
    "print(\"Where transition\", square_dims, square_dims.shape)\n",
    "\n",
    "rate_new_val_probs = rate_vals_square[\n",
    "    torch.arange(B, device=device), square_dims, :\n",
    "]  # (B, S)\n",
    "print(rate_new_val_probs, rate_new_val_probs.shape)\n",
    "\n",
    "square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "    rate_new_val_probs\n",
    ")\n",
    "\n",
    "# Shape: (B,) mit Werten im Bereich [0, S)\n",
    "square_newval_samples = (\n",
    "    square_newvalcat.sample()\n",
    ")\n",
    "print(\"Transition value\", square_newval_samples, square_newval_samples.shape)\n",
    "\n",
    "x_tilde = x_t.clone()\n",
    "        # noisy image \n",
    "x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "print(x_t)\n",
    "print(x_tilde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------ELBO-------------------\n",
    "mask_reg = torch.ones((B, D, S), device=device)\n",
    "\n",
    "mask_reg[\n",
    "    torch.arange(B, device=device).repeat_interleave(D),\n",
    "    torch.arange(D, device=device).repeat(B),\n",
    "    x_tilde.long().flatten(),\n",
    "] = 0.0\n",
    "print(x_tilde)\n",
    "print(mask_reg, mask_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt0_numer_reg = qt0.view(B, S, S)\n",
    "print(qt0_numer_reg , qt0_numer_reg.shape)\n",
    "# q_{t|0} (x|x_0)\n",
    "qt0_denom_reg = (\n",
    "    qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(D),\n",
    "        :,\n",
    "        x_tilde.long().flatten(),\n",
    "    ].view(B, D, S)\n",
    "    + 1e-6\n",
    ")\n",
    "#print(qt0_denom_reg, qt0_denom_reg.shape)\n",
    "\n",
    "#print(rate, rate.shape)\n",
    "rate_vals_reg = rate[\n",
    "    torch.arange(B, device=device).repeat_interleave(D),\n",
    "    :,\n",
    "    x_tilde.long().flatten(),\n",
    "].view(B, D, S)\n",
    "print(rate_vals_reg, rate_vals_reg.shape)\n",
    "print((mask_reg * rate_vals_reg))\n",
    "reg_tmp = (mask_reg * rate_vals_reg) @ qt0_numer_reg.transpose(1, 2)\n",
    "print(reg_tmp, reg_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_const = 1\n",
    "S = 3\n",
    "B = 2\n",
    "D = 4\n",
    "cfg = get_config()\n",
    "cfg.data.S = S\n",
    "cfg.model.rate_const = rate_const\n",
    "uni = UniformRate(cfg, 'cpu')\n",
    "ts = torch.rand((B,))\n",
    "xt= torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "print(xt)\n",
    "\n",
    "qt0 = uni.transition(ts)\n",
    "\n",
    "qt0_y2x = qt0.permute(0, 2, 1)\n",
    "print(qt0, qt0.shape)\n",
    "print(qt0_y2x, qt0_y2x.shape)\n",
    "print(qt0 == qt0_y2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = utils.expand_dims(\n",
    "    torch.arange(xt.shape[0]), tuple(range(1, xt.dim()))\n",
    ")\n",
    "print(b, b.shape)\n",
    "qt0_y2x = qt0_y2x[b, xt]\n",
    "print(qt0_y2x, qt0_y2x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = qt0_y2x\n",
    "log_p0t = F.log_softmax(logits, dim=-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_qt0 = torch.where(qt0 <= 1e-35, -1e9, torch.log(qt0))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_qt0 = utils.expand_dims(log_qt0, axis=list(range(1, xt.dim())))\n",
    "print(log_qt0, log_qt0.shape)\n",
    "log_p0t = log_p0t.unsqueeze(-1)\n",
    "print(log_p0t, log_p0t.shape)\n",
    "log_prob = torch.logsumexp(log_p0t + log_qt0, dim=-2)\n",
    "print(log_prob, log_prob.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_onehot = F.one_hot(xt.long(), S)\n",
    "qt0 = uni.transition(ts)\n",
    "p0t = F.softmax(logits, dim=-1)\n",
    "print(p0t, p0t.shape)\n",
    "qt0 = utils.expand_dims(qt0, axis=list(range(1, xt.dim() - 1)))\n",
    "print(qt0, qt0.shape)\n",
    "prob_all = p0t @ qt0\n",
    "print(prob_all.shape)\n",
    "log_prob = torch.log(prob_all + 1e-35)\n",
    "print(log_prob, log_prob.shape)\n",
    "log_xt = torch.sum(log_prob * xt_onehot, axis=-1)\n",
    "print(log_xt, log_xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt0 = uni.transition(ts)\n",
    "b = utils.expand_dims(torch.arange(B), (tuple(range(1, x0.dim()))))\n",
    "qt0_rows_reg2 = qt0[b, x0]\n",
    "print(qt0_rows_reg2, qt0_rows_reg2.shape)\n",
    "logits = torch.where(qt0_rows_reg2  <= 0.0, -1e9, torch.log(qt0_rows_reg2))\n",
    "print(logits, logits.shape)\n",
    "\n",
    "x_t_cat = torch.distributions.categorical.Categorical(logits).sample()\n",
    "print(x_t_cat,x_t_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits# B, D, S\n",
    "loss = -(\n",
    "    (S - 1) * ll_xt\n",
    "    + torch.sum(utils.log1mexp(ll_all), dim=-1)\n",
    "    - utils.log1mexp(ll_xt)\n",
    ")\n",
    "print(loss, loss.shape)\n",
    "weight = torch.ones((B,), dtype=torch.float32)\n",
    "weight = utils.expand_dims(weight, axis=list(range(1, loss.dim())))\n",
    "print(weight, weight.shape)\n",
    "loss = loss * weight\n",
    "print(loss, loss.shape)\n",
    "loss = torch.sum(loss) / xt.shape[0]\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_xt = xt #B, D\n",
    "ll_all =  logits\n",
    "xt_onehot = F.one_hot(xt.long(), num_classes=S)\n",
    "b = utils.expand_dims(torch.arange(xt.shape[0]), tuple(range(1, xt.dim())))\n",
    "print(b, b.shape)\n",
    "qt0_x2y = uni.transition(ts)\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = qt0_x2y.permute(0, 2, 1)\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "qt0_y2x = qt0_y2x[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "ll_xt = ll_xt.unsqueeze(-1)\n",
    "print(\"ll\", ll_xt, ll_xt.shape)\n",
    "backwd = torch.exp(ll_all - ll_xt) * qt0_y2x\n",
    "print(backwd , backwd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_term = torch.sum(backwd * (1 - xt_onehot), dim=-1)\n",
    "print(first_term , first_term.shape)\n",
    "qt0_x2y = qt0_x2y[b, xt]\n",
    "print(qt0_x2y, qt0_x2y.shape)\n",
    "fwd = (ll_xt - ll_all) * qt0_x2y\n",
    "print(fwd, fwd.shape)\n",
    "second_term = torch.sum(fwd * (1 - xt_onehot), dim=-1)\n",
    "print(second_term, second_term.shape)\n",
    "loss = first_term - second_term\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones((B,), dtype=torch.float32)\n",
    "weight = utils.expand_dims(weight, axis=list(range(1, loss.dim())))\n",
    "print(weight, weight.shape)\n",
    "loss = loss * weight\n",
    "print(loss, loss.shape)\n",
    "loss = torch.sum(loss) / xt.shape[0]\n",
    "print(loss, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.999\n",
      "0.998\n",
      "0.997\n",
      "0.996\n",
      "0.995\n",
      "0.994\n",
      "0.993\n",
      "0.992\n",
      "0.991\n",
      "0.99\n",
      "0.989\n",
      "0.988\n",
      "0.987\n",
      "0.986\n",
      "0.985\n",
      "0.984\n",
      "0.983\n",
      "0.982\n",
      "0.981\n",
      "0.98\n",
      "0.979\n",
      "0.978\n",
      "0.977\n",
      "0.976\n",
      "0.975\n",
      "0.974\n",
      "0.973\n",
      "0.972\n",
      "0.971\n",
      "0.97\n",
      "0.969\n",
      "0.968\n",
      "0.967\n",
      "0.966\n",
      "0.965\n",
      "0.964\n",
      "0.963\n",
      "0.962\n",
      "0.961\n",
      "0.96\n",
      "0.959\n",
      "0.958\n",
      "0.957\n",
      "0.956\n",
      "0.955\n",
      "0.954\n",
      "0.953\n",
      "0.952\n",
      "0.951\n",
      "0.95\n",
      "0.949\n",
      "0.948\n",
      "0.947\n",
      "0.946\n",
      "0.945\n",
      "0.944\n",
      "0.943\n",
      "0.942\n",
      "0.941\n",
      "0.94\n",
      "0.9390000000000001\n",
      "0.938\n",
      "0.937\n",
      "0.9359999999999999\n",
      "0.935\n",
      "0.9339999999999999\n",
      "0.933\n",
      "0.9319999999999999\n",
      "0.931\n",
      "0.9299999999999999\n",
      "0.929\n",
      "0.9279999999999999\n",
      "0.927\n",
      "0.926\n",
      "0.925\n",
      "0.924\n",
      "0.923\n",
      "0.922\n",
      "0.921\n",
      "0.92\n",
      "0.919\n",
      "0.918\n",
      "0.917\n",
      "0.916\n",
      "0.915\n",
      "0.914\n",
      "0.913\n",
      "0.912\n",
      "0.911\n",
      "0.91\n",
      "0.909\n",
      "0.908\n",
      "0.907\n",
      "0.906\n",
      "0.905\n",
      "0.904\n",
      "0.903\n",
      "0.902\n",
      "0.901\n",
      "0.9\n",
      "0.899\n",
      "0.898\n",
      "0.897\n",
      "0.896\n",
      "0.895\n",
      "0.894\n",
      "0.893\n",
      "0.892\n",
      "0.891\n",
      "0.89\n",
      "0.889\n",
      "0.888\n",
      "0.887\n",
      "0.886\n",
      "0.885\n",
      "0.884\n",
      "0.883\n",
      "0.882\n",
      "0.881\n",
      "0.88\n",
      "0.879\n",
      "0.878\n",
      "0.877\n",
      "0.876\n",
      "0.875\n",
      "0.874\n",
      "0.873\n",
      "0.872\n",
      "0.871\n",
      "0.87\n",
      "0.869\n",
      "0.868\n",
      "0.867\n",
      "0.866\n",
      "0.865\n",
      "0.864\n",
      "0.863\n",
      "0.862\n",
      "0.861\n",
      "0.86\n",
      "0.859\n",
      "0.858\n",
      "0.857\n",
      "0.856\n",
      "0.855\n",
      "0.854\n",
      "0.853\n",
      "0.852\n",
      "0.851\n",
      "0.85\n",
      "0.849\n",
      "0.848\n",
      "0.847\n",
      "0.846\n",
      "0.845\n",
      "0.844\n",
      "0.843\n",
      "0.842\n",
      "0.841\n",
      "0.84\n",
      "0.839\n",
      "0.838\n",
      "0.837\n",
      "0.836\n",
      "0.835\n",
      "0.834\n",
      "0.833\n",
      "0.832\n",
      "0.831\n",
      "0.83\n",
      "0.829\n",
      "0.828\n",
      "0.827\n",
      "0.826\n",
      "0.825\n",
      "0.8240000000000001\n",
      "0.823\n",
      "0.8220000000000001\n",
      "0.821\n",
      "0.8200000000000001\n",
      "0.819\n",
      "0.8180000000000001\n",
      "0.817\n",
      "0.8160000000000001\n",
      "0.815\n",
      "0.8140000000000001\n",
      "0.813\n",
      "0.812\n",
      "0.8109999999999999\n",
      "0.81\n",
      "0.8089999999999999\n",
      "0.808\n",
      "0.8069999999999999\n",
      "0.806\n",
      "0.8049999999999999\n",
      "0.804\n",
      "0.8029999999999999\n",
      "0.802\n",
      "0.8009999999999999\n",
      "0.8\n",
      "0.7989999999999999\n",
      "0.798\n",
      "0.7969999999999999\n",
      "0.796\n",
      "0.7949999999999999\n",
      "0.794\n",
      "0.7929999999999999\n",
      "0.792\n",
      "0.791\n",
      "0.79\n",
      "0.789\n",
      "0.788\n",
      "0.787\n",
      "0.786\n",
      "0.785\n",
      "0.784\n",
      "0.783\n",
      "0.782\n",
      "0.781\n",
      "0.78\n",
      "0.779\n",
      "0.778\n",
      "0.777\n",
      "0.776\n",
      "0.775\n",
      "0.774\n",
      "0.773\n",
      "0.772\n",
      "0.771\n",
      "0.77\n",
      "0.769\n",
      "0.768\n",
      "0.767\n",
      "0.766\n",
      "0.765\n",
      "0.764\n",
      "0.763\n",
      "0.762\n",
      "0.761\n",
      "0.76\n",
      "0.759\n",
      "0.758\n",
      "0.757\n",
      "0.756\n",
      "0.755\n",
      "0.754\n",
      "0.753\n",
      "0.752\n",
      "0.751\n",
      "0.75\n",
      "0.749\n",
      "0.748\n",
      "0.747\n",
      "0.746\n",
      "0.745\n",
      "0.744\n",
      "0.743\n",
      "0.742\n",
      "0.741\n",
      "0.74\n",
      "0.739\n",
      "0.738\n",
      "0.737\n",
      "0.736\n",
      "0.735\n",
      "0.734\n",
      "0.733\n",
      "0.732\n",
      "0.731\n",
      "0.73\n",
      "0.729\n",
      "0.728\n",
      "0.727\n",
      "0.726\n",
      "0.725\n",
      "0.724\n",
      "0.723\n",
      "0.722\n",
      "0.721\n",
      "0.72\n",
      "0.719\n",
      "0.718\n",
      "0.717\n",
      "0.716\n",
      "0.715\n",
      "0.714\n",
      "0.713\n",
      "0.712\n",
      "0.7110000000000001\n",
      "0.71\n",
      "0.7090000000000001\n",
      "0.708\n",
      "0.7070000000000001\n",
      "0.706\n",
      "0.7050000000000001\n",
      "0.704\n",
      "0.7030000000000001\n",
      "0.702\n",
      "0.7010000000000001\n",
      "0.7\n",
      "0.6990000000000001\n",
      "0.698\n",
      "0.6970000000000001\n",
      "0.696\n",
      "0.6950000000000001\n",
      "0.694\n",
      "0.6930000000000001\n",
      "0.692\n",
      "0.6910000000000001\n",
      "0.69\n",
      "0.6890000000000001\n",
      "0.688\n",
      "0.687\n",
      "0.6859999999999999\n",
      "0.685\n",
      "0.6839999999999999\n",
      "0.683\n",
      "0.6819999999999999\n",
      "0.681\n",
      "0.6799999999999999\n",
      "0.679\n",
      "0.6779999999999999\n",
      "0.677\n",
      "0.6759999999999999\n",
      "0.675\n",
      "0.6739999999999999\n",
      "0.673\n",
      "0.6719999999999999\n",
      "0.671\n",
      "0.6699999999999999\n",
      "0.669\n",
      "0.6679999999999999\n",
      "0.667\n",
      "0.6659999999999999\n",
      "0.665\n",
      "0.6639999999999999\n",
      "0.663\n",
      "0.6619999999999999\n",
      "0.661\n",
      "0.6599999999999999\n",
      "0.659\n",
      "0.6579999999999999\n",
      "0.657\n",
      "0.6559999999999999\n",
      "0.655\n",
      "0.6539999999999999\n",
      "0.653\n",
      "0.6519999999999999\n",
      "0.651\n",
      "0.6499999999999999\n",
      "0.649\n",
      "0.648\n",
      "0.647\n",
      "0.646\n",
      "0.645\n",
      "0.644\n",
      "0.643\n",
      "0.642\n",
      "0.641\n",
      "0.64\n",
      "0.639\n",
      "0.638\n",
      "0.637\n",
      "0.636\n",
      "0.635\n",
      "0.634\n",
      "0.633\n",
      "0.632\n",
      "0.631\n",
      "0.63\n",
      "0.629\n",
      "0.628\n",
      "0.627\n",
      "0.626\n",
      "0.625\n",
      "0.624\n",
      "0.623\n",
      "0.622\n",
      "0.621\n",
      "0.62\n",
      "0.619\n",
      "0.618\n",
      "0.617\n",
      "0.616\n",
      "0.615\n",
      "0.614\n",
      "0.613\n",
      "0.612\n",
      "0.611\n",
      "0.61\n",
      "0.609\n",
      "0.608\n",
      "0.607\n",
      "0.606\n",
      "0.605\n",
      "0.604\n",
      "0.603\n",
      "0.602\n",
      "0.601\n",
      "0.6\n",
      "0.599\n",
      "0.598\n",
      "0.597\n",
      "0.596\n",
      "0.595\n",
      "0.594\n",
      "0.593\n",
      "0.592\n",
      "0.591\n",
      "0.59\n",
      "0.589\n",
      "0.588\n",
      "0.587\n",
      "0.586\n",
      "0.585\n",
      "0.584\n",
      "0.583\n",
      "0.5820000000000001\n",
      "0.581\n",
      "0.5800000000000001\n",
      "0.579\n",
      "0.5780000000000001\n",
      "0.577\n",
      "0.5760000000000001\n",
      "0.575\n",
      "0.5740000000000001\n",
      "0.573\n",
      "0.5720000000000001\n",
      "0.571\n",
      "0.5700000000000001\n",
      "0.569\n",
      "0.5680000000000001\n",
      "0.567\n",
      "0.5660000000000001\n",
      "0.565\n",
      "0.5640000000000001\n",
      "0.563\n",
      "0.562\n",
      "0.5609999999999999\n",
      "0.56\n",
      "0.5589999999999999\n",
      "0.558\n",
      "0.5569999999999999\n",
      "0.556\n",
      "0.5549999999999999\n",
      "0.554\n",
      "0.5529999999999999\n",
      "0.552\n",
      "0.5509999999999999\n",
      "0.55\n",
      "0.5489999999999999\n",
      "0.548\n",
      "0.5469999999999999\n",
      "0.546\n",
      "0.5449999999999999\n",
      "0.544\n",
      "0.5429999999999999\n",
      "0.542\n",
      "0.5409999999999999\n",
      "0.54\n",
      "0.5389999999999999\n",
      "0.538\n",
      "0.5369999999999999\n",
      "0.536\n",
      "0.5349999999999999\n",
      "0.534\n",
      "0.5329999999999999\n",
      "0.532\n",
      "0.5309999999999999\n",
      "0.53\n",
      "0.5289999999999999\n",
      "0.528\n",
      "0.5269999999999999\n",
      "0.526\n",
      "0.5249999999999999\n",
      "0.524\n",
      "0.5229999999999999\n",
      "0.522\n",
      "0.5209999999999999\n",
      "0.52\n",
      "0.519\n",
      "0.518\n",
      "0.517\n",
      "0.516\n",
      "0.515\n",
      "0.514\n",
      "0.513\n",
      "0.512\n",
      "0.511\n",
      "0.51\n",
      "0.509\n",
      "0.508\n",
      "0.507\n",
      "0.506\n",
      "0.505\n",
      "0.504\n",
      "0.503\n",
      "0.502\n",
      "0.501\n",
      "0.5\n",
      "0.499\n",
      "0.498\n",
      "0.497\n",
      "0.496\n",
      "0.495\n",
      "0.494\n",
      "0.493\n",
      "0.492\n",
      "0.491\n",
      "0.49\n",
      "0.489\n",
      "0.488\n",
      "0.487\n",
      "0.486\n",
      "0.485\n",
      "0.484\n",
      "0.483\n",
      "0.482\n",
      "0.481\n",
      "0.48\n",
      "0.479\n",
      "0.478\n",
      "0.477\n",
      "0.476\n",
      "0.475\n",
      "0.474\n",
      "0.473\n",
      "0.472\n",
      "0.471\n",
      "0.47\n",
      "0.469\n",
      "0.46799999999999997\n",
      "0.46699999999999997\n",
      "0.46599999999999997\n",
      "0.46499999999999997\n",
      "0.46399999999999997\n",
      "0.46299999999999997\n",
      "0.46199999999999997\n",
      "0.46099999999999997\n",
      "0.45999999999999996\n",
      "0.45899999999999996\n",
      "0.45799999999999996\n",
      "0.45699999999999996\n",
      "0.45599999999999996\n",
      "0.45499999999999996\n",
      "0.45399999999999996\n",
      "0.45299999999999996\n",
      "0.45199999999999996\n",
      "0.45099999999999996\n",
      "0.44999999999999996\n",
      "0.44899999999999995\n",
      "0.44799999999999995\n",
      "0.44699999999999995\n",
      "0.44599999999999995\n",
      "0.44499999999999995\n",
      "0.44399999999999995\n",
      "0.44299999999999995\n",
      "0.44199999999999995\n",
      "0.44099999999999995\n",
      "0.43999999999999995\n",
      "0.43899999999999995\n",
      "0.43799999999999994\n",
      "0.43699999999999994\n",
      "0.43599999999999994\n",
      "0.43499999999999994\n",
      "0.43399999999999994\n",
      "0.43299999999999994\n",
      "0.43199999999999994\n",
      "0.43099999999999994\n",
      "0.42999999999999994\n",
      "0.42899999999999994\n",
      "0.42799999999999994\n",
      "0.42699999999999994\n",
      "0.42599999999999993\n",
      "0.42499999999999993\n",
      "0.42399999999999993\n",
      "0.42300000000000004\n",
      "0.42200000000000004\n",
      "0.42100000000000004\n",
      "0.42000000000000004\n",
      "0.41900000000000004\n",
      "0.41800000000000004\n",
      "0.41700000000000004\n",
      "0.41600000000000004\n",
      "0.41500000000000004\n",
      "0.41400000000000003\n",
      "0.41300000000000003\n",
      "0.41200000000000003\n",
      "0.41100000000000003\n",
      "0.41000000000000003\n",
      "0.40900000000000003\n",
      "0.40800000000000003\n",
      "0.40700000000000003\n",
      "0.406\n",
      "0.405\n",
      "0.404\n",
      "0.403\n",
      "0.402\n",
      "0.401\n",
      "0.4\n",
      "0.399\n",
      "0.398\n",
      "0.397\n",
      "0.396\n",
      "0.395\n",
      "0.394\n",
      "0.393\n",
      "0.392\n",
      "0.391\n",
      "0.39\n",
      "0.389\n",
      "0.388\n",
      "0.387\n",
      "0.386\n",
      "0.385\n",
      "0.384\n",
      "0.383\n",
      "0.382\n",
      "0.381\n",
      "0.38\n",
      "0.379\n",
      "0.378\n",
      "0.377\n",
      "0.376\n",
      "0.375\n",
      "0.374\n",
      "0.373\n",
      "0.372\n",
      "0.371\n",
      "0.37\n",
      "0.369\n",
      "0.368\n",
      "0.367\n",
      "0.366\n",
      "0.365\n",
      "0.364\n",
      "0.363\n",
      "0.362\n",
      "0.361\n",
      "0.36\n",
      "0.359\n",
      "0.358\n",
      "0.357\n",
      "0.356\n",
      "0.355\n",
      "0.354\n",
      "0.353\n",
      "0.352\n",
      "0.351\n",
      "0.35\n",
      "0.349\n",
      "0.348\n",
      "0.347\n",
      "0.346\n",
      "0.345\n",
      "0.344\n",
      "0.34299999999999997\n",
      "0.34199999999999997\n",
      "0.34099999999999997\n",
      "0.33999999999999997\n",
      "0.33899999999999997\n",
      "0.33799999999999997\n",
      "0.33699999999999997\n",
      "0.33599999999999997\n",
      "0.33499999999999996\n",
      "0.33399999999999996\n",
      "0.33299999999999996\n",
      "0.33199999999999996\n",
      "0.33099999999999996\n",
      "0.32999999999999996\n",
      "0.32899999999999996\n",
      "0.32799999999999996\n",
      "0.32699999999999996\n",
      "0.32599999999999996\n",
      "0.32499999999999996\n",
      "0.32399999999999995\n",
      "0.32299999999999995\n",
      "0.32199999999999995\n",
      "0.32099999999999995\n",
      "0.31999999999999995\n",
      "0.31899999999999995\n",
      "0.31799999999999995\n",
      "0.31699999999999995\n",
      "0.31599999999999995\n",
      "0.31499999999999995\n",
      "0.31399999999999995\n",
      "0.31299999999999994\n",
      "0.31199999999999994\n",
      "0.31099999999999994\n",
      "0.30999999999999994\n",
      "0.30899999999999994\n",
      "0.30799999999999994\n",
      "0.30699999999999994\n",
      "0.30599999999999994\n",
      "0.30499999999999994\n",
      "0.30399999999999994\n",
      "0.30299999999999994\n",
      "0.30199999999999994\n",
      "0.30099999999999993\n",
      "0.29999999999999993\n",
      "0.29899999999999993\n",
      "0.29799999999999993\n",
      "0.29699999999999993\n",
      "0.29600000000000004\n",
      "0.29500000000000004\n",
      "0.29400000000000004\n",
      "0.29300000000000004\n",
      "0.29200000000000004\n",
      "0.29100000000000004\n",
      "0.29000000000000004\n",
      "0.28900000000000003\n",
      "0.28800000000000003\n",
      "0.28700000000000003\n",
      "0.28600000000000003\n",
      "0.28500000000000003\n",
      "0.28400000000000003\n",
      "0.28300000000000003\n",
      "0.28200000000000003\n",
      "0.281\n",
      "0.28\n",
      "0.279\n",
      "0.278\n",
      "0.277\n",
      "0.276\n",
      "0.275\n",
      "0.274\n",
      "0.273\n",
      "0.272\n",
      "0.271\n",
      "0.27\n",
      "0.269\n",
      "0.268\n",
      "0.267\n",
      "0.266\n",
      "0.265\n",
      "0.264\n",
      "0.263\n",
      "0.262\n",
      "0.261\n",
      "0.26\n",
      "0.259\n",
      "0.258\n",
      "0.257\n",
      "0.256\n",
      "0.255\n",
      "0.254\n",
      "0.253\n",
      "0.252\n",
      "0.251\n",
      "0.25\n",
      "0.249\n",
      "0.248\n",
      "0.247\n",
      "0.246\n",
      "0.245\n",
      "0.244\n",
      "0.243\n",
      "0.242\n",
      "0.241\n",
      "0.24\n",
      "0.239\n",
      "0.238\n",
      "0.237\n",
      "0.236\n",
      "0.235\n",
      "0.23399999999999999\n",
      "0.23299999999999998\n",
      "0.23199999999999998\n",
      "0.23099999999999998\n",
      "0.22999999999999998\n",
      "0.22899999999999998\n",
      "0.22799999999999998\n",
      "0.22699999999999998\n",
      "0.22599999999999998\n",
      "0.22499999999999998\n",
      "0.22399999999999998\n",
      "0.22299999999999998\n",
      "0.22199999999999998\n",
      "0.22099999999999997\n",
      "0.21999999999999997\n",
      "0.21899999999999997\n",
      "0.21799999999999997\n",
      "0.21699999999999997\n",
      "0.21599999999999997\n",
      "0.21499999999999997\n",
      "0.21399999999999997\n",
      "0.21299999999999997\n",
      "0.21199999999999997\n",
      "0.21099999999999997\n",
      "0.20999999999999996\n",
      "0.20899999999999996\n",
      "0.20799999999999996\n",
      "0.20699999999999996\n",
      "0.20599999999999996\n",
      "0.20499999999999996\n",
      "0.20399999999999996\n",
      "0.20299999999999996\n",
      "0.20199999999999996\n",
      "0.20099999999999996\n",
      "0.19999999999999996\n",
      "0.19899999999999995\n",
      "0.19799999999999995\n",
      "0.19699999999999995\n",
      "0.19599999999999995\n",
      "0.19499999999999995\n",
      "0.19399999999999995\n",
      "0.19299999999999995\n",
      "0.19199999999999995\n",
      "0.19099999999999995\n",
      "0.18999999999999995\n",
      "0.18899999999999995\n",
      "0.18799999999999994\n",
      "0.18699999999999994\n",
      "0.18599999999999994\n",
      "0.18499999999999994\n",
      "0.18399999999999994\n",
      "0.18299999999999994\n",
      "0.18199999999999994\n",
      "0.18099999999999994\n",
      "0.17999999999999994\n",
      "0.17899999999999994\n",
      "0.17799999999999994\n",
      "0.17699999999999994\n",
      "0.17599999999999993\n",
      "0.17499999999999993\n",
      "0.17399999999999993\n",
      "0.17299999999999993\n",
      "0.17199999999999993\n",
      "0.17099999999999993\n",
      "0.16999999999999993\n",
      "0.16899999999999993\n",
      "0.16799999999999993\n",
      "0.16700000000000004\n",
      "0.16600000000000004\n",
      "0.16500000000000004\n",
      "0.16400000000000003\n",
      "0.16300000000000003\n",
      "0.16200000000000003\n",
      "0.16100000000000003\n",
      "0.16000000000000003\n",
      "0.15900000000000003\n",
      "0.15800000000000003\n",
      "0.15700000000000003\n",
      "0.15600000000000003\n",
      "0.15500000000000003\n",
      "0.15400000000000003\n",
      "0.15300000000000002\n",
      "0.15200000000000002\n",
      "0.15100000000000002\n",
      "0.15000000000000002\n",
      "0.14900000000000002\n",
      "0.14800000000000002\n",
      "0.14700000000000002\n",
      "0.14600000000000002\n",
      "0.14500000000000002\n",
      "0.14400000000000002\n",
      "0.14300000000000002\n",
      "0.14200000000000002\n",
      "0.14100000000000001\n",
      "0.14\n",
      "0.139\n",
      "0.138\n",
      "0.137\n",
      "0.136\n",
      "0.135\n",
      "0.134\n",
      "0.133\n",
      "0.132\n",
      "0.131\n",
      "0.13\n",
      "0.129\n",
      "0.128\n",
      "0.127\n",
      "0.126\n",
      "0.125\n",
      "0.124\n",
      "0.123\n",
      "0.122\n",
      "0.121\n",
      "0.12\n",
      "0.119\n",
      "0.118\n",
      "0.11699999999999999\n",
      "0.11599999999999999\n",
      "0.11499999999999999\n",
      "0.11399999999999999\n",
      "0.11299999999999999\n",
      "0.11199999999999999\n",
      "0.11099999999999999\n",
      "0.10999999999999999\n",
      "0.10899999999999999\n",
      "0.10799999999999998\n",
      "0.10699999999999998\n",
      "0.10599999999999998\n",
      "0.10499999999999998\n",
      "0.10399999999999998\n",
      "0.10299999999999998\n",
      "0.10199999999999998\n",
      "0.10099999999999998\n",
      "0.09999999999999998\n",
      "0.09899999999999998\n",
      "0.09799999999999998\n",
      "0.09699999999999998\n",
      "0.09599999999999997\n",
      "0.09499999999999997\n",
      "0.09399999999999997\n",
      "0.09299999999999997\n",
      "0.09199999999999997\n",
      "0.09099999999999997\n",
      "0.08999999999999997\n",
      "0.08899999999999997\n",
      "0.08799999999999997\n",
      "0.08699999999999997\n",
      "0.08599999999999997\n",
      "0.08499999999999996\n",
      "0.08399999999999996\n",
      "0.08299999999999996\n",
      "0.08199999999999996\n",
      "0.08099999999999996\n",
      "0.07999999999999996\n",
      "0.07899999999999996\n",
      "0.07799999999999996\n",
      "0.07699999999999996\n",
      "0.07599999999999996\n",
      "0.07499999999999996\n",
      "0.07399999999999995\n",
      "0.07299999999999995\n",
      "0.07199999999999995\n",
      "0.07099999999999995\n",
      "0.06999999999999995\n",
      "0.06899999999999995\n",
      "0.06799999999999995\n",
      "0.06699999999999995\n",
      "0.06599999999999995\n",
      "0.06499999999999995\n",
      "0.06399999999999995\n",
      "0.06299999999999994\n",
      "0.061999999999999944\n",
      "0.06099999999999994\n",
      "0.05999999999999994\n",
      "0.05899999999999994\n",
      "0.05799999999999994\n",
      "0.05699999999999994\n",
      "0.05599999999999994\n",
      "0.05499999999999994\n",
      "0.05399999999999994\n",
      "0.052999999999999936\n",
      "0.051999999999999935\n",
      "0.050999999999999934\n",
      "0.04999999999999993\n",
      "0.04899999999999993\n",
      "0.04799999999999993\n",
      "0.04699999999999993\n",
      "0.04599999999999993\n",
      "0.04499999999999993\n",
      "0.04399999999999993\n",
      "0.04299999999999993\n",
      "0.041999999999999926\n",
      "0.040999999999999925\n",
      "0.040000000000000036\n",
      "0.039000000000000035\n",
      "0.038000000000000034\n",
      "0.03700000000000003\n",
      "0.03600000000000003\n",
      "0.03500000000000003\n",
      "0.03400000000000003\n",
      "0.03300000000000003\n",
      "0.03200000000000003\n",
      "0.031000000000000028\n",
      "0.030000000000000027\n",
      "0.029000000000000026\n",
      "0.028000000000000025\n",
      "0.027000000000000024\n",
      "0.026000000000000023\n",
      "0.025000000000000022\n",
      "0.02400000000000002\n",
      "0.02300000000000002\n",
      "0.02200000000000002\n",
      "0.02100000000000002\n",
      "0.020000000000000018\n",
      "0.019000000000000017\n",
      "0.018000000000000016\n",
      "0.017000000000000015\n",
      "0.016000000000000014\n",
      "0.015000000000000013\n",
      "0.014000000000000012\n",
      "0.013000000000000012\n",
      "0.01200000000000001\n",
      "0.01100000000000001\n",
      "0.010000000000000009\n",
      "0.009000000000000008\n",
      "0.008000000000000007\n",
      "0.007000000000000006\n",
      "0.006000000000000005\n",
      "0.0050000000000000044\n",
      "0.0040000000000000036\n",
      "0.0030000000000000027\n",
      "0.0020000000000000018\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "ts = np.concatenate((np.linspace(1.0, 1e-3, 1000), np.array([0])))\n",
    "#save_ts = ts[np.linspace(0, len(ts)-2, num_intermediates, dtype=int)]\n",
    "\n",
    "for idx, t in (enumerate(ts[0:-1])):\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
