{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from lib.models.models import UniformRate\n",
    "import ml_collections\n",
    "from config.config_train_sample import get_config\n",
    "from lib.utils import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now, when we minimize LCT, we are sampling (x, x ̃) from the forward process and then maximizing the assigned model probability for \n",
    "\n",
    "the pairing in the reverse direction, just as in LDT. The slight extra complexity comes from the fact we areconsidering the case \n",
    "\n",
    "when xk = xk+1 and the case when xk ̸= xk+1 separately. When xk = xk+1, this corresponds to the first term in LCT which we can see \n",
    "\n",
    "is minimizing the reverse rate out of x which is exactly maximizing the model probability for no transition to occur. When xk ̸= xk+1, \n",
    "\n",
    "this corresponds to the second term in LCT, which is maximizing the reverse rate from x ̃ to x which in turn maximizes the model probability \n",
    "\n",
    "for the x ̃ to x transition to occur.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fragen Yannick:\n",
    "# Wieso xt samplen from q_t|0 and then one transition to x_tilde => and then logits = net(x_tile, t)\n",
    "#    # q_{t|0} (x ̃|x_0) =>  qt0_numer_reg = qt0.view(B, S, S)\n",
    "\n",
    "# 2 forward passed: p^{θ}_{0|t}(x0|x) to calculate Rˆ{θ}_t(x, x′) and p^{θ}_{0|t}(x0|x ̃) to calculate Rˆ{θ}_t(x ̃, x). This is wasteful\n",
    "rate_const = 1\n",
    "S = 3\n",
    "B = 2\n",
    "D = 4\n",
    "device = 'cpu'\n",
    "rate = rate_const * np.ones((S, S))\n",
    "rate = rate - np.diag(np.diag(rate))\n",
    "#print(rate)\n",
    "rate = rate - np.diag(np.sum(rate, axis=1))\n",
    "\n",
    "#print(rate)\n",
    "rate_matrix = torch.from_numpy(rate).float()\n",
    "\n",
    "rate_matrix = torch.tile(rate_matrix.view(1, S, S), (B, 1, 1))\n",
    "#print(rate_matrix.shape)\n",
    "v = torch.tensor([1, 2, 3])\n",
    "matrix = torch.diag_embed(v)\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2817, 0.2817, 0.4367],\n",
      "        [0.4367, 0.2817, 0.2817],\n",
      "        [0.2817, 0.4367, 0.2817],\n",
      "        [0.4367, 0.2817, 0.2817],\n",
      "        [0.7028, 0.1486, 0.1486],\n",
      "        [0.1486, 0.7028, 0.1486],\n",
      "        [0.1486, 0.7028, 0.1486],\n",
      "        [0.1486, 0.1486, 0.7028]]) torch.Size([8, 3])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[0.2817, 0.2817, 0.4367],\n",
      "        [0.4367, 0.2817, 0.2817],\n",
      "        [0.2817, 0.4367, 0.2817],\n",
      "        [0.4367, 0.2817, 0.2817],\n",
      "        [0.7028, 0.1486, 0.1486],\n",
      "        [0.1486, 0.7028, 0.1486],\n",
      "        [0.1486, 0.7028, 0.1486],\n",
      "        [0.1486, 0.1486, 0.7028]]) torch.Size([8, 3])\n",
      "tensor([[0, 1, 2, 2],\n",
      "        [0, 1, 0, 0]]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "#-----------Transition matrix q_t|0: x0 -> xt ---------------------\n",
    "cfg = get_config()\n",
    "cfg.data.S = S\n",
    "cfg.model.rate_const = rate_const\n",
    "uni = UniformRate(cfg, 'cpu')\n",
    "ts = torch.rand((B,))\n",
    "qt0 = uni.transition(ts)\n",
    "x0= torch.randint(low=0, high=S, size=(B, D), dtype=torch.int)\n",
    "#print(x0)\n",
    "#print(qt0, qt0.shape)\n",
    "qt0_rows_reg = qt0[\n",
    "    torch.arange(B, device=device).repeat_interleave(\n",
    "        D\n",
    "    ),  # repeats every element 0 to B-1 D-times\n",
    "    x0.flatten().long(),  # minibatch.flatten() => (B, D) => (B*D) (1D-Tensor)\n",
    "    :,\n",
    "]\n",
    "print(qt0_rows_reg, qt0_rows_reg.shape)\n",
    "b = utils.expand_dims(torch.arange(B), (tuple(range(1, x0.dim()))))\n",
    "qt0_rows_reg2 = qt0[b, x0].view(-1, S)\n",
    "print(qt0_rows_reg2 == qt0_rows_reg)\n",
    "print(qt0_rows_reg2, qt0_rows_reg2.shape)\n",
    "\n",
    "x_t_cat = torch.distributions.categorical.Categorical(qt0_rows_reg)\n",
    "x_t = x_t_cat.sample().view(B, D)\n",
    "print(x_t, x_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.]]) torch.Size([8, 3])\n",
      "tensor([[[1., 1., 0.],\n",
      "         [0., 1., 1.],\n",
      "         [0., 1., 1.],\n",
      "         [1., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 1.],\n",
      "         [1., 1., 0.],\n",
      "         [0., 1., 1.],\n",
      "         [1., 0., 1.]]]) torch.Size([2, 4, 3])\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]]) torch.Size([2, 4])\n",
      "Where transition tensor([3, 0]) torch.Size([2])\n",
      "tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.]]) torch.Size([2, 3])\n",
      "Transition value tensor([0, 2]) torch.Size([2])\n",
      "tensor([[2, 0, 0, 2],\n",
      "        [0, 2, 0, 1]])\n",
      "tensor([[2, 0, 0, 0],\n",
      "        [2, 2, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "#-------------- Transition rate: x_t -> x_tilde ------------------\n",
    "rate = uni.rate(ts)\n",
    "#print(rate, rate.shape) # B, S, S\n",
    "rate_vals_square = rate[\n",
    "        torch.arange(B, device=device).repeat_interleave(D), x_t.long().flatten(), :\n",
    "    ]\n",
    "#print(rate_vals_square, rate_vals_square.shape)\n",
    "rate_vals_square[\n",
    "        torch.arange(B * D, device=device), x_t.long().flatten()\n",
    "    ] = 0.0 \n",
    "print(rate_vals_square, rate_vals_square.shape)\n",
    "\n",
    "rate_vals_square = rate_vals_square.view(B, D, S)\n",
    "print(rate_vals_square, rate_vals_square.shape)\n",
    "\n",
    "rate_vals_square_dimsum = torch.sum(rate_vals_square, dim=2).view(B, D)\n",
    "print(rate_vals_square_dimsum, rate_vals_square_dimsum.shape)\n",
    "\n",
    "square_dimcat = torch.distributions.categorical.Categorical(rate_vals_square_dimsum)\n",
    "\n",
    "square_dims = square_dimcat.sample() # sampled where transition takes places in every row of B\n",
    "print(\"Where transition\", square_dims, square_dims.shape)\n",
    "\n",
    "rate_new_val_probs = rate_vals_square[\n",
    "    torch.arange(B, device=device), square_dims, :\n",
    "]  # (B, S)\n",
    "print(rate_new_val_probs, rate_new_val_probs.shape)\n",
    "\n",
    "square_newvalcat = torch.distributions.categorical.Categorical(\n",
    "    rate_new_val_probs\n",
    ")\n",
    "\n",
    "# Shape: (B,) mit Werten im Bereich [0, S)\n",
    "square_newval_samples = (\n",
    "    square_newvalcat.sample()\n",
    ")\n",
    "print(\"Transition value\", square_newval_samples, square_newval_samples.shape)\n",
    "\n",
    "x_tilde = x_t.clone()\n",
    "        # noisy image \n",
    "x_tilde[torch.arange(B, device=device), square_dims] = square_newval_samples\n",
    "print(x_t)\n",
    "print(x_tilde)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 0, 0],\n",
      "        [2, 2, 0, 1]])\n",
      "tensor([[[1., 1., 0.],\n",
      "         [0., 1., 1.],\n",
      "         [0., 1., 1.],\n",
      "         [0., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 0.],\n",
      "         [1., 1., 0.],\n",
      "         [0., 1., 1.],\n",
      "         [1., 0., 1.]]]) torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "#-----------ELBO-------------------\n",
    "mask_reg = torch.ones((B, D, S), device=device)\n",
    "\n",
    "mask_reg[\n",
    "    torch.arange(B, device=device).repeat_interleave(D),\n",
    "    torch.arange(D, device=device).repeat(B),\n",
    "    x_tilde.long().flatten(),\n",
    "] = 0.0\n",
    "print(x_tilde)\n",
    "print(mask_reg, mask_reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3818, 0.3091, 0.3091],\n",
      "         [0.3091, 0.3818, 0.3091],\n",
      "         [0.3091, 0.3091, 0.3818]],\n",
      "\n",
      "        [[0.3917, 0.3042, 0.3042],\n",
      "         [0.3042, 0.3917, 0.3042],\n",
      "         [0.3042, 0.3042, 0.3917]]]) torch.Size([2, 3, 3])\n",
      "tensor([[[ 1.,  1., -2.],\n",
      "         [-2.,  1.,  1.],\n",
      "         [-2.,  1.,  1.],\n",
      "         [-2.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  1., -2.],\n",
      "         [ 1.,  1., -2.],\n",
      "         [-2.,  1.,  1.],\n",
      "         [ 1., -2.,  1.]]]) torch.Size([2, 4, 3])\n",
      "tensor([[[1., 1., -0.],\n",
      "         [-0., 1., 1.],\n",
      "         [-0., 1., 1.],\n",
      "         [-0., 1., 1.]],\n",
      "\n",
      "        [[1., 1., -0.],\n",
      "         [1., 1., -0.],\n",
      "         [-0., 1., 1.],\n",
      "         [1., -0., 1.]]])\n",
      "tensor([[[0.6909, 0.6909, 0.6182],\n",
      "         [0.6182, 0.6909, 0.6909],\n",
      "         [0.6182, 0.6909, 0.6909],\n",
      "         [0.6182, 0.6909, 0.6909]],\n",
      "\n",
      "        [[0.6958, 0.6958, 0.6083],\n",
      "         [0.6958, 0.6958, 0.6083],\n",
      "         [0.6083, 0.6958, 0.6958],\n",
      "         [0.6958, 0.6083, 0.6958]]]) torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "qt0_numer_reg = qt0.view(B, S, S)\n",
    "print(qt0_numer_reg , qt0_numer_reg.shape)\n",
    "# q_{t|0} (x|x_0)\n",
    "qt0_denom_reg = (\n",
    "    qt0[\n",
    "        torch.arange(B, device=device).repeat_interleave(D),\n",
    "        :,\n",
    "        x_tilde.long().flatten(),\n",
    "    ].view(B, D, S)\n",
    "    + 1e-6\n",
    ")\n",
    "#print(qt0_denom_reg, qt0_denom_reg.shape)\n",
    "\n",
    "#print(rate, rate.shape)\n",
    "rate_vals_reg = rate[\n",
    "    torch.arange(B, device=device).repeat_interleave(D),\n",
    "    :,\n",
    "    x_tilde.long().flatten(),\n",
    "].view(B, D, S)\n",
    "print(rate_vals_reg, rate_vals_reg.shape)\n",
    "print((mask_reg * rate_vals_reg))\n",
    "reg_tmp = (mask_reg * rate_vals_reg) @ qt0_numer_reg.transpose(1, 2)\n",
    "print(reg_tmp, reg_tmp.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
