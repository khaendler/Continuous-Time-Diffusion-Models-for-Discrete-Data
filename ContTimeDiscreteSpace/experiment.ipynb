{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lib.networks.networks import MiniUNet, MiniUNetDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[242,  37,  42,  ..., 222, 249, 163],\n",
      "          [105,  86, 123,  ...,  65,  35, 206],\n",
      "          [134,  45, 220,  ..., 222,  18, 210],\n",
      "          ...,\n",
      "          [ 37, 229,  55,  ..., 238, 141, 165],\n",
      "          [ 65, 211, 176,  ...,  79, 219, 148],\n",
      "          [ 35, 201, 211,  ..., 192,  95,   5]]],\n",
      "\n",
      "\n",
      "        [[[ 33, 190,  63,  ..., 133, 178, 176],\n",
      "          [149, 196, 110,  ...,  43,  52,  28],\n",
      "          [103, 139, 207,  ..., 163,  57, 129],\n",
      "          ...,\n",
      "          [ 22,  68,  68,  ..., 175, 248,  88],\n",
      "          [205, 116,  34,  ...,  93, 178, 110],\n",
      "          [126, 166, 157,  ...,  24, 102, 204]]],\n",
      "\n",
      "\n",
      "        [[[ 53, 182, 123,  ..., 118,  70, 144],\n",
      "          [ 67, 188,  52,  ..., 170,  13, 163],\n",
      "          [128, 242, 203,  ...,  49, 195,  63],\n",
      "          ...,\n",
      "          [170, 182, 251,  ..., 215, 178,  45],\n",
      "          [ 91, 132, 250,  ..., 210, 202, 204],\n",
      "          [180, 239,  89,  ...,  45, 132, 166]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[199,  97,  44,  ...,  35,  92, 167],\n",
      "          [ 11,  92, 194,  ..., 113, 103,  21],\n",
      "          [175,  11, 184,  ..., 230, 188,  80],\n",
      "          ...,\n",
      "          [176, 123, 170,  ..., 178,  94, 139],\n",
      "          [244, 114, 252,  ...,  61, 183, 155],\n",
      "          [216, 126, 133,  ..., 134, 252,  95]]],\n",
      "\n",
      "\n",
      "        [[[ 63, 222,  51,  ..., 163, 212,  46],\n",
      "          [236, 167,  87,  ...,  48, 104, 108],\n",
      "          [114,  56, 223,  ..., 202, 181, 195],\n",
      "          ...,\n",
      "          [186,  47,  52,  ..., 187, 207,  75],\n",
      "          [ 77,  69, 114,  ..., 203, 233, 179],\n",
      "          [146, 187,  20,  ..., 180,  83,  94]]],\n",
      "\n",
      "\n",
      "        [[[125,  74, 154,  ..., 128,  69,  79],\n",
      "          [152,  58, 168,  ..., 178, 106,  52],\n",
      "          [ 64,  50, 187,  ..., 127, 210, 215],\n",
      "          ...,\n",
      "          [242,  28,   9,  ..., 123,  10,  60],\n",
      "          [ 97, 117,  47,  ..., 188, 127, 156],\n",
      "          [172, 162, 236,  ..., 149, 125,  33]]]], dtype=torch.uint8)\n",
      "after encoder: torch.Size([16, 32, 16, 16])\n",
      "after middle: torch.Size([16, 32, 16, 16])\n",
      "out after decode torch.Size([16, 2, 32, 32])\n",
      "MU, SCALE torch.Size([16, 1, 32, 32]) torch.Size([16, 1, 32, 32])\n",
      "torch.Size([16, 1, 32, 32, 1])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMU, SCALE\u001b[39m\u001b[39m\"\u001b[39m, mu\u001b[39m.\u001b[39mshape, scale\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(mu\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOutput shape:\u001b[39m\u001b[39m\"\u001b[39m, output_tensor\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "input_ch = 1\n",
    "output_ch = 1\n",
    "unet = MiniUNetDiscrete(dim=32, in_channel=input_ch, out_channel=output_ch, model_output='logistic_pars', num_classes=256, x_min_max=(0, 255))\n",
    "batch_size = 16\n",
    "channels = 1\n",
    "height = 32\n",
    "width = 32\n",
    "x = torch.randint(0, 256, (batch_size, channels, height, width), dtype=torch.uint8)\n",
    "print(x)\n",
    "\n",
    "output_tensor = unet(x)\n",
    "mu, scale = output_tensor\n",
    "print(\"MU, SCALE\", mu.shape, scale.shape)\n",
    "print(mu.unsqueeze(-1).shape)\n",
    "print(\"Output shape:\", output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in unet.parameters())\n",
    "print(total_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
